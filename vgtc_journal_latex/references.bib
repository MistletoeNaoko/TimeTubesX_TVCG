@INPROCEEDINGS{Sawada2018,
author={N. {Sawada} and M. {Nakayama} and M. {Uemura} and I. {Fujishiro}},
booktitle={Proceedings of 2018 IEEE Scientific Visualization Conference},
title={TimeTubes: Automatic Extraction of Observable Blazar Features from Long-Term, Multi-Dimensional Datasets},
year={2018},
pages={67-71},
keywords={data analysis;data visualisation;feature extraction;image motion analysis;quasars;spatiotemporal phenomena;relativistic jet;attractive objects;blazars;multidimensional datasets;observable blazar features;automatic extraction;characteristic spatiotemporal subspaces;astronomers;feature extraction;biased analysis;long-term datasets;data analysis;3D volumetric tube;called TimeTubes;visualization scheme;multidimensional time-dependent;characteristic temporal variation patterns;Feature extraction;Data visualization;Electron tubes;Image color analysis;Time series analysis;Visualization;Three-dimensional displays;Human-centered computing;Visualization;Visualization application domains;Scientific visualization;Empirical studies in visualization},
doi={10.1109/SciVis.2018.8823802},
}

@inproceedings{Palshikar2009,
abstract = {Identifying and analyzing peaks (or spikes) in a given time-series is important in many applications. Peaks indicate significant events such as sudden increase in price/volume, sharp rise in demand, bursts in data traffic etc. While it is easy to visually identify peaks in a small univariate time-series, there is a need to formalize the notion of a peak to avoid subjectivity and to devise algorithms to automatically detect peaks in any given time-series. The latter is important in applications such as data center monitoring where thousands of large time-series indicating CPU/memory utilization need to be analyzed in real-time. A data point in a time-series is a local peak if (a) it is a large and locally maximum value within a window, which is not necessarily large nor globally maximum in the entire time-series; and (b) it is isolated i.e., not too many points in the window have similar values. Not all local peaks are true peaks; a local peak is a true peak if it is a reasonably large value even in the global context. We offer different formalizations of the notion of a peak and propose corresponding algorithms to detect peaks in the given time-series. We experimentally compare the effectiveness of these algorithms.},
author = {Palshikar, Girish Keshav},
booktitle = {Proceedings of 1st International Conference on Advanced Data Analysis, Business Analytics and Intelligence},
doi = {10.1109/IEMBS.2002.1134453},
file = {:Users/nsawada/Google Drive/Papers/Simple Algorithms for Peak Detection in Time-Series.pdf:pdf},
isbn = {0-7803-7612-9},
pages = {1--13},
title = {{Simple algorithms for peak detection in time-series}},
year = {2009}
}
@inproceedings{Igarashi2016,
abstract = {An interactive method for segmentation and isosurface extraction of medical volume data is proposed. In conventional methods, users decompose a volume into multiple regions iteratively, segment each region using a threshold, and then manually clean the segmentation result by removing clutter in each region. However, this is tedious and requires many mouse operations from different camera views. We propose an alternative approach whereby the user simply applies painting operations to the volume using tools commonly seen in painting systems, such as flood fill and brushes. This significantly reduces the number of mouse and camera control operations. Our technical contribution is in the introduction of the threshold field, which assigns spatially-varying threshold values to individual voxels. This generalizes discrete decomposition of a volume into regions and segmentation using a constant threshold in each region, thereby offering a much more flexible and efficient workflow. This paper describes the details of the user interaction and its implementation. Furthermore, the results of a user study are discussed. The results indicate that the proposed method can be a few times faster than a conventional method.},
author = {Igarashi, Takeo and Shono, Naoyuki and Kin, Taichi and Saito, Toki},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
doi = {10.1145/2984511.2984537},
file = {:Users/nsawada/Google Drive/Papers/Interactive Volume Segmentation with Threshold Field Painting.pdf:pdf;:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Igarashi et al. - 2016 - Interactive volume segmentation with threshold field painting.pdf:pdf},
isbn = {9781450345316},
keywords = {Medical imaging,Volume segmentation},
pages = {403--413},
title = {{Interactive volume segmentation with threshold field painting}},
year = {2016}
}
@inproceedings{Owada2005,
abstract = {It is difficult to obtain a specific region within unsegmented volume data (region of interest, ROI). The user must first segment the volume, a task which itself involves significant user intervention, and then chooses a desired target within the 3D space. This paper proposes a simple and intuitive user interface for the task: the user traces the contour of the target region using a 2D free form stroke on the screen, and the system instantly returns a plausible 3D region inside the stroke by applying a segmentation algorithm. The main contribution is that the system infers the depth information of the ROI automatically by analyzing the data, whereas existing systems require the user to provide the depth information explicitly. Our system first computes the 3D location of the user-specified 2D stroke based on the assumption that the user traced the silhouette of the ROI, that is, the curve where the gradient is perpendicular to the viewing direction. The system then places constraint points around the 3D stroke to guide the following segmentation. Foreground constraints are placed inside the stroke and background constraints are placed outside the stroke. We currently use the statistical region-merging algorithm of Nock et al. [Nock and Nielsen 2004a] to perform the segmentation. We tested our system with real-world examples to verify the effectiveness of our approach. {\textcopyright} 2005 ACM.},
author = {Owada, Shigeru and Nielsen, Frank and Igarashi, Takeo},
booktitle = {Proceedings of the Symposium on Interactive 3D Graphics},
doi = {10.1145/1053427.1053445},
file = {:Users/nsawada/Google Drive/Papers/Volume catcher.pdf:pdf},
isbn = {1595930132},
keywords = {Segmentation,User interface,Volume graphics},
pages = {111--116},
title = {{Volume catcher}},
year = {2005}
}
@inproceedings{Ratanamahatana2004,
author = {Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
booktitle = {Proceedings of the Third Workshop on Mining Temporal and Sequential Data},
file = {:Users/nsawada/Google Drive/Papers/DTW{\_}myths.pdf:pdf},
keywords = {data mining,dynamic time warping,experimentation},
pages = {32:1--32:11},
title = {{Everything you know about Dynamic Time Warping is wrong}},
year = {2004}
}
@article{Gillian2011,
abstract = {This paper presents a novel algorithm that has been specif-ically designed for the recognition of multivariate tempo-ral musical gestures. The algorithm is based on Dynamic Time Warping and has been extended to classify any N -dimensional signal, automatically compute a classification threshold to reject any data that is not a valid gesture and be quickly trained with a low number of training examples. The algorithm is evaluated using a database of 10 temporal gestures performed by 10 participants achieving an average cross-validation result of 99{\%}.},
author = {Gillian, Nicholas and Knapp, R Benjamin and {O 'modhrain}, Sile},
file = {:Users/nsawada/Google Drive/Papers/Recognition Of Multivariate Temporal Musical Gestures using n-dimensional dynamic time warping.pdf:pdf},
issn = {2220-4806},
journal = {Nime},
keywords = {Dynamic Time Warping,Gesture Recognition,Multivariate Temporal Gestures,Musician-Computer Interaction},
number = {June},
pages = {337--342},
title = {{Recognition Of Multivariate Temporal Musical Gestures Using N-Dimensional Dynamic Time Warping}},
year = {2011}
}
@article{Shokoohi-Yekta2015,
abstract = {Abstract In the last decade, Dynamic Time Warping (DTW) has emerged as the distance measure of choice for virtually all time series data mining applications. This is the result of significant progress in improving DTW's efficiency, and multiple empirical studies showing ...$\backslash$n},
author = {Shokoohi-Yekta, Mohammad and Wang, Jun and Keogh, Eamonn},
file = {:Users/nsawada/Google Drive/Papers/On the Non-Trivial Generalization of Dynamic Time Warping to the Multi-Dimensional Case.pdf:pdf},
isbn = {9781510811522},
journal = {SIAM International Conference on Data Mining 2015},
keywords = {Classification,Dynamic Time Warping},
pages = {289--297},
title = {{On the non-trivial generalization of Dynamic Time Warping to the multi-dimensional case}},
year = {2015}
}
@article{Sacha2017,
abstract = {{\textcopyright} 2016 IEEE. Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a 'human in the loop' process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.},
author = {Sacha, Dominik and Zhang, Leishi and Sedlmair, Michael and Lee, John A. and Peltonen, Jaakko and Weiskopf, Daniel and North, Stephen C. and Keim, Daniel A.},
doi = {10.1109/TVCG.2016.2598495},
file = {:Users/nsawada/Google Drive/Papers/Visual Interaction with Dimensionality Reduction A Structured Literature Analysis.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Interactive visualization,dimensionality reduction,machine learning,visual analytics},
number = {1},
pages = {241--250},
title = {{Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis}},
volume = {23},
year = {2017}
}
@article{Wilkinson2018,
abstract = {Visualizing outliers in massive datasets requires statistical pre-processing in order to reduce the scale of the problem to a size amenable to rendering systems like D3, Plotly or analytic systems like R or SAS. This paper presents a new algorithm, called hdoutliers, for detecting multidimensional outliers. It is unique for a) dealing with a mixture of categorical and continuous variables, b) dealing with big-p (many columns of data), c) dealing with big-n (many rows of data), d) dealing with outliers that mask other outliers, and e) dealing consistently with unidimensional and multidimensional datasets. Unlike ad hoc methods found in many machine learning papers, hdoutliers is based on a distributional model that allows outliers to be tagged with a probability. This critical feature reduces the likelihood of false discoveries.},
author = {Wilkinson, Leland},
doi = {10.1109/TVCG.2017.2744685},
file = {:Users/nsawada/Google Drive/Papers/Visualizing Big Data Outliers Through Distributed Aggregation.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Anomalies,Outliers},
number = {1},
pages = {256--266},
publisher = {IEEE},
title = {{Visualizing Big Data Outliers Through Distributed Aggregation}},
volume = {24},
year = {2018}
}
@article{Simunic2003,
abstract = {With this work in progress we propose a visualization system for stock market charts. Insight into stock charts is important in technical stock market analysis where exclusively the chart shape is considered in decision making. We focus on clustering existing chart shapes. Clustering delivers representative charts representing a set of similar charts. In our work, we generate a 2D map of these representative charts and implement tools like zooming, levels of details and selection. Thus, we present a new approach of automatically generating the whole picture of the stock market dynamics.},
author = {Simunic, K},
file = {:Users/nsawada/Google Drive/Papers/Visualization of Stock Market Charts.pdf:pdf},
isbn = {80-903100-2-8},
journal = {Som},
keywords = {a selection of 3-4,charts from each industry,information visualization,multi-dimensional visualization,of the most promising,selection of 10-20 stock,stock market,stocks in,technical chart analysis},
pages = {129--132},
title = {{Visualization of stock market charts}},
year = {2003}
}
@inproceedings{Simunic2003a,
abstract = {With this work in progress we propose a visualization system for stock market charts. Insight into stock charts is important in technical stock market analysis where exclusively the chart shape is considered in decision making. We focus on clustering existing chart shapes. Clustering delivers representative charts representing a set of similar charts. In our work, we generate a 2D map of these representative charts and implement tools like zooming, levels of details and selection. Thus, we present a new approach of automatically generating the whole picture of the stock market dynamics.},
author = {Simunic, Kresimir},
booktitle = {Proceedings of International Conference in Central Europe on Computer Graphics},
file = {:Users/nsawada/Google Drive/Papers/Visualization of Stock Market Charts.pdf:pdf},
isbn = {80-903100-2-8},
keywords = {a selection of 3-4,charts from each industry,information visualization,multi-dimensional visualization,of the most promising,selection of 10-20 stock,stock market,stocks in,technical chart analysis},
pages = {129--132},
title = {{Visualization of stock market charts}},
year = {2003}
}
@inproceedings{Shokoohi-Yekta2015a,
abstract = {Abstract In the last decade, Dynamic Time Warping (DTW) has emerged as the distance measure of choice for virtually all time series data mining applications. This is the result of significant progress in improving DTW's efficiency, and multiple empirical studies showing ...$\backslash$n},
author = {Shokoohi-Yekta, Mohammad and Wang, Jun and Keogh, Eamonn},
booktitle = {Proceedings of the 2015 2015},
doi = {10.1137/1.9781611974010.33},
file = {:Users/nsawada/Google Drive/Papers/On the Non-Trivial Generalization of Dynamic Time Warping to the Multi-Dimensional Case.pdf:pdf},
isbn = {9781510811522},
keywords = {Classification,Dynamic Time Warping},
pages = {289--297},
title = {{On the non-trivial generalization of Dynamic Time Warping to the multi-dimensional case}},
year = {2015}
}
@inproceedings{Gillian2011a,
abstract = {This paper presents a novel algorithm that has been specif-ically designed for the recognition of multivariate tempo-ral musical gestures. The algorithm is based on Dynamic Time Warping and has been extended to classify any N -dimensional signal, automatically compute a classification threshold to reject any data that is not a valid gesture and be quickly trained with a low number of training examples. The algorithm is evaluated using a database of 10 temporal gestures performed by 10 participants achieving an average cross-validation result of 99{\%}.},
author = {Gillian, Nicholas and Knapp, R Benjamin and {O 'modhrain}, Sile},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
file = {:Users/nsawada/Google Drive/Papers/Recognition Of Multivariate Temporal Musical Gestures using n-dimensional dynamic time warping.pdf:pdf},
issn = {2220-4806},
keywords = {Dynamic Time Warping,Gesture Recognition,Multivariate Temporal Gestures,Musician-Computer Interaction},
pages = {337--342},
title = {{Recognition of multivariate temporal musical gestures using N-dimensional Dynamic Time Warping}},
year = {2011}
}
@article{Sacha2017a,
abstract = {{\textcopyright} 2016 IEEE. Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a 'human in the loop' process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.},
author = {Sacha, Dominik and Zhang, Leishi and Sedlmair, Michael and Lee, John A. and Peltonen, Jaakko and Weiskopf, Daniel and North, Stephen C. and Keim, Daniel A.},
doi = {10.1109/TVCG.2016.2598495},
file = {:Users/nsawada/Google Drive/Papers/Visual Interaction with Dimensionality Reduction A Structured Literature Analysis.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Interactive visualization,dimensionality reduction,machine learning,visual analytics},
number = {1},
pages = {241--250},
title = {{Visual interaction with dimensionality reduction: A structured literature analysis}},
volume = {23},
year = {2017}
}
@article{Wilkinson2018a,
abstract = {Visualizing outliers in massive datasets requires statistical pre-processing in order to reduce the scale of the problem to a size amenable to rendering systems like D3, Plotly or analytic systems like R or SAS. This paper presents a new algorithm, called hdoutliers, for detecting multidimensional outliers. It is unique for a) dealing with a mixture of categorical and continuous variables, b) dealing with big-p (many columns of data), c) dealing with big-n (many rows of data), d) dealing with outliers that mask other outliers, and e) dealing consistently with unidimensional and multidimensional datasets. Unlike ad hoc methods found in many machine learning papers, hdoutliers is based on a distributional model that allows outliers to be tagged with a probability. This critical feature reduces the likelihood of false discoveries.},
author = {Wilkinson, Leland},
doi = {10.1109/TVCG.2017.2744685},
file = {:Users/nsawada/Google Drive/Papers/Visualizing Big Data Outliers Through Distributed Aggregation.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
title = {{Visualizing big data outliers through distributed aggregation}},
volume = {24},
year = {2018}
}
@inproceedings{Faloutsos1994a,
abstract = {We present an efficient indexing method to locate 1-dimensional subsequences within a collection of sequences, such that the subsequences match a given (query) pattern within a specified tolerance. The idea is to map each data sequences into a small set of multidimensional rectangles in feature space. Then, these rectangles can be readily indexed using traditional spatial access methods, like the R*-tree [9]. In more detail, we use a sliding window over the data sequence and extract its features; the result is a trail in feature space. We propose an efficient and effective algorithm to divide such trails into sub-trails, which are subsequently represented by their Minimum Bounding Rectangles (MBRs). We also examine queries of varying lengths, and we show how to handle each case efficiently. We implemented our method and carried out experiments on synthetic and real data (stock price movements). We compared the method to sequential scanning, which is the only obvious competitor. The results were excellent: our method accelerated the search time from 3 times up to 100 times.},
address = {New York, New York, USA},
author = {Faloutsos, Christos and Ranganathan, M. and Manolopoulos, Yannis and Faloutsos, Christos and Ranganathan, M. and Manolopoulos, Yannis},
booktitle = {Proceedings of the 1994 ACM SIGMOD international conference on Management of data},
doi = {10.1145/191839.191925},
file = {:Users/nsawada/Google Drive/Papers/Fast subsequence matching in time-series databases.pdf:pdf},
isbn = {0897916395},
number = {2},
pages = {419--429},
publisher = {ACM Press},
title = {{Fast subsequence matching in time-series databases}},
url = {http://portal.acm.org/citation.cfm?doid=191839.191925},
volume = {23},
year = {1994}
}
@article{Berndt1994a,
abstract = {Knowledge discovery in databases presents many interesting challenges within the context of providing computer tools for exploring large data archives. Electronic data repositories are growing qulckiy and contain data from commercial, scientific, and other domains. Much of this data is inherently temporal, such as stock prices or NASA telemetry data. Detecting patterns in such data streams or time series is an important knowledge discovery task. This paper describes some primary experiments with a dynamic programming approach to the problem. The pattern detection algorithm is based on the dynamic time warping technique used in the speech recognition field. Keywords: dynamic programming, dynamic time warping, knowledge discovery, pattern analysis, time series.},
author = {Berndt, Donald and Clifford, James},
file = {:Users/nsawada/Google Drive/Papers/Using Dynamic Time Warping to Find Patterns in Time Series.pdf:pdf},
isbn = {0-929280-73-3},
journal = {Workshop on Knowledge Knowledge Discovery in Databases},
keywords = {dynamic programming,dynamic time warping,knowledge discovery,pat,tern analysis,time series},
pages = {359--370},
title = {{Using dynamic time warping to find patterns in time series}},
url = {http://www.aaai.org/Papers/Workshops/1994/WS-94-03/WS94-03-031.pdf},
volume = {398},
year = {1994}
}
@article{Data2012,
abstract = {Abstract?Many flow visualization techniques, especially integration-based methods, are problematic when the measured data exhibit noise and discretization issues. Particularly, this is the case for flow-sensitive phase-contrast magnetic resonance imaging (PC-MRI) data sets which not only record anatomic information, but also time-varying flow information. We propose a novel approach for the visualization of such data sets using integration-based methods. Our ideas are based upon finite-time Lyapunov exponents (FTLE) and enable identification of vessel boundaries in the data as high regions of separation. This allows us to correctly restrict integration-based visualization to blood vessels. We validate our technique by comparing our approach to existing anatomy-based methods as well as addressing the benefits and limitations of using FTLE to restrict flow. We also discuss the importance of parameters, i.e., advection length and data resolution, in establishing a well-defined vessel boundary. We extract appropriate flow lines and surfaces that enable the visualization of blood flow within the vessels. We further enhance the visualization by analyzing flow behavior in the seeded region and generating simplified depictions.},
author = {Krishnan, Harinarayan and Garth, Christoph and G{\"{u}}hring, Jens and G{\"{u}}ls{\"{u}}n, Mehmet Akif and Greiser, Andreas and Joy, Kenneth I. and Data, Flow-sensitive Pc-mri and Gu, M Akif and Krishnan, Harinarayan and Garth, Christoph and Gu, Jens and Greiser, Andreas and Joy, Kenneth I. and Society, Ieee Computer},
doi = {http://doi.ieeecomputersociety.org/10.1109/TVCG.2011.80},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Krishnan et al. - 2012 - Analysis of time-dependent flow-sensitive PC-MRI data.pdf:pdf},
isbn = {1077-2626},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Flow analysis,flow-sensitive MRI,medical visualization,medical visualization.,surface extraction,time-varying and time-series visualization},
number = {6},
pages = {966--977},
pmid = {21519102},
title = {{Analysis of time-dependent flow-sensitive PC-MRI data}},
volume = {18},
year = {2012}
}
@article{Fu2008,
abstract = {The last few years have seen an increasing understanding that Dynamic Time Warping (DTW), a technique that allows local flexibil- ity in aligning time series, is superior to the ubiquitous Euclidean Distance for time series classification, clustering, and indexing. More recently, it has been shown that for some prob- lems, Uniform Scaling (US), a technique that allows global scaling of time series, may just be as important for some problems. In this work, we note that for many real world prob- lems, it is necessary to combine both DTW and US to achieve meaningful results. This is particularly true in domains where we must account for the natural variability of human action, including biometrics, query by hum- ming, motion-capture/animation, and hand- writing recognition. We introduce the first technique which can handle both DTW and US simultaneously, and demonstrate its utility and effectiveness on a wide range of problems in industry, medicine, and entertainment.},
annote = {combination of dtw and us},
author = {Fu, Ada Wai Chee and Keogh, Eamonn and Lau, Leo Yung Hang and Ratanamahatana, Chotirat Ann and Wong, Raymond Chi Wing},
doi = {10.1007/s00778-006-0040-z},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Fu et al. - 2008 - Scaling and time warping in time series querying.pdf:pdf},
issn = {10668888},
journal = {VLDB Journal},
keywords = {Dynamic time warping,Nearest neighbor search,Scaled and warped matching,Subsequence matching,Uniform scaling},
number = {4},
pages = {899--921},
title = {{Scaling and time warping in time series querying}},
volume = {17},
year = {2008}
}
@article{Jonsson2017,
abstract = {{\textcopyright} 2016 IEEE. We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40{\%}-50{\%}.},
author = {J{\"{o}}nsson, Daniel and Ynnerman, Anders},
doi = {10.1109/TVCG.2016.2598430},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Volume rendering,global illumination,participating media,photon mapping},
number = {1},
pages = {901--910},
title = {{Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data}},
volume = {23},
year = {2017}
}
@inproceedings{Bach2014,
abstract = {We reviewa range of temporal data visualization techniques through a newlens, by describing them as series of op- erations performed on a conceptual space-time cube. These operations include extracting subparts of a space-time cube, flattening it across space or time, or transforming the cube's geometry or content.We introduce a taxonomy of elementary space-time cube operations, and explain how they can be combined to turn a three-dimensional space-time cube into an easily-readable two-dimensional visualization. Our model captures most visualizations showing two or more data dimensions in addition to time, such as geotemporal visualizations, dynamic networks, time-evolving scatterplots, or videos. We finally review interactive systems that support a range of operations. By introducing this conceptual framework we hope to facilitate the description, criticism and comparison of existing temporal data visualizations, as well as encourage the exploration of new techniques and systems. Categories},
annote = {not related
review for spatial time-series data},
author = {Bach, B. and Dragicevic, P. and Archambault, D. and Hurter, C. and Carpendale, S.},
booktitle = {Eurographics Conference on Visualization},
doi = {10.2312/eurovisstar.20141171},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Bach et al. - 2014 - A review of temporal data visualizations based on space-time cube operations(4).pdf:pdf},
isbn = {-},
issn = {01677055},
keywords = {5,acm ccs,e,g,h,hci,information interfaces and presentation,information visualization,m,miscellaneous,network visualization,space-time cubes,temporal data,video visualization},
number = {00},
pages = {23--41},
title = {{A review of temporal data visualizations based on space-time cube operations}},
url = {http://diglib.eg.org/EG/DL/PE/EuroVisSTAR/EuroVisSTAR2014/023-041.pdf.abstract.pdf;internal{\&}action=action.digitallibrary.ShowPaperAbstract},
volume = {00},
year = {2014}
}
@article{Chair1986a,
abstract = {There is an increasing interest in employing multiple sensors for surveillance and communications. Some of the motivating factors are reliability, survivability, increase in the number of targets under consideration, and increase in required coverage. Tenney and Sandell have recently treated the Bayesian detection problem with distributed sensors. They did not consider the design of data fusion algorithms. We present an optimum data fusion structure given the detectors. Individual decisions are weighted according to the reliability of the detector and then a threshold comparison is performed to obtain the global decision.},
author = {Chair, Z. and Varshney, P. K.},
doi = {10.1109/TAES.1986.310699},
isbn = {0018-9251},
issn = {00189251},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
number = {1},
pages = {98--101},
title = {{Optimal data fusion in multiple sensor detection systems}},
volume = {AES-22},
year = {1986}
}
@article{Li2008,
abstract = {With recent advances in the measurement technology for allsky astrophysical imaging, our view of the sky is no longer limited to the tiny visible spectral range over the 2D Celestial sphere. We now can access a third dimension corresponding to a broad electromagnetic spectrum with a wide range of allsky surveys; these surveys span frequency bands including long wavelength radio, microwaves, very short X-rays, and gamma rays. These advances motivate us to study and examine multiwavelength visualization techniques to maximize our capabilities to visualize and exploit these informative image data sets. In this work, we begin with the processing of the data themselves, uniformizing the representations and units of raw data obtained from varied detector sources. Then we apply tools to map, convert, color-code, and format the multiwavelength data in forms useful for applications. We explore different visual representations for displaying the data, including such methods as textured image stacks, the horseshoe representation, and GPU-based volume visualization. A family of visual tools and analysis methods is introduced to explore the data, including interactive data mapping on the graphics processing unit (GPU), the mini-map explorer, and GPU-based interactive feature analysis.},
author = {Li, Hongwei and Fu, Chi-Wing and Hanson, Andrew J.},
doi = {10.1109/TVCG.2008.182},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Hongwei Li et al. - 2008 - Visualizing multiwavelength astrophysical data.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Astronomy,Astrophysical visualization,Multiwavelength data},
number = {6},
pages = {1555--1562},
pmid = {18989010},
title = {{Visualizing multiwavelength astrophysical data}},
volume = {14},
year = {2008}
}
@article{Landesberger2016,
author = {von Landesberger, Tatiana and Brodkorb, Felix and Roskosch, Philipp and Andrienko, Natalia},
doi = {10.1109/TVCG.2015.2468111},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Landesberger et al. - 2016 - Mobility Graphs Visual analysis of mass mobility dynamics via spatio-temporal graphs and clustering(2).pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {11--20},
title = {{Mobility Graphs: Visual analysis of mass mobility dynamics via spatio-temporal graphs and clustering}},
url = {http://apps.isiknowledge.com/full{\_}record.do?product=UA{\&}search{\_}mode=GeneralSearch{\&}qid=10{\&}SID=Z1pIMugVKe2yDt2Ciq9{\&}page=1{\&}doc=4},
volume = {22},
year = {2016}
}
@article{Burchett2019,
abstract = {We introduce IGM-Vis, a novel astrophysics visualization and data analysis application for investigating galaxies and the gas that surrounds them in context with their larger scale environment, the Cosmic Web. Environment is an important factor in the evolution of galaxies from actively forming stars to quiescent states with little, if any, discernible star formation activity. The gaseous halos of galaxies (the circumgalactic medium, or CGM) play a critical role in their evolution, because the gas necessary to fuel star formation and any gas expelled from widely observed galactic winds must encounter this interface region between galaxies and the intergalactic medium (IGM). We present a taxonomy of tasks typically employed in IGM/CGM studies informed by a survey of astrophysicists at various career levels, and demonstrate how these tasks are facilitated via the use of our visualization software. Finally, we evaluate the effectiveness of IGM-Vis through two in-depth use cases that depict real-world analysis sessions that use IGM/CGM data.},
author = {Burchett, J.N. N and Abramov, D. and Otto, J. and Artanegara, C. and Prochaska, J.X. X and Forbes, A.G. G},
doi = {10.1111/cgf.13705},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Burchett et al. - 2019 - IGM-Vis Analyzing Intergalactic and Circumgalactic Medium Absorption Using Quasar Sightlines in a Cosmic Web C.pdf:pdf},
issn = {0167-7055},
journal = {Computer Graphics Forum},
keywords = {Computer Graphics Forum,EUROGRAPHICS},
month = {jun},
number = {3},
pages = {491--504},
publisher = {John Wiley {\&} Sons, Ltd (10.1111)},
title = {{IGMâVis: Analyzing Intergalactic and Circumgalactic Medium Absorption Using Quasar Sightlines in a Cosmic Web Context}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13705},
volume = {38},
year = {2019}
}
@article{Arbesser2017a,
abstract = {VAST template ref. Good example of tool for users. $\backslash$r$\backslash$n$\backslash$r$\backslash$nâTrends like decentralized energy production lead to an exploding number of time series from sensors and other sources that need to be assessed regarding their data quality (DQ). While the identification of DQ problems for such routinely collected data is typically based on existing automated plausibility checks, an efficient inspection and validation of check results for hundreds or thousands of time series is challenging. The main contribution of this paper is the validated design of Visplause, a system to support an efficient inspection of DQ problems for many time series. The key idea of Visplause is to utilize meta-information concerning the semantics of both the time series and the plausibility checks for structuring and summarizing results of DQ checks in a flexible way. Linked views enable users to inspect anomalies in detail and to generate hypotheses about possible causes. The design of Visplause was guided by goals derived from a comprehensive task analysis with domain experts in the energy sector. We reflect on the design process by discussing design decisions at four stages and we identify lessons learned. We also report feedback from domain experts after using Visplause for a period of one month. This feedback suggests significant efficiency gains for DQ assessment, increased confidence in the DQ, and the applicability of Visplause to summarize indicators also outside the context of DQ.},
author = {Arbesser, Clemens and Spechtenhauser, Florian and Uhlbacher, Thomas and Piringer, Harald and Thomas, M$\backslash$"uhlbacher and Piringer, Harald},
doi = {10.1109/TVCG.2016.2598592},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Arbesser et al. - 2017 - Visplause Visual data quality assessment of many time series using plausibility checks.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Hierarchical Aggregation,High-Dimensional Data,Index TermsâData Quality Assessment,Linked Views},
number = {1},
pages = {641--650},
title = {{Visplause: Visual data quality assessment of many time series using plausibility checks}},
volume = {23},
year = {2017}
}
@inproceedings{TenHolt2007,
abstract = {Modern content-based image retrieval systems use different features to represent properties (e.g., color, shape, texture) of the visual content of an image. Retrieval is performed by example where a query image is given as input and an appropriate metric is used to find the best matches in the corresponding feature space. Both selecting the features and the distance metric continue to be active areas of research. In this paper, we propose a new approach, based on the recently proposed Multidimensional Dynamic Time Warping (MD-DTW) distance 1, for assessing the texture similarity of images with structured textures. The MD-DTW allows the detection and comparison of arbitrarily shifted patterns between multi-dimensional series, such as those found in structured textures. Chaos theory tools are used as a preprocessing step to uncover and characterize regularities in structured textures. The main advantage of the proposed approach is that explicit selection and extraction of texture features is not required (i.e., similarity comparisons are performed directly on the raw pixel data alone). The method proposed in this preliminary investigation is shown to be valid by proving that it creates a statistically significant image texture similarity measure.},
annote = {Dynamic time warping for multi dimensional data},
author = {{Ten Holt}, G a and Reinders, M J T and Hendriks, E a},
booktitle = {Proceedings of 13th annual conference of the Advanced School for Computing and Imaging},
doi = {10.1007/978-3-540-88190-2},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Ten Holt, Reinders, Hendriks - 2007 - Multi-Dimensional Dynamic Time Warping for Gesture Recognition.pdf:pdf},
isbn = {9783540881896},
issn = {03029743},
keywords = {dynamic time warping,multi dimensional time series,pattern recognition},
pages = {23--32},
title = {{Multi-dimensional dynamic time warping for gesture recognition}},
url = {http://ict.ewi.tudelft.nl/pub/gineke/DTW-vASCI.pdf},
volume = {5249},
year = {2007}
}
@article{Ostriker1997a,
annote = {From Duplicate 1 (Cosmology of the early universe viewed through the new infrastructure - Ostriker, Jeremiah P.; Norman, Michael L.)

From Duplicate 1 (Cosmology of the early universe viewed through the new infrastructure - Ostriker, Jeremiah P.; Norman, Michael L.)

proposed a framework for simulating cosmology and reviewed the related requirements in high performance computing environments

From Duplicate 2 (Cosmology of the early universe viewed through the new infrastructure - Ostriker, Jeremiah P.; Norman, Michael L.)

From Duplicate 1 (Cosmology of the early universe viewed through the new infrastructure - Ostriker, Jeremiah P.; Norman, Michael L.)

From Duplicate 1 (Cosmology of the early universe viewed through the new infrastructure - Ostriker, Jeremiah P.; Norman, Michael L.)

proposed a framework for simulating cosmology and reviewed the related requirements in high performance computing environments

From Duplicate 2 (Cosmology of the early universe viewed through the new infrastructure - Ostriker, Jeremiah P.; Norman, Michael L.)

proposed a framework for simulating cosmology and reviewed the related requirements in high performance computing environments},
author = {Ostriker, Jeremiah P. and Norman, Michael L.},
doi = {10.1145/265684.265695},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Ostriker, Norman - 1997 - Cosmology of the early universe viewed through the new infrastructure(2).pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = {nov},
number = {11},
pages = {84--94},
publisher = {ACM},
title = {{Cosmology of the early universe viewed through the new infrastructure}},
url = {http://portal.acm.org/citation.cfm?doid=265684.265695},
volume = {40},
year = {1997}
}
@article{Stitz2016,
abstract = {Multi-attribute time-series data plays a vital role in many different domains, such as economics, sensor networks, and biology. An important task when making sense of such data is to provide users with an overview to identify items that show an interesting development over time, including both absolute and relative changes in multiple attributes simultaneously. However, this is not well supported by existing visualization techniques. To address this issue, we present ThermalPlot, a visualization technique that summarizes combinations of multiple attributes over time using an items position, the most salient visual variable. More precisely, the x-position in the ThermalPlot is based on a user-defined degree-of-interest (DoI) function that combines multiple attributes over time. The y-position is determined by the relative change in the DoI value ( $\Delta$DoI) within a user-specified time window. Animating this mapping via a moving time window gives rise to circular movements of items over timeâas in thermal systems. To help the user to identify important items that match user-defined temporal patterns and to increase the technique's scalability, we adapt the level of detail of the items' representation based on the DoI value. Furthermore, we present an interactive exploration environment for multi-attribute time-series data that ties together a carefully chosen set of visualizations, designed to support analysts in interacting with the ThermalPlot technique. We demonstrate the effectiveness of our technique by means of two usage scenarios that address the visual analysis of economic development data and of stock market data.},
author = {Stitz, Holger and Gratzl, Samuel and Aigner, Wolfgang and Streit, Marc and Member, Student and Gratzl, Samuel and Member, Student},
doi = {10.1109/TVCG.2015.2513389},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Stitz et al. - 2016 - ThermalPlot Visualizing multi-attribute time-series data using a thermal metaphor(2).pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Focus+context,Multi-attribute data,Semantic zooming,Time-dependent data},
number = {12},
pages = {2594--2607},
publisher = {IEEE},
title = {{ThermalPlot: Visualizing multi-attribute time-series data using a thermal metaphor}},
volume = {22},
year = {2016}
}
@article{Meulemans2017a,
abstract = {Fig. 1: The effects of adding gaps (whitespace) to a small-multiples layout (blue squares) representing the 12 provinces of the Netherlands, measured via our suite of metrics. Each metric is represented by a colored line in the chart, indicating at each axis how well the layout below performs in the metric. The layout algorithm here optimizes for the displacement metricâwhich aims to preserve the spatial (geographic) distributionâas whitespace is increased from left to right. Although some metrics show improvement as gaps are added, others reflect the resulting smaller and more dispersed distribution, which may hinder comparison. AbstractâSmall multiples enable comparison by providing different views of a single data set in a dense and aligned manner. A common frame defines each view, which varies based upon values of a conditioning variable. An increasingly popular use of this technique is to project two-dimensional locations into a gridded space (e.g. grid maps), using the underlying distribution both as the conditioning variable and to determine the grid layout. Using whitespace in this layout has the potential to carry information, especially in a geographic context. Yet, the effects of doing so on the spatial properties of the original units are not understood. We explore the design space offered by such small multiples with gaps. We do so by constructing a comprehensive suite of metrics that capture properties of the layout used to arrange the small multiples for comparison (e.g. compactness and alignment) and the preservation of the original data (e.g. distance, topology and shape). We study these metrics in geographic data sets with varying properties and numbers of gaps. We use simulated annealing to optimize for each metric and measure the effects on the others. To explore these effects systematically, we take a new approach, developing a system to visualize this design space using a set of interactive matrices. We find that adding small amounts of whitespace to small multiple arrays improves some of the characteristics of 2D layouts, such as shape, distance and direction. This comes at the cost of other metrics, such as the retention of topology. Effects vary according to the input maps, with degree of variation in size of input regions found to be a factor. Optima exist for particular metrics in many cases, but at different amounts of whitespace for different maps. We suggest multiple metrics be used in optimized layouts, finding topology to be a primary factor in existing manually-crafted solutions, followed by a trade-off between shape and displacement. But the rich range of possible optimized layouts leads us to challenge single-solution thinking; we suggest to consider alternative optimized layouts for small multiples with gaps. Key to our work is the systematic, quantified and visual approach to exploring design spaces when facing a trade-off between many competing criteriaâan approach likely to be of value to the analysis of other design spaces.},
author = {Meulemans, Wouter and Dykes, Jason and Slingsby, Aidan and Turkay, Cagatay and Wood, Jo},
doi = {10.1109/TVCG.2016.2598542},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Geographic visualization,design space,metrics,optimization,small multiples,whitespace},
number = {1},
pages = {381--390},
title = {{Small Multiples with Gaps}},
volume = {23},
year = {2017}
}
@article{Wang2017a,
abstract = {â Analyzing high-dimensional data and finding hidden patterns is a difficult problem and has attracted numerous research efforts. Automated methods can be useful to some extent but bringing the data analyst into the loop via interactive visual tools can help the discovery process tremendously. An inherent problem in this effort is that humans lack the mental capacity to truly understand spaces exceeding three spatial dimensions. To keep within this limitation, we describe a framework that decomposes a high-dimensional data space into a continuum of generalized 3D subspaces. Analysts can then explore these 3D subspaces individually via the familiar trackball interface, but using additional facilities to smoothly transition to adjacent subspaces for expanded space comprehension. Since the number of such subspaces suffers from combinatorial explosion, we provide a set of data-driven subspace selection and navigation tools which can guide users to interesting subspaces and views. A subspace trail map allows users to manage the explored subspaces, and also helps them navigate within and across any higher-dimensional subspaces identified by clustering. Both trackball and trail map are each embedded into a word cloud of attribute labels, sized according to the relevance of the associated data dimensions in the currently selected subspace. Finally, a view gallery helps users keep their bearings and return to interesting subspaces and views. We demonstrate our system via several use cases in a diverse set of application areas, such as cluster analysis and refinement, information discovery, and supervised training of classifiers.},
author = {Wang, BingBN and Mueller, Klaus},
doi = {10.1109/TVCG.2017.2672987},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Mueller - 2018 - The Subspace Voyager Exploring high-dimensional data along a continuum of salient 3D subspaces.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {High-dimensional data,Index Termsâ High-dimensional data,PCA,ant colony optimization,ant colony optimization1,subspace navigation,trackball},
month = {feb},
number = {2},
pages = {1204--1222},
title = {{The Subspace Voyager: Exploring high-dimensional data along a continuum of salient 3D subspaces}},
url = {http://ieeexplore.ieee.org/document/7862917/},
volume = {24},
year = {2018}
}
@article{Stolte2011,
abstract = {ÃIn the last several years, large multidimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. In this paper, we present Polaris, an interface for exploring large multidimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table-based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations.},
annote = {Present Polaris, which is an interface for exploring multidimensional relational databases
Relational databases organize data into tables},
author = {Stolte, Chris and Hanrahan, Pat},
doi = {10.1109/INFVIS.2000.885086},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Stolte, Hanrahan - 2011 - Polaris A system for query, analysis and visualization of multi-dimensional relational databases.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Index TermsÃDatabase visualization,Pivot Table interface,Polaris,Polarization,Relational databases,Visualization,complex queries,data sets,data visualisation,database analysis,dense graphical representations,exploration tasks,formal specification,interactive systems,large multi-dimensional databases,multi-dimensional relational database visualizatio,multidimensional databases,query processing,relational databases,relational queries,table based graphical displays,user interface,user interfaces,very large databases,visual feedback,visual specifications,visualization formalism},
number = {1},
pages = {75--84},
title = {{Polaris: A system for query, analysis and visualization of multi-dimensional relational databases}},
url = {http://www.cise.ufl.edu/class/cis6930fa11lad/cis6930fa11{\_}Polaris.pdf},
volume = {8},
year = {2011}
}
@article{Holten2006,
abstract = {A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations.},
annote = {From Duplicate 1 (Hierarchical edge bundles: Visualization of adjacency relations in hierarchical data - Holten, Danny)

Related to project! (related work)
not straightforward way to show adjacency edges in conjunction with existing tree visualization techniques},
author = {Holten, Danny},
doi = {10.1109/TVCG.2006.147},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Holten - 2006 - Hierarchical edge bundles Visualization of adjacency relations in hierarchical data(2).pdf:pdf},
isbn = {1077-2626 VO - 12},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Curves,Edge aggregation,Edge bundling,Edge concentration,Graph visualization,Hierarchies,Network visualization,Node-link diagrams,Tree visualization,Treemaps},
month = {sep},
number = {5},
pages = {741--748},
pmid = {17080795},
publisher = {IEEE},
title = {{Hierarchical edge bundles: Visualization of adjacency relations in hierarchical data}},
url = {http://ieeexplore.ieee.org/document/4015425/},
volume = {12},
year = {2006}
}
@article{Kahler2002a,
abstract = {For quantitative examination of phenomena that simultaneously occur on very different spatial and temporal scales, adaptive hierarchical schemes are required. A special numerical multilevel technique, associated with a particular hierarchical data structure, is so-called Adaptive Mesh Refinement (AMR). It allows one to bridge a wide range of spatial and temporal resolutions and therefore gains increasing popularity. We describe the interplay of several visualization and VR software packages for rendering time dependent AMR simulations of the evolution of the first star in the universe. The work was done in the framework of a television production for DISCOVERY CHANNEL TELEVISION, "The Unfolding Universe." Parts of the data were taken from one of the most complex AMR simulation ever carried out: It contained up to 27 levels of resolution, requiring modifications to the texture based AMR volume rendering algorithm that was used to depict the density distribution of the gaseous interstellar matter. A voice and gesture controlled CAVE application was utilized to define camera paths following the interesting features deep inside the computational domains. Background images created from cosmological computational data were combined with the final renderings.},
author = {Kahler, R. and Cox, Donna and Patterson, Robert and Levy, Stuart and Hege, Hans Christian H.-C. and Abel, Tom and K{\"{a}}hler, Ralf and Cox, Donna and Patterson, Robert and Levy, Stuart and Hege, Hans Christian H.-C. and Abel, Tom},
doi = {10.1109/VISUAL.2002.1183824},
isbn = {0-7803-7498-3},
journal = {Proceedings of the IEEE Visualization Conference},
keywords = {3D texture based volume rendering,Adaptive mesh refinement data,CAVE applications,Data visualization},
pages = {537--540},
publisher = {IEEE},
title = {{Rendering the first star in the Universe - A case study}},
url = {http://ieeexplore.ieee.org/document/1183824/},
year = {2002}
}
@article{Walker2016,
abstract = {{\textcopyright} 1995-2012 IEEE. Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. Onedimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques.},
annote = {Evaluation paper {\&} design paper
Graphical survey for visualizations for time-series data and propose a new visualization named TimeNotes, which allows effective approach for time-series data with chart visualizations and interactions},
author = {Walker, James and Borgo, Rita and Jones, Mark W.},
doi = {10.1109/TVCG.2015.2467751},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Walker, Borgo, Jones - 2016 - TimeNotes A study on effective chart visualization and interaction techniques for time-series data(6).pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Context,Data mining,Data visualization,Layout,Lenses,Rivers,Visualization},
number = {1},
pages = {549--558},
pmid = {26390489},
publisher = {IEEE},
title = {{TimeNotes: A study on effective chart visualization and interaction techniques for time-series data}},
volume = {22},
year = {2016}
}
@article{Chan1999,
abstract = {Time series stored as feature vectors can be indexed by$\backslash$nmultidimensional index trees like R-Trees for fast retrieval. Due to the$\backslash$ndimensionality curse problem, transformations are applied to time series$\backslash$nto reduce the number of dimensions of the feature vectors. Different$\backslash$ntransformations like Discrete Fourier Transform (DFT) Discrete Wavelet$\backslash$nTransform (DWT), Karhunen-Loeve (KL) transform or Singular Value$\backslash$nDecomposition (SVD) can be applied. While the use of DFT and K-L$\backslash$ntransform or SVD have been studied on the literature, to our knowledge,$\backslash$nthere is no in-depth study on the application of DWT. In this paper we$\backslash$npropose to use Haar Wavelet Transform for time series indexing. The$\backslash$nmajor contributions are: (1) we show that Euclidean distance is$\backslash$npreserved in the Haar transformed domain and no false dismissal will$\backslash$noccur, (2) we show that Haar transform can outperform DFT through$\backslash$nexperiments, (3) a new similarity model is suggested to accommodate$\backslash$nvertical shift of time series, and (4) a two-phase method is proposed$\backslash$nfor efficient n-nearest neighbor query in time series databases},
annote = {Related
Discrete expressions of time series, propose to use Haar Wavelet Transform for time series indexing
Suggest a similarity definition to handle the problem of vertical shifts of time series, propose an algorithm on n-nearest neighbor for the proposed wavelet method

In this paper, an efficient time series matching technique 
through dimension reduction by Haar Wavelet Transform is pro- 
posed},
author = {pong Chan, Kin-pong and chee Fu, Ada Wai-chee},
doi = {10.1109/ICDE.1999.754915},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Chan, Fu - 1999 - Efficient time series matching by wavelets.pdf:pdf},
journal = {Proceedings - International Conference on Data Engineering},
pages = {126--133},
publisher = {IEEE},
title = {{Efficient time series matching by wavelets}},
year = {1999}
}
@inproceedings{Berndt1994,
abstract = {Knowledge discovery in databases presents many interesting challenges within the context of providing computer tools for exploring large data archives. Electronic data repositories are growing qulckiy and contain data from commercial, scientific, and other domains. Much of this data is inherently temporal, such as stock prices or NASA telemetry data. Detecting patterns in such data streams or time series is an important knowledge discovery task. This paper describes some primary experiments with a dynamic programming approach to the problem. The pattern detection algorithm is based on the dynamic time warping technique used in the speech recognition field. Keywords: dynamic programming, dynamic time warping, knowledge discovery, pattern analysis, time series.},
annote = {Pattern finding of time series based on dynamic time warping},
author = {Bemdt, Donald J and Berndt, Donald J. and Clifford, James},
booktitle = {Proceedings of Workshop on Knowledge Discovery in Databases},
file = {:Users/nsawada/Google Drive/Papers/Using Dynamic Time Warping to Find Patterns in Time Series.pdf:pdf},
isbn = {0-929280-73-3},
keywords = {dynamic programming,dynamic time warping,knowledge discovery,pat-,tern analysis,time series},
pages = {359--370},
title = {{Using dynamic time warping to find patterns in time series}},
volume = {398},
year = {1994}
}
@article{Weber2001a,
abstract = {In this paper, we present a new approach for the visualization of time-series data based on spirals. Different to classical bar charts and line graphs, the spiral is suited to visualize large data sets and supports much better the identification of periodic structures in the data. Moreover, it supports both the visualization of nominal and quantitative data based on a similar visualization metaphor. The extension of the spiral visualization to 3D gives access to concepts for zooming and focusing and linking in the data set. As such, spirals complement other visualization techniques for time series and specifically enhance the identification of periodic patterns.},
author = {Weber, M. and Alexa, M. and M{\"{u}}ller, W.},
journal = {Proceedings of the IEEE Symposium on Information Visualization},
keywords = {Data mining,Graph drawing,Information visualization,Visualization of time-series data},
pages = {7--13},
title = {{Visualizing time-series on spirals}},
year = {2001}
}
@article{Tanaka2005,
abstract = {Recently, the research on efficient extraction of previously unknown, frequently appearing patterns in a time-series data has received much attention. These patterns are called âmotifs'. Motifs are useful for various time-series data mining tasks. In this paper,wepropose a motif discovery algorithm to extract a motif that represents a characteristic pattern of the given data based on Minimum Description Length (MDL) principle. In addition, the algorithm can extract motifs from multi-dimensional time-series data by using Principal Component Analysis (PCA). In experimental evaluation, we show the efficiency of the motif discovery algorithm, and the usefulness of extracted motifs to various data mining tasks.},
annote = {Pattern finding using PCA
In this paper, we propose a motif discovery algorithm to extract a motif that represents 
a characteristic pattern of the given data based on Minimum Description Length (MDL) principle},
author = {Tanaka, Yoshiki and Iwamoto, Kazuhisa and Uehara, Kuniaki},
doi = {10.1007/s10994-005-5829-2},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Tanaka, Iwamoto, Uehara - 2005 - Discovery of time-series motif from multi-dimensional data based on MDL principle.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {MDL principle good,Multi-dimensional time-series data,PCA,Time-series motifs},
number = {2-3},
pages = {269--300},
title = {{Discovery of time-series motif from multi-dimensional data based on MDL principle}},
volume = {58},
year = {2005}
}
@article{Uemura2016,
abstract = {Optical polarization provides important clues to the magnetic field in blazar jets. It is easy to find noteworthy patterns in the time-series data of the polarization degree (PD) and position angle (PA). On the other hand, we need to see the trajectory of the object in the Stokes Q U plane when the object has multiple polarized components. In this case, ironically, the more data we have, the more difficult it is to gain any knowledge from it. Here, we introduce TimeTubes, a new visualization scheme to explore the time-series data of polarization observed in blazars. In TimeTubes, the data is represented by tubes in 3D (Q, U, and time) space. The measurement errors of Q and U, color, and total flux of objects are expressed as the size, color, and brightness of the tubes. As a result, TimeTubes allows us to see the behavior of six variables in one view. We used TimeTubes for our data taken by the Kanata telescope between 2008 and 2014. We found that this tool facilitates the recognition of the patterns in blazar variations; for example, favored PA of flares and PA rotations associated with a series of flares.},
author = {Uemura, Makoto and Itoh, Ryosuke and Xu, Longyin and Nakayama, Masanori and Wu, Hsiang-Yun and Watanabe, Kazuho and Takahashi, Shigeo and Fujishiro, Issei},
doi = {10.3390/galaxies4030023},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Uemura et al. - 2016 - TimeTubes Visualization of polarization variations in blazars(3).pdf:pdf},
journal = {Galaxies},
keywords = {optical polarization,visualization},
number = {3},
pages = {23:1--23:9},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{TimeTubes: Visualization of polarization variations in blazars}},
volume = {4},
year = {2016}
}
@article{Obermaier2016,
abstract = {{\textcopyright} 2016 IEEE.Visualization and analysis techniques play a key role in the discovery of relevant features in ensemble data. Trends, in the form of persisting commonalities or differences in time-varying ensemble datasets, constitute one of the most expressive feature types in ensemble analysis. We develop a flow-graph representation as the core of a system designed for the visual analysis of trends in time-varying ensembles. In our interactive analysis framework, this graph is linked to a representation of ensemble parameter-space and the ensemble itself. This facilitates a detailed examination of trends and their correlations to properties of input-space. We demonstrate the utility of the proposed trends analysis framework in several benchmark data sets, highlighting its capability to support goal-driven design of time-varying simulations.},
author = {Obermaier, Harald and Bensema, Kevin and Joy, Kenneth I.},
doi = {10.1109/TVCG.2015.2507592},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Obermaier, Bensema, Joy - 2016 - Visual trends analysis in time-varying ensembles(3).pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Ensemble visualization,data analysis,trend visualization},
number = {10},
pages = {2331--2342},
title = {{Visual trends analysis in time-varying ensembles}},
volume = {22},
year = {2016}
}
@article{Coogan2013a,
abstract = {Traffic on Indian roads (both urban and inter-urban) consists of a variety of vehicles. These vehicles have widely different static and dynamic characteristics. The traffic is also very different from homogeneous traffic which primarily consists of motorized vehicles. Homogeneous traffic follows strict lane discipline as compared to non-homogeneous traffic. Western traffic planning methodologies mostly address the concerns of homogeneous traffic and therefore often prove inadequate in solving problems involving non-homogeneous traffic conditions as found in Indian cities. This paper presents studies conducted on non-homogeneous traffic. Section 1 presents a methodology to verify the continuity equation, the basic block of any traffic planning analysis. In 2, the methodology developed is applied to modify the Highway Capacity Manual (HCM) 2000 density method to derive passengercar equivalencies (PCEs) or units (PCUs) for heavy vehicles and recreational vehicles. These PCUs appear as 'ET' and 'ER' in HCM tables. The density method assumes motorized, four-wheeler traffic, i.e., homogeneous traffic, and does not include motorized three-wheelers, motorized two-wheelers, and non-motorized traffic often present on Indian highways. By modifying the density method to represent non-homogeneous traffic, which includes significant percentages of motorized, three-wheelers, motorized two-wheelers, and non-motorized traffic entities, one can derive more accurate passenger car units for Indian conditions. Transport professionals can use these PCU values for accurate capacity, safety, and operational analysis of highways carrying non-homogeneous traffic.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Coogan, Samuel and Arcak, Murat and Fallis, A.G and Illner, Reinhard and Mcgregor, Geoffrey and Scheepens, Roeland and Hurter, Christophe and Wetering, Huub Van De and Wijk, Jarke J Van and Tiwari, Geetam and Fazio, Joseph and Gaurav, Sushant and Yin, Derek and Qiu, Tony Z},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Coogan et al. - 2013 - Visualization, selection, and analysis of traffic flows(2).pdf:pdf},
isbn = {0256-2499},
issn = {02562499},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Modified density method,Non-homogeneous traffic,Non-motorized traffic,Passenger-car units,Traffic simulation,avec pr{\'{e}}cision,compatibility analysis,d,de,de la circulation pour,densit{\'{e}} doivent {\^{e}}tre pr{\'{e}}dites,d{\'{e}}bit pr{\'{e}}dits,flow models,functional-differential,icle,kinetic and macroscopic traffic,la densit{\'{e}} et le,la pr{\'{e}}vision en ligne,la vitesse,la vitesse et la,le pr{\'{e}}sent article compare,les variables de l,macroscopic simulation,macroscopique,microscopic simulation,mod{\`{e}}le pr{\'{e}}dictif du contr{\^{o}}le,on veut implanter un,pour {\'{e}}valuer la pr{\'{e}}cision,r{\'{e}}duire la congestion,r{\'{e}}sum{\'{e}},si l,stop and go,telles que le d{\'{e}}bit,time step length,traffic model,traveling waves,un mod{\`{e}}le de circulation,{\'{e}}tat de la circulation},
number = {1},
pages = {379--388},
pmid = {25246403},
title = {{Visualization, selection, and analysis of traffic flows}},
volume = {22},
year = {2013}
}
@article{Andrienko2016,
abstract = {Origin-destination (OD) movement data describe moves or trips between spatial locations by specifying the origins, destinations, start, and end times, but not the routes travelled. For studying the spatio-temporal patterns and trends of mass mobility, individual OD moves of many people are aggregated into flows (collective moves) by time intervals. Time-variant flow data pose two difficult challenges for visualization and analysis. First, flows may connect arbitrary locations (not only neighbors), thus making a graph with numerous edge intersections, which is hard to visualize in a comprehensible way. Even a single spatial situation consisting of flows in one time step is hard to explore. The second challenge is the need to analyze long time series consisting of numerous spatial situations. We present an approach facilitating exploration of long-term flow data by means of spatial and temporal abstraction. It involves a special way of data aggregation, which allows representing spatial situations by diagram maps instead of flow maps, thus reducing the intersections and occlusions pertaining to flow maps. The aggregated data are used for clustering of time intervals by similarity of the spatial situations. Temporal and spatial displays of the clustering results facilitate the discovery of periodic patterns and longer-term trends in the mass mobility behavior.},
author = {Andrienko, Gennady and Andrienko, Natalia and Fuchs, Georg and Wood, Jo},
doi = {10.1109/TVCG.2016.2616404},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Andrienko et al. - 2016 - Revealing patterns and trends of mass mobility through spatial and temporal abstraction of origin-destinati(4).pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Movement data,flow map,mobility behavior,spatial flow situation},
number = {9},
pages = {1--1},
title = {{Revealing patterns and trends of mass mobility through spatial and temporal abstraction of origin-destination movement data}},
url = {http://ieeexplore.ieee.org/document/7587808/},
volume = {23},
year = {2016}
}
@inproceedings{Correll2016,
author = {Correll, Michael and Gleicher, Michael},
booktitle = {Proceedings of the 2016 IEEE Conference on Visual Analytics Science and Technology},
doi = {10.1109/VAST.2016.7883519},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Correll, Gleicher - 2016 - The semantics of sketch A visual query system for time series data(2).pdf:pdf},
isbn = {9781509056613},
pages = {131--140},
title = {{The semantics of sketch: A visual query system for time series data}},
year = {2016}
}
@article{Huang2015,
abstract = {We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph's capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis.},
author = {Huang, Xiaoke and Zhao, Ye and Ma, Chao and Yang, Jing and Ye, Xinyue},
doi = {10.1109/TVCG.2015.2467771},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Huang et al. - 2015 - TrajGraph A graph-based visual analytics approach to studying(2).pdf:pdf},
isbn = {1077-2626},
issn = {1077-2626},
journal = {IEEE Visualization Conference},
number = {c},
pages = {1--1},
pmid = {26529696},
title = {{TrajGraph: A graph-based visual analytics approach to studying}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7192687},
volume = {2626},
year = {2015}
}
@article{Song2019,
abstract = {Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.},
annote = {From Duplicate 2 (Where's my data? Evaluating visualizations with missing data - Song, Hayeong; Szafir, Danielle Albers)

Highly related!!! Well done evaluation paper! Cook book for writing evaluation paper!
Cloud sourcing paper},
author = {Song, Hayeong and Szafir, Danielle Albers},
doi = {10.1109/TVCG.2018.2864914},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Song, Szafir - 2019 - Where's my data Evaluating visualizations with missing data.pdf:pdf},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data Wrangling,Graphical Perception,Imputation,Information Visualization,Time Series Data},
month = {jan},
number = {1},
pages = {914--924},
publisher = {IEEE},
title = {{Where's my data? Evaluating visualizations with missing data}},
url = {https://ieeexplore.ieee.org/document/8440857/},
volume = {25},
year = {2019}
}
@article{Ikejiri2011,
abstract = {We report on the correlation between the flux, color, and polarization variations on time scales of days-months in blazars, and discuss their universal aspects. We performed monitoring of 42 blazars in the optical and near-infrared bands from 2008 to 2010 using TRISPEC attached to the "Kanata" 1.5-m telescope. We found that 28 blazars exhibited "bluer-when-brighter" trends in their whole or a part of time-series data sets. This corresponds to 88{\%} of objects that were observed for {\textgreater}10 days. Thus, our observation unambiguously confirmed that the "bluer-whenbrighter" trend is common in the emission from blazar jets. This trend was apparently generated by a variation component with a constant and relatively blue color and an underlying red component. Prominent short-term flares on time scales of days-weeks tended to exhibit a spectral hysteresis; their rising phases were bluer than their decay phases around the flare maxima. In contrast to the strong flux - color correlation, the correlation of the flux and polarization degree was relatively weak; only 10 objects showed significant positive correlations. Rotations of polarization were detected only in three objects: PKS 1510-089, 3C 454.3, and PKS 1749+096, and possibly in S5 0716+714. We also investigated the dependence of the degree of variability on the luminosity and the synchrotron peak frequency, vpeak. As a result, we found that lower luminosity and higher vpeak objects had smaller variations in their amplitudes both in the flux, color, and polarization degree. Our observation suggests the presence of several distinct emitting sources, which have different variation time-scales, colors, and polarizations. We propose that the energy injection by, for example, internal shocks in relativistic shells is a major factor for blazar variations on time scales of both days and months. {\textcopyright} 2011. Astronomical Society of Japan.},
archivePrefix = {arXiv},
arxivId = {arXiv:1105.0255v2},
author = {Ikejiri, Yuki and Uemura, Makoto and Sasada, Mahito and Ito, Ryosuke and Yamanaka, Masayuki and Sakimoto, Kiyoshi and Arai, Akira and Fukazawa, Yasushi and Ohsugi, Takashi and Kawabata, Koji S. and Yoshida, Michitoshi and Sato, Shuji and Kino, Masaru},
doi = {10.1093/pasj/63.3.327},
eprint = {arXiv:1105.0255v2},
file = {:Users/nsawada/Google Drive/Papers/Photopolarimetric Monitoring of Blazars.pdf:pdf},
issn = {00046264},
journal = {Publications of the Astronomical Society of Japan},
keywords = {Galaxies: BL Lacertae objects: general,Galaxies: active,Galaxies: jets},
number = {3},
pages = {639--675},
title = {{Photopolarimetric monitoring of blazars in the optical and near-infrared bands with the Kanata telescope. I. Correlations between flux, color, and polarization}},
volume = {63},
year = {2011}
}
@inproceedings{Lin2002,
abstract = {The problem of efficiently locating previously known patterns in a time series database (i.e., query by content) has received much attention and may now largely be regarded as a solved problem. However, from a knowledge discovery viewpoint, a more interesting problem is the enumeration of previously unknown, frequently occurring patterns. We call such patterns motifs, because of their close analogy to their discrete counterparts in computation biology. An efficient motif discovery algorithm for time series would be useful as a tool for summarizing and visualizing massive time series databases. In addition, it could be used as a subroutine in various other data mining tasks, including the discovery of association rules, clustering and classification. In this work we carefully motivate, then introduce, a non-trivial definition of time series motifs. We propose an efficient algorithm to discover them, and we demonstrate the utility and efficiency of our approach on several real world datasets.},
annote = {Algorithm to find out motifs
finding repeated patterns},
archivePrefix = {arXiv},
arxivId = {1-58113-567-X},
author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Patel, Pranav},
booktitle = {Proceeding of the 2nd Workshop on Temporal Data Mining},
doi = {10.1.1.19.6629},
eprint = {1-58113-567-X},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Lin et al. - 2002 - Finding motifs in time series.pdf:pdf},
isbn = {158113567X},
pages = {53--68},
title = {{Finding motifs in time series}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.6629},
year = {2002}
}
@inproceedings{Yiu2007,
abstract = {The top-k dominating query returns k data objects which dominate the highest number of objects in a dataset. This query is an important tool for decision support since it provides data analysts an intuitive way for finding significant objects. ...},
annote = {Not related?},
author = {Yiu, Man Lung and Mamoulis, Nikos},
booktitle = {Proceedings of 33rd International Conference on Very Large Data Bases},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Yiu, Mamoulis - 2007 - Efficient processing of top-k dominating queries on multi-dimensional data.pdf:pdf},
isbn = {9781595936493},
pages = {483--494},
title = {{Efficient processing of top-k dominating queries on multi-dimensional data}},
year = {2007}
}
@inproceedings{Krueger2017,
abstract = {We investigated whether individual great tits, Parus major, vary consistently in their exploratory behaviour in a novel environment and measured the repeatability and heritability of this trait. Wild birds were caught in their natural habitat, tested in the laboratory in an open field test on the following morning, then released at the capture site. We measured individual consistency of exploratory behaviour for recaptured individuals (repeatability) and estimated the heritability with parentâoffspring regressions and sibling analyses. Measures of exploratory behaviour of individuals at repeated captures were consistent in both sexes and study areas (repeatabilities ranged from 0.27 to 0.48). Exploration scores did not differ between the sexes, and were unrelated to age, condition at fledging or condition during measurement. Heritability estimates were 0.22â0.41 (parentâoffspring regressions) and 0.37â0.40 (sibling analyses). We conclude that (1) consistent individual variation in open field behaviour exists in individuals from the wild, and (2) this behavioural variation is heritable. This is one of the first studies showing heritable variation in a behavioural trait in animals from the wild, and poses the question of how this variation is maintained under natural conditions. Copyright 2002 The Association for the Study of Animal Behaviour. Published by Elsevier Science Ltd. All rights reserved.},
annote = {A little related
Visual query system for human mobility data, express complex mobility information with simple and understandable icons},
author = {Krueger, Robert and Tremel, Tina and Thom, Dennis},
booktitle = {Proceedings of the 2017 International Symposium on Big Data Visual Analytics (BDVA)},
doi = {10.1109/BDVA.2017.8114626},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Krueger, Tremel, Thom - 2017 - VESPa 2 . 0 Data-Driven Behavior Models for Visual Analytics of Movement Sequences.pdf:pdf},
isbn = {9781538607817},
month = {nov},
pages = {1--8},
publisher = {IEEE},
title = {{VESPa 2.0: Data-driven behavior models for visual analytics of movement sequences}},
url = {http://ieeexplore.ieee.org/document/8114626/},
year = {2017}
}
@article{Antonucci1993a,
abstract = {The straw person model (SPM), in which there are two basic types of AGN, the radio quiets and the radio louds, is presented. For each type there is a range in intrinsic luminosity, and the luminosity controls some properties such as the Fanaroff and Riley classes. Evidence to the effect that orientation effects are important and widespread is presented. A list of types and a summary of the phenomenology of the quiets, a detailed description of the prototype Seyfert 2/1, NGC 1068, and an update on polarization observations of quiets in general, as it bears on unified models, are provided. Evidence is presented for unification of the narrow line radio galaxies with the broad line radio galaxies and lobe-dominant radio quasars, and the resulting relaxation or resolution of the statistical anomalies associated with relativistic beaming.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Antonucci, Robert},
doi = {10.1146/annurev.astro.31.1.473},
eprint = {arXiv:1011.1669v3},
isbn = {0066-4146},
issn = {0066-4146},
journal = {Annual Review of Astronomy and Astrophysics},
keywords = {bl lac objects,blazars,ovv,radio galaxies,seyfert galaxies},
number = {31},
pages = {473--521},
pmid = {25246403},
title = {{Unified models for active galactic nuclei and quasars}},
volume = {31},
year = {1993}
}
@article{Uemura2017,
abstract = {We report on the variation in the optical polarization of the blazar PKS 1749+096 observed in 2008--2015. The degree of polarization (PD) tends to increase in short flares having a time-scale of a few days. The object favors a polarization angle (PA) of {\$}40{\^{}}\backslashcirc{\$}--{\$}50{\^{}}\backslashcirc{\$} at the flare maxima, which is close to the position angle of the jet ({\$}20{\^{}}\backslashcirc{\$}--{\$}40{\^{}}\backslashcirc{\$}). Three clear polarization rotations were detected in the negative PA direction associated with flares. In addition, a rapid and large decrease in the PA was observed in the other two flares, while another two flares showed no large PA variation. The light curve maxima of the flares possibly tend to lag behind the PD maxima and color-index minima. The PA became {\$}-50{\^{}}\backslashcirc{\$} to {\$}-20{\^{}}\backslashcirc{\$} in the decay phase of active states, which is almost perpendicular to the jet position angle. We propose a scenario to explain these observational features, where transverse shocks propagate along curved trajectories. The favored PA at the flare maxima suggests that the observed variations were governed by the variations in the Doppler factor, {\$}\backslashdelta{\$}. Based on this scenario, the minimum viewing angle of the source, {\$}\backslashtheta{\_}\backslashmathrm{\{}min{\}}=4.8{\^{}}\backslashcirc{\$}--{\$}6.6{\^{}}\backslashcirc{\$}, and the location of the source, {\$}\backslashDelta r\backslashgtrsim 0.1{\$}pc, from the central black hole were estimated. In addition, the acceleration of electrons by the shock and synchrotron cooling would have a time-scale similar to that of the change in {\$}\backslashdelta{\$}. The combined effect of the variation in {\$}\backslashdelta{\$} and acceleration/cooling of electrons is probably responsible for the observed diversity of the polarization variations in the flares.},
archivePrefix = {arXiv},
arxivId = {arXiv:1709.02524v1},
author = {Uemura, Makoto and Itoh, Ryosuke and Liodakis, Ioannis and Blinov, Dmitry and Nakayama, Masanori and Xu, Longyin and Sawada, Naoko and Wu, Hsiang-Yun and Fujishiro, Issei},
doi = {10.1093/pasj/psx111},
eprint = {arXiv:1709.02524v1},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Uemura et al. - 2017 - Optical polarization variations in the blazar PKS 1749 096(2).pdf:pdf},
issn = {0004-6264},
journal = {Publications of the Astronomical Society of Japan},
keywords = {096,4609697,6,69,96,academic,active,all rights reserved,article-abstract,bl lacertae objects,c the author 2017,com,downloaded from https,for permissions,galaxies,individual,japan,jets,journals,oup,pasj,permissions,pks 1749,please email,polarization,press on behalf of,published by oxford university,the astronomical society of},
number = {6},
pages = {96:1--96:12},
title = {{Optical polarization variations in the blazar PKS 1749 + 096}},
volume = {69},
year = {2017}
}
@incollection{Munzner2008,
abstract = {The goal of this paper is to help authors recognize and avoid a set of pitfalls that recur in many rejected information visualization papers, using a chronological model of the research process. Selecting a target paper type in the initial stage can avert an inappropriate choice of validation methods. Pitfalls involving the design of a visual encoding may occur during the middle stages of a project. In a later stage when the bulk of the research is finished and the paper writeup begins, the possible pitfalls are strategic choices for the content and structure of the paper as a whole, tactical problems localized to specific sections, and unconvincing ways to present the results. Final-stage pitfalls of writing style can be checked after a full paper draft exists, and the last set of problems pertain to submission.},
address = {Berlin, Heidelberg},
archivePrefix = {arXiv},
arxivId = {1504.02878},
author = {Munzner, Tamara},
booktitle = {Information Visualization},
doi = {10.1007/978-3-540-70956-5_6},
editor = {Kerren, Andreas and Stasko, John T. and Fekete, Jean-Daniel and North, Chris},
eprint = {1504.02878},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Munzner - 2008 - Process and pitfalls in writing information visualization research papers.pdf:pdf},
isbn = {354070955X},
issn = {03029743},
pages = {134--153},
publisher = {Springer Berlin Heidelberg},
title = {{Process and pitfalls in writing information visualization research papers}},
url = {http://link.springer.com/10.1007/978-3-540-70956-5{\_}6},
year = {2008}
}
@article{Ding2008,
abstract = {The last decade has witnessed a tremendous growths of in- terests in applications that deal with querying and min- ing of time series data. Numerous representation methods for dimensionality reduction and similarity measures geared towards time series have been introduced. Each individ- ual work introducing a particular method has made spe- cific claims and, aside from the occasional theoretical justi- fications, provided quantitative experimental observations. However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods over some of the previ- ously introduced ones. In order to provide a comprehensive validation, we conducted an extensive set of time series ex- periments re-implementing 8 different representation meth- ods and 9 similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In this paper, we give an overview of these different techniques and present our com- parative experimental findings regarding their effectiveness. Our experiments have provided both a unified validation of some of the existing achievements, and in some cases, sug- gested that certain claims in the literature may be unduly optimistic.},
annote = {Comparison among dimensional reduction methods for time series and distance measurements 
we conducted an extensive experimental 
consolidation on the state-of-the-art representation meth- 
ods and similarity measures for time series data},
author = {Ding, Hui and Trajcevski, Goce and Scheuermann, Peter and Wang, Xiaoyue and Keogh, Eamonn},
doi = {10.14778/1454159.1454226},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Ding et al. - 2008 - Querying and mining of time series data Experimental comparison of representations and distance measures.pdf:pdf},
isbn = {0000000000000},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {2},
pages = {1542--1552},
title = {{Querying and mining of time series data: Experimental comparison of representations and distance measures}},
volume = {1},
year = {2008}
}
@article{Vlachos2003,
abstract = {Although most time-series data mining research has concentrated on providing solutions for a single distance function, in this work we motivate the need for a single index structure that can support multiple distance measures. Our specific area of interest is the efficient retrieval and analysis of trajectory similarities. Trajectory datasets are very common in environmental applications, mobility experiments, video surveillance and are especially important for the discovery of certain biological patterns. Our primary similarity measure is based on the Longest Common Subsequence (LCSS) model, that offers enhanced robustness, particularly for noisy data, which are encountered very often in real world applications. However, our index is able to accommodate other distance measures as well, including the ubiquitous Euclidean distance, and the increasingly popular Dynamic Time Warping (DTW). While other researchers have advocated one or other of these similarity measures, a major contribution of our work is the ability to support all these measures without the need to restructure the index. Our framework guarantees no false dismissals and can also be tailored to provide much faster response time at the expense of slightly reduced precision/recall. The experimental results demonstrate that our index can help speed-up the computation of expensive similarity measures such as the LCSS and the DTW.},
annote = {In this work we present an efficient and compact, external memory index for fast detection of similar trajectories for mul- 
tidimensional trajectories},
author = {Vlachos, Michail and Hadjieleftheriou, Marios and Gunopulos, Dimitrios and Keogh, Eamonn},
doi = {10.1145/956750.956777},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Vlachos et al. - 2003 - Indexing multi-dimensional time-series with support for multiple distance measures.pdf:pdf},
isbn = {1581137370},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Dynamic time warping,Longest common subsequence,Trajectories},
pages = {216--225},
title = {{Indexing multi-dimensional time-series with support for multiple distance measures}},
year = {2003}
}
@article{Vrotsou2009,
abstract = {The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today's information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines.},
author = {Vrotsou, Katerina and Johansson, Jimmy and Cooper, Matthew},
doi = {10.1109/TVCG.2009.117},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Vrotsou, Johansson, Cooper - 2009 - ActiviTree Interactive visual exploration of sequences in event-based data using graph similarity(2).pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Interactive visual exploration,event-based data,graph similarity,node similarity,sequence identification},
month = {nov},
number = {6},
pages = {945--952},
pmid = {19834158},
publisher = {IEEE},
title = {{ActiviTree: Interactive visual exploration of sequences in event-based data using graph similarity}},
url = {http://ieeexplore.ieee.org/document/5290698/},
volume = {15},
year = {2009}
}
@article{Bleiholder2009,
abstract = {This article places data fusion into the greater context of data integration, precisely defines the goals of data fusion, namely, complete, concise, and consistent data, and highlights the challenges of data fusion, namely, uncertain and conflicting data values. We give an overview and classification of different ways of fusing data and present several techniques based on standard and advanced operators of the relational algebra and SQL. Finally, the article features a comprehensive survey of data integration systems from academia and industry, showing if and how data fusion is performed in each.},
author = {Bleiholder, Jens and Naumann, Felix},
doi = {10.1145/1456650.1456651},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Bleiholder, Naumann - 2009 - Data fusion(2).pdf:pdf},
isbn = {1101145145},
issn = {0360-0300},
journal = {ACM Computing Surveys},
number = {1},
pages = {article no. 1},
pmid = {20806056},
title = {{Data fusion}},
url = {http://portal.acm.org/citation.cfm?doid=1456650.1456651},
volume = {41},
year = {2009}
}
@article{Haroz2016,
annote = {Paper type: Evaluation?, case study
CS depicts two simultaneous time series as one line. This paper presents how CS is constructed, evaluate its effectiveness, and measure the types and frequency of misinterpretations.
Fig.4 and 6 are easy to understand. CS is a kind of projection of two variables' changes.},
author = {Haroz, Steve and Kosara, Robert and Franconeri, Steven L},
doi = {10.1109/TVCG.2015.2502587},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Haroz, Kosara, Franconeri - 2016 - The connected scatterplot for presenting paired time series.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {9},
pages = {2174--2186},
publisher = {IEEE},
title = {{The connected scatterplot for presenting paired time series}},
volume = {22},
year = {2016}
}
@inproceedings{Fujishiro2015a,
address = {Kobe, Japan},
author = {Fujishiro, Issei and Chen, Bing-Yu and Chen, Wei and Hong, Seok-Hee and Itoh, Takayuki and Koyamada, Koji and Ono, Kenji and Nonaka, Jorji},
booktitle = {SIGGRAPH Asia 2015 Visualization in High Performance Computing},
doi = {10.1145/2818517.2818545},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Fujishiro et al. - 2015 - Top computational visualization R{\&}D problems 2015 Panel(2).pdf:pdf},
isbn = {978-1-4503-3929-2},
pages = {20:1--20:13},
publisher = {ACM},
title = {{Top computational visualization R{\&}D problems 2015: Panel}},
year = {2015}
}
@article{Lin2007,
abstract = {Many high level representations of time series have been proposed for data mining, including Fourier transforms, wavelets, eigenwaves, piecewise polynomial models, etc. Many researchers have also considered symbolic representations of time series, noting that such representations would potentiality allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities. While many symbolic representations of time series have been introduced over the past decades, they all suffer from two fatal flaws. First, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Second, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. In this work we formulate a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. In particular, we will demonstrate the utility of our representation on various data mining tasks of clustering, classification, query by content, anomaly detection, motif discovery, and visualization.},
annote = {Sax
A new symbolic representation of time series and distance measures depending on the original series.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0211456v3},
author = {Lin, Jessica and Keogh, Eamonn and Wei, Li and Lonardi, Stefano},
doi = {10.1007/s10618-007-0064-z},
eprint = {0211456v3},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Lin et al. - 2007 - Experiencing SAX A novel symbolic representation of time series.pdf:pdf},
isbn = {1384-5810},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
keywords = {Data mining,Discretize,Symbolic representation,Time series},
number = {2},
pages = {107--144},
pmid = {1974367},
primaryClass = {arXiv:cond-mat},
title = {{Experiencing SAX: A novel symbolic representation of time series}},
volume = {15},
year = {2007}
}
@article{Li2005,
author = {Li, Ai Guo and Qin, Zheng},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Keogh et al. - 2001 - Dimensionality reduction and fast similarity search in large time series databases.pdf:pdf},
issn = {02544164},
journal = {Jisuanji Xuebao/Chinese Journal of Computers},
keywords = {Data mining,Database,Query,Similarity search,Time series},
number = {9},
pages = {1467--1475},
title = {{Dimensionality reduction and similarity search in large time series databases}},
volume = {28},
year = {2005}
}
@inproceedings{Xi2006,
abstract = {Many algorithms have been proposed for the problem of time series classification. However, it is clear that one-nearest-neighbor with Dynamic Time Warping (DTW) distance is exceptionally difficult to beat. This approach has one weakness, however; it is computationally too demanding for many realtime applications. One way to mitigate this problem is to speed up the DTW calculations. Nonetheless, there is a limit to how much this can help. In this work, we propose an additional technique, numerosity reduction, to speed up one-nearest-neighbor DTW. While the idea of numerosity reduction for nearest-neighbor classifiers has a long history, we show here that we can leverage off an original observation about the relationship between dataset size and DTW constraints to produce an extremely compact dataset with little or no loss in accuracy. We test our ideas with a comprehensive set of experiments, and show that it can efficiently produce extremely fast accurate classifiers.},
author = {Xi, Xiaopeng and Keogh, Eamonn and Shelton, Christian and Wei, Li and Ratanamahatana, Chotirat Ann},
booktitle = {Proceedings of the 23nd International Conference on Machine Learning},
doi = {10.1136/gut.33.10.1386},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Xi et al. - 2006 - Fast time series classification using numerosity reduction.pdf:pdf},
issn = {00175749},
pages = {1033--1040},
title = {{Fast time series classification using numerosity reduction}},
year = {2006}
}
@article{Keogh2001,
annote = {A new dimensional deduction method for time series
we introduce a novel transform to achieve dimensionality reduction},
author = {Keogh, Eamonn and Chakrabarti, Kaushik and Pazzani, Michael and Mehrotra, Sharad},
doi = {10.1007/PL00011669},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Keogh et al. - 2001 - Dimensionality reduction and fast similarity search in large time series databases.pdf:pdf},
issn = {02544164},
journal = {Knowledge and Information Systems},
keywords = {Data mining,Database,Query,Similarity search,Time series},
number = {3},
pages = {263--286},
title = {{Dimensionality reduction and fast similarity search in large time series databases}},
volume = {3},
year = {2001}
}
@article{Berger2011,
abstract = {Systems projecting a continuous n-dimensional parameter space to a continuous m-dimensional target space play an important role in science and engineering. If evaluating the system is expensive, however, an analysis is often limited to a small number of sample points. The main contribution of this paper is an interactive approach to enable a continuous analysis of a sampled parameter space with respect to multiple target values. We employ methods from statistical learning to predict results in real-time at any user-defined point and its neighborhood. In particular, we describe techniques to guide the user to potentially interesting parameter regions, and we visualize the inherent uncertainty of predictions in 2D scatterplots and parallel coordinates. An evaluation describes a real-world scenario in the application context of car engine design and reports feedback of domain experts. The results indicate that our approach is suitable to accelerate a local sensitivity analysis of multiple target dimensions, and to determine a sufficient local sampling density for interesting parameter regions.},
author = {Berger, W. and Piringer, H. and Filzmoser, P. and Gr{\"{o}}ller, E.},
doi = {10.1111/j.1467-8659.2011.01940.x},
file = {:Users/nsawada/Google Drive/Papers/Uncertainty-Aware Exploration of Continuous Parameter Spaces Using Multivariate Prediction.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
number = {3},
pages = {911--920},
title = {{Uncertainty-aware exploration of continuous parameter spaces using multivariate prediction}},
volume = {30},
year = {2011}
}
@inproceedings{Kim2019,
address = {New York, New York, USA},
author = {Kim, Nam Wook and Pfister, Hanspeter and {Henry Riche}, Nathalie and Bach, Benjamin and Xu, Guanpeng and Brehmer, Matthew and Hinckley, Ken and Pahud, Michel and Xia, Haijun and McGuffin, Michael J.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI '19},
doi = {10.1145/3290605.3300335},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Kim et al. - 2019 - DataToon Drawing Data Comics About Dynamic Networks with Pen Touch Interaction.pdf:pdf},
isbn = {9781450359702},
pages = {105:1--105:12},
publisher = {ACM Press},
title = {{DataToon: Drawing dynamic network comics with pen + touch interaction}},
url = {http://dl.acm.org/citation.cfm?doid=3290605.3300335},
year = {2019}
}
@article{Bernard2010,
abstract = {Digital Library support for textual and certain types of non- textual documents has significantly advanced over the last years. While Digital Library support implies many aspects along the whole library workflow model, interactive and visual retrieval allowing effective query formulation and result presentation are important functions. Recently, new kinds of non-textual documents whichmerit Digital Library support, but yet cannot be accommodated by existing Digital Library technology, have come into focus. Scientific primary data, as produced for example, by scientific experimentation, earth observation, or simulation, is such a data type. We report on a concept and first implementation of Digital Library functionality, supporting visual retrieval and exploration in a specific important class of scientific primary data, namely, time-oriented data. The approach is developed in an interdisciplinary effort by experts from the library, natural sciences, and visual analytics communities. In addition to presenting the concept and discussing relevant challenges, we present results from a first implementation of our approach as applied on a real-world scientific primary data set.},
annote = {Highly related
a concept 
and first implementation of Digital Library functionality 
for supporting visual retrieval and exploration in a specific 
important class of scientific primary data, namely, time- 
oriented research data
Feature extraction, visual query,etc.},
author = {Bernard, J{\"{u}}rgen and Brase, Jan and Fellner, Dieter and Koepler, Oliver and Kohlhammer, J{\"{o}}rn and Ruppert, Tobias and Schreck, Tobias and Sens, Irina},
doi = {10.1007/s00799-011-0072-x},
file = {:Users/nsawada/Google Drive/Papers/A Visual Digital Library Approach for Time-Oriented Scientific Primary Data.pdf:pdf},
issn = {14325012},
journal = {International Journal on Digital Libraries},
keywords = {Content-based retrieval,Scientific research data,Time series,Visual cluster analysis,Visual search},
number = {2},
pages = {111--123},
title = {{A visual digital library approach for time-oriented scientific primary data}},
volume = {11},
year = {2010}
}
@inproceedings{Abouzied2014,
abstract = {DataPlay is a query tool that encourages a trial-and-error approach to query specification. DataPlay uses a graphi-cal query language to make a particularly challenging query specification task -quantification -easier. It constrains the relational data model to enable the presentation of non-answers, in addition to answers, to aid query interpretation. Two novel features of DataPlay are suggesting semantic vari-ations to a query and correcting queries by example. We in-troduce DataPlay as a sophisticated query specification tool and demonstrate its unique interaction models.},
annote = {Not related
Visual query for database 
Express queries as visual language},
author = {Abouzied, Azza and Hellerstein, Joseph M. and Silberschatz, Avi},
booktitle = {Proceedings of the VLDB Endowment},
doi = {10.14778/2367502.2367542},
file = {:Users/nsawada/Google Drive/Papers/Playful Query Specification with DataPlay.pdf:pdf},
issn = {21508097},
number = {12},
pages = {1938--1941},
title = {{Playful query specification with DataPlay}},
volume = {5},
year = {2014}
}
@article{Yu2008,
abstract = {With advances in computing techniques, a large amount of high-resolution high-quality multimedia data (video and audio, etc.) has been collected in research laboratories in various scientific disciplines, particularly in social and behavioral studies. How to automatically and effectively discover new knowledge from rich multimedia data poses a compelling challenge since state-of-the-art data mining techniques can most often only search and extract pre-defined patterns or knowledge from complex heterogeneous data. In light of this, our approach is to take advantages of both the power of human perception system and the power of computational algorithms. More specifically, we propose an approach that allows scientists to use data mining as a first pass, and then forms a closed loop of visual analysis of current results followed by more data mining work inspired by visualization, the results of which can be in turn visualized and lead to the next round of visual exploration and analysis. In this way, new insights and hypotheses gleaned from the raw data and the current level of analysis can contribute to further analysis. As a first step toward this goal, we implement a visualization system with three critical components: (1) A smooth interface between visualization and data mining. The new analysis results can be automatically loaded into our visualization tool. (2) A flexible tool to explore and query temporal data derived from raw multimedia data. We represent temporal data into two forms - continuous variables and event variables. We have developed various ways to visualize both temporal correlations and statistics of multiple variables with the same type, and conditional and high-order statistics between continuous and event variables. (3) A seamless interface between raw multimedia data and derived data. Our visualization tool allows users to explore, compare, and analyze multi-stream derived variables and simultaneously switch to access raw multimedia data. We demonstrate various functions in our visualization program using a set of multimedia data including video, audio and motion tracking data.},
author = {Yu, Chen and Zhong, Yiwen and Smith, Thomas and Park, Ikhyun and Huang, Weixia},
doi = {10.1109/VAST.2008.4677369},
file = {:Users/nsawada/Google Drive/Papers/Visual Mining of Multimedia Data for Social and Behavioral Studies.pdf:pdf},
journal = {Proceedings of 2008 IEEE Symposium on Visual Analytics Science and Technology},
keywords = {Data mining,Data visualization,H.1.2 [Information Systems]: Models and principles,H.2.8 [Database Management]: Database Applications,H.3.3 [Information Storage and Retrieval]: Informa,H.5.1 [Information Interface and Presentation]: Mu,H.5.2 [Information Interface and Presentation]: Us,Humans,Laboratories,Management information systems,Multimedia computing,Multimedia databases,Multimedia systems,Statistics,Switches,behavioral studies,behavioural sciences computing,data mining,high-quality multimedia data,multimedia computing,multimedia data,social sciences computing,social studies,visual data mining,visual mining,visual programming,visualization program},
pages = {155--162},
title = {{Visual data mining of multimedia data for social and behavioral studies}},
year = {2008}
}
@article{Pahins2017,
abstract = {We propose Hashedcubes, a data structure that enables real-time visual exploration of large datasets that improves the state of the art by virtue of its low memory requirements, low query latencies, and implementation simplicity. In some instances, Hashedcubes notably requires two orders of magnitude less space than recent data cube visualization proposals. In this paper, we describe the algorithms to build and query Hashedcubes, and how it can drive well-known interactive visualizations such as binned scatterplots, linked histograms and heatmaps. We report memory usage, build time and query latencies for a variety of synthetic and real-world datasets, and find that although sometimes Hashedcubes offers slightly slower querying times to the state of the art, the typical query is answered fast enough to easily sustain a interaction. In datasets with hundreds of millions of elements, only about 2{\%} of the queries take longer than 40ms. Finally, we discuss the limitations of data structure, potential spacetime tradeoffs, and future research directions.},
author = {Pahins, C{\'{i}}cero A.L. and Stephens, Sean A. and Scheidegger, Carlos and Comba, Jo{\~{a}}o L.D.},
doi = {10.1109/TVCG.2016.2598624},
file = {:Users/nsawada/Google Drive/Papers/Hashedcubes Simple, Low Memory, Real-Time Visual Exploration of Big Data.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Scalability,data cube,interactive exploration,multidimensional data},
number = {1},
pages = {671--680},
title = {{Hashedcubes: Simple, low memory, real-time visual exploration of big data}},
volume = {23},
year = {2017}
}
@article{Grammel2010,
abstract = {It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.},
author = {Grammel, Lars and Tory, Melanie and Storey, Margaret Anne},
doi = {10.1109/TVCG.2010.164},
file = {:Users/nsawada/Google Drive/Papers/How Information Visualization Novices Construct Visualizations.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Empirical study,novices,visual analytics,visual mapping,visualization,visualization construction},
number = {6},
pages = {943--952},
title = {{How information visualization novices construct visualizations}},
volume = {16},
year = {2010}
}
@article{Dork2008,
abstract = {In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds.},
author = {D{\"{o}}rk, Marian and Carpendale, Sheelagh and Collins, Christopher and Williamson, Carey},
doi = {10.1109/TVCG.2008.175},
file = {:Users/nsawada/Google Drive/Papers/VisGets Coordinated Visualizations for Web-based Information Exploration and Discovery.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {6},
pages = {1205--1212},
title = {{VisGets: Coordinated visualizations for web-based information exploration and discovery}},
volume = {14},
year = {2008}
}
@inproceedings{Pienta2016,
address = {New York, New York, USA},
author = {Pienta, Robert and Tamersoy, Acar and Endert, Alex and Navathe, Shamkant and Tong, Hanghang and Chau, Duen Horng},
booktitle = {Proceedings of the International Working Conference on Advanced Visual Interfaces},
doi = {10.1145/2909132.2909246},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Pienta et al. - 2016 - VISAGE Interactive visual graph querying.pdf:pdf},
isbn = {9781450341318},
pages = {272--279},
publisher = {ACM Press},
title = {{VISAGE: Interactive visual graph querying}},
url = {http://dl.acm.org/citation.cfm?doid=2909132.2909246},
year = {2016}
}
@inproceedings{Ahlberg1992,
abstract = {We designed, implemented and evaluated a new concept for direct manipulation of databases, called dynamic queries, that allows users to formulate queries with graphical widgets, such as sliders. By providing a graphical visualization of the database and search results, users can find trends and exceptions easily. Eighteen undergraduate chemistry students performed statistically significantly faster using a dynamic queries interface compared to two interfaces both providing form fill-in as input method, one with graphical visualization output and one with all-textual output. The interfaces were used to explore the periodic table of elements and search on their properties.},
annote = {Visual query system for database
Cited by ConnectomeExplorer
The meaning of visual query here is the query controlled by visual elements, like sliders
It does not mean visual expression itself is query},
author = {Ahlberg, Christopher and Williamson, Christopher and Shneiderman, Ben},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/142750.143054},
file = {:Users/nsawada/Google Drive/Papers/dynamic queries for information exploration an implementation and evaluation.pdf:pdf},
isbn = {0897915135},
pages = {619--626},
title = {{Dynamic queries for information exploration: An implementation and evaluation}},
year = {1992}
}
@article{Gerken2009,
abstract = {Designing information-seeking systems has become an increasingly complex task as today's information spaces are rapidly growing in quantity, heterogeneity, and dimensionality. The challenge is to provide user interfaces that have a satisfying usability and user experience even for novice users. Although information visualization and interaction design offer solutions, many information-seeking systems such as online catalogs for libraries or web search engines continue to use outdated user-interface concepts developed decades ago. In this paper, we will present four principles that we identified as crucial for the successful design of a modern visual information-seeking system. These are (1) to support various ways of formulating an information need, (2) to integrate analytical and browsing-oriented ways of exploration, (3) to provide views on different dimensions of the information space, and (4) to make search a pleasurable experience. These design principles are based on our experience over a long period in the user-centered design and evaluation of visual information-seeking systems. Accordingly, we will showcase individual designs from our own work of the past 10 years to illustrate each principle and hence narrow the gap between the scientific discussion and the designing practitioner that has often hindered research ideas from becoming reality. However, most of the times search is only one part of a higher level user activity (e. g. writing a paper). Thus future research should focus on the challenges when regarding search in such a broader context. We will use the final two chapters to point out some of these challenges and outline our vision of an integrated and consistent digital work environment named Zoomable Object-oriented Information Landscape. {\textcopyright} Springer-Verlag 2009.},
annote = {Cited by ConnectomeExplorer
Present design principles for visual information seeking
Make queries visuble?
Different from what I expected?},
author = {Gerken, Jens and Heilig, Mathias and Jetter, Hans Christian and Rexhausen, Sebastian and Demarmels, Mischa and K{\"{o}}nig, Werner A. and Reiterer, Harald},
doi = {10.1007/s00799-009-0052-6},
file = {:Users/nsawada/Google Drive/Papers/Lessons learned from the design and evaluation of visual information-seeking systems.pdf:pdf},
issn = {14325012},
journal = {International Journal on Digital Libraries},
keywords = {Design principles,Digital libraries,Human-computer interaction,Information visualization,Interaction design,Search,Semantic zooming,Visual information-seeking},
number = {2-3},
pages = {49--66},
title = {{Lessons learned from the design and evaluation of visual information-seeking systems}},
volume = {10},
year = {2009}
}
@inproceedings{Stockinger2005,
author = {Stockinger, K. and Shalf, J. and {Kesheng Wu} and Bethel, E.W.},
booktitle = {Proceedings of 2005 IEEE Visualization},
doi = {10.1109/VISUAL.2005.1532792},
file = {:Users/nsawada/Google Drive/Papers/Query-driven visualization of large data sets.pdf:pdf},
isbn = {0-7803-9462-3},
keywords = {bitmap,data anal-,index,large data visualization,multivariate visualization,query-driven visualization,scientific data management,visual analytics,ysis},
pages = {167--174},
title = {{Query-driven visualization of large data sets}},
url = {http://ieeexplore.ieee.org/document/1532792/},
year = {2005}
}
@article{Shneiderman1994,
abstract = {Considers how dynamic queries allow users to "fly through" databases by adjusting widgets and viewing the animated results. In studies, users reacted to this approach with an enthusiasm more commonly associated with video games. Adoption requires research into retrieval and display algorithms and user-interface design. The author discusses how experts may benefit from visual interfaces because they will be able to formulate more complex queries and interpret intricate results.},
author = {Shneiderman, Ben},
file = {:Users/nsawada/Google Drive/Papers/Dynamic queries for visual information seeking.pdf:pdf},
journal = {IEEE Software},
number = {6},
pages = {70--77},
title = {{Dynamic queries for visual information seeking}},
volume = {11},
year = {1994}
}
@article{Catarci1997,
abstract = {Visual query systems (VQSs) are query systems for databases that use visual representations to depict the domain of interest and express related requests. VQSs can be seen as an evolution of query languages adopted into database management systems; they are designed to improve the effectiveness of the human-computer communication. Thus, their most important features are those that determine the nature of the human-computer dialogue. In order to survey and compare existing VQSs used for querying traditional databases, we first introduce a classification based on such features, namely the adopted visual representations and the interaction strategies. We then identify several user types and match the VQS classes against them, in order to understand which kind of system may be suitable for each kind of user. We also report usability experiments which support our claims. Finally, some of the most important open problems in the VQS area are described. {\textcopyright} 1997 Academic Press Limited.},
author = {Catarci, Tiziana and Costabile, Maria F. and Levialdi, Stefano and Batini, Carlo},
doi = {10.1006/jvlc.1997.0037},
file = {:Users/nsawada/Google Drive/Papers/Visual Query Systems for Databases A Survey.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages and Computing},
number = {2},
pages = {215--260},
title = {{Visual query systems for databases: A survey}},
volume = {8},
year = {1997}
}
@inproceedings{Smart2008,
abstract = {Query formulation is a key aspect of information retrieval, contributing to both the efficiency and usability of many semantic applications. A number of query languages, such as SPARQL, have been developed for the Semantic Web; however, there are, as yet, few tools to support end users with respect to the creation and editing of semantic queries. In this paper we introduce NITELIGHT, a Web-based graphical tool for semantic query construction that is based on the W3C SPARQL specification. NITELIGHT combines a number of features to support end-users with respect to the creation of SPARQL queries. These include a columnar ontology browser, an interactive graphical design surface, a SPARQL-compliant visual query language, a SPARQL syntax viewer and an integrated semantic query results browser. The functionality of each of these components is described in the current paper. In addition, we discuss the potential contribution of the NITELIGHT tool to rule creation/editing and semantic integration capabilities. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
author = {Smart, Paul R. and Russell, Alistair and Braines, Dave and Kalfoglou, Yannis and Bao, Jie and Shadbolt, Nigel R.},
booktitle = {Proceedings of the 16th International Conference on Knowledge Engineering: Practice and Patterns},
doi = {10.1007/978-3-540-87696-0-25},
file = {:Users/nsawada/Google Drive/Papers/Smart2008{\_}Chapter{\_}AVisualApproachToSemanticQuery.pdf:pdf},
isbn = {3540876952},
issn = {03029743},
keywords = {Graphical query language,Ontology,Ontology alignment,Owl,Rdf,Semantic integration,Semantic web,Sparql,Visual query system},
pages = {275--291},
title = {{A visual approach to semantic query design using a web-based graphical query designer}},
volume = {5268},
year = {2008}
}
@inproceedings{Derthick1997,
author = {Derthick, Mark and Kolojejchick, John and Steven, F. Roth},
booktitle = {Proceedings of the 10th annual ACM symposium on User interface software and technology},
file = {:Users/nsawada/Google Drive/Papers/An interactive visual query environment for exploring data.pdf:pdf},
pages = {189--198},
title = {{An interactive visual query environment for exploring data}},
year = {1997}
}
@inproceedings{Martin2005,
abstract = {Brushing is an operation found in many data visualization systems.$\backslash$nIt is a mechanism for interactively selecting subsets of the data$\backslash$nso that they may be highlighted, deleted, or masked. Traditionally,$\backslash$nbrushes have been defined in screen space via methods such as painting$\backslash$nand rubberband rectangles. In this paper we describe the design of$\backslash$nN-dimensional brushes which are defined in data space rather than$\backslash$nscreen space, and show how they have been integrated into {\{}XmdvTool,{\}}$\backslash$na visualization package for displaying multivariate data. Depending$\backslash$non the data display technique in use, brushes may be specified and$\backslash$nmanipulated via direct or indirect methods, and the specification$\backslash$nmay be demand-driven or data-driven. Various brush operations such$\backslash$nas highlighting, linking, masking, moving average, and quantitative$\backslash$ndisplay have been developed to apply to the selected data. In addition,$\backslash$nwe have explored several new brush concepts, such as non-discrete$\backslash$nbrush boundaries, simultaneous display of multiple brushes, and creating$\backslash$ncomposite brushes via logical operators. Preliminary experimental$\backslash$nevaluation with test subjects supports the usefulness of N-dimensional$\backslash$nbrushes in data exploration tasks.},
author = {Martin, A.R. and Ward, M.O.},
booktitle = {Proceedings of Visualization '95},
doi = {10.1109/visual.1995.485139},
file = {:Users/nsawada/Google Drive/Papers/High Dimensional Brushing for Interactive Exploration of Multivariate Data.pdf:pdf},
pages = {271--278},
title = {{High dimensional brushing for interactive exploration of multivariate data}},
year = {2005}
}
@article{Beyer2013,
abstract = {This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time. {\textcopyright} 1995-2012 IEEE.},
annote = {A little related
Our system incorporates a knowledge-based query 
algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer 
domain-specific questions in an intuitive manner
Query of ConnectomeExplorer looks like tree, which is combination of set algebra},
author = {Beyer, Johanna and Al-Awami, Ali and Kasthuri, Narayanan and Lichtman, Jeff W. and Pfister, Hanspeter and Hadwiger, Markus},
doi = {10.1109/TVCG.2013.142},
file = {:Users/nsawada/Google Drive/Papers/ConnectomeExplorer Query-Guided Visual Analysis of Large Volumetric Neuroscience Data.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Connectomics,neuroscience,petascale volume analysis,query algebra,visual knowledge discovery},
number = {12},
pages = {2868--2877},
publisher = {IEEE},
title = {{ConnectomeExplorer: Query-guided visual analysis of large volumetric neuroscience data}},
volume = {19},
year = {2013}
}
@inproceedings{Ahlberg1992a,
address = {New York, New York, USA},
author = {Ahlberg, Christopher and Williamson, Christopher and Shneiderman, Ben},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems},
doi = {10.1145/142750.143054},
isbn = {0897915135},
pages = {619--626},
publisher = {ACM Press},
title = {{Dynamic queries for information exploration}},
url = {http://portal.acm.org/citation.cfm?doid=142750.143054},
year = {1992}
}
@inproceedings{Shen2008,
abstract = {The widespread use of mobile devices brings opportunities to capture large-scale, continuous information about human behavior. Mobile data has tremendous value, leading to business opportunities, market strategies, security concerns, etc. Visual analytics systems that support interactive exploration and discovery are needed to extracting insight from the data. However, visual analysis of complex social-spatial-temporal mobile data presents several challenges. We have created MobiVis, a visual analytics tool, which incorporates the idea of presenting social and spatial information in one heterogeneous network. The system supports temporal and semantic filtering through an interactive time chart and ontology graph, respectively, such that data subsets of interest can be isolated for close-up investigation. "Behavior rings," a compact radial representation of individual and group behaviors, is introduced to allow easy comparison of behavior patterns. We demonstrate the capability of MobiVis with the results obtained from analyzing the MIT Reality Mining dataset.},
annote = {Not related
A new network based visualization for mobility data, which can show summary of data at different time scale, heterogeneous network of spatial and social information, etc.
A heat map based visualization (time chart) shows time variations at different 2 scale, which is helpful to reveal repetitive patterns},
author = {Shen, Zeqian and Kwan-Liu, Ma},
booktitle = {Proceedings of 2008 IEEE Pacific Visualisation Symposium},
doi = {10.1109/PACIFICVIS.2008.4475474},
file = {:Users/nsawada/Google Drive/Papers/MobiVis A Visualization System for Exploring Mobile Data.pdf:pdf},
isbn = {9781424419661},
keywords = {Information visualization,Mobile data,Social-spatial-temporal data visualization,Visual analytics},
pages = {175--182},
title = {{MobiVis: A visualization system for exploring mobile data}},
year = {2008}
}
@inproceedings{Sukharev2009,
abstract = {We present a correlation study of time-varying multivariate volumetric data sets. In most scientific disciplines, to test hypotheses and discover insights, scientists are interested in looking for connections among different variables, or among different spatial locations within a data field. In response, we propose a suite of techniques to analyze the correlations in time-varying multivariate data. Various temporal curves are utilized to organize the data and capture the temporal behaviors. To reveal patterns and find connections, we perform data clustering and segmentation using the k-means clustering and graph partitioning algorithms. We study the correlation structure of a single or a pair of variables using pointwise correlation coefficients and canonical correlation analysis. We demonstrate our approach using results on time-varying multivariate climate data sets.},
annote = {propose a suite of
techniques to analyze the correlations in time-varying multivariate
data},
author = {Sukharev, Jeffrey and Wang, Chaoli and Ma, Kwan Liu and Wittenberg, Andrew T.},
booktitle = {Proceedings of 2009 IEEE Pacific Visualization Symposium},
doi = {10.1109/PACIFICVIS.2009.4906852},
file = {:Users/nsawada/Google Drive/Papers/Correlation Study of Time-Varying Multivariate Climate Data Sets.pdf:pdf},
isbn = {9781424444045},
keywords = {G.3 [probability and statistics]: Multivariate sta,G.3 [probability and statistics]: Time series stat,J.2 [physical sciences and engineering]: Earth and},
pages = {161--168},
title = {{Correlation study of time-varying multivariate climate data sets}},
year = {2009}
}
@article{Muelder2009,
abstract = {In serial computation, program profiling is often helpful for optimization of key sections of code. When moving to parallel computation, not only does the code execution need to be considered but also communication between the different processes which can induce delays that are detrimental to performance. As the number of processes increases, so does the impact of the communication delays on performance. For large-scale parallel applications, it is critical to understand how the communication impacts performance in order to make the code more efficient. There are several tools available for visualizing program execution and communications on parallel systems. These tools generally provide either views which statistically summarize the entire program execution or process-centric views. However, process-centric visualizations do not scale well as the number of processes gets very large. In particular, the most common representation of parallel processes is a Gantt char t with a row for each process. As the number of processes increases, these charts can become difficult to work with and can even exceed screen resolution. We propose a new visualization approach that affords more scalability and then demonstrate it on systems running with up to 16,384 processes.},
annote = {Not related },
author = {Muelder, Chris and Gygi, Francois and Ma, Kwan Liu},
doi = {10.1109/TVCG.2009.196},
file = {:Users/nsawada/Google Drive/Papers/Visual Analysis of Inter-Process Communication for Large-Scale Parallel Computing.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Information Visualization,MPI Profiling,Scalability},
number = {6},
pages = {1129--1136},
publisher = {IEEE},
title = {{Visual analysis of inter-process communication for large-scale parallel computing}},
volume = {15},
year = {2009}
}
@article{Wang2010,
abstract = {We advocate an application-driven approach to compressing and rendering large-scale time-varying scientific-simulation data. Scientists often have specific visualization tasks in mind based on certain domain knowledge. For example, in the context of time-varying, multivariate volume-data visualization, a scientist's domain knowledge might include the salient isosurface of interest for some variable. Given this knowledge, the scientist might want to observe spatiotemporal relationships among other variables in the neighborhood of that isosurface. We've tried to directly incorporate such knowledge and tasks into data reduction, compression, and rendering. Here, we present our solution andexperimental results for two largescale time-varying, multivariate scientific data sets.},
author = {Wang, Chaoli and Yu, Hongfeng and Ma, Kwan-Liu},
doi = {10.1109/MCG.2010.3},
file = {:Users/nsawada/Google Drive/Papers/Application-Driven Compression for Visualizing Large-Scale Time-Varying Data.pdf:pdf},
journal = {IEEE Computer Graphics and Applications},
keywords = {Data visualization,Isosurfaces,Large-scale systems,Spatiotemporal phenomena,application-driven compression,bit-wise texture packing,computer graphics,data compression,data reduction,data visualisation,deferred filtering,graphics and multimedia,importance-based compression,large-data visualization,large-scale time-varying scientific-simulation dat,multivariate volume-data visualization,natural sciences computing,rendering (computer graphics),spatiotemporal relationships,time-varying data visualization},
number = {1},
pages = {59--69},
title = {{Application-driven compression for visualizing large-scale time-varying data}},
volume = {30},
year = {2010}
}
@article{Akiba2007,
abstract = {The importance of visualizing multivariate volume data from turbulent combustion simulations is discussed. Direct numerical simulation (DNS) of a turbulent non-premixed flame with the detailed chemistry shows how the resulting visualizations present information, which are previously unseen and provide new understanding and validation of such simulations. DNS can fully resolve a turbulent combustion process's finest spatial and temporal details and focus on a particular physical aspect of the process. Visualization's major roles in the DNS of combustion will be to provide qualitative understanding of the underlying combustion phenomena and guide combustion scientists toward regions requiring more quantitative analysis. The ability to simultaneously visualize multiple variables is essential because combustion is a multiscalar problem with intricate coupling between reactive scalars and the flow field. The techniques are also useful in guiding qualitative understanding and extracting knowledge from combustion data.},
annote = {Data fusion 
Kind of feature extraction
Visualization for time varying 3D volumetric data
Can select the features of interest through parallel coordinates, fig 8},
author = {Akiba, Hiroshi and Ma, Kwan Liu and Chen, Jacqueline H. and Hawkes, Evatt R.},
doi = {10.1109/MCSE.2007.42},
file = {:Users/nsawada/Google Drive/Papers/Visualizing Multivariate Volume Data from Turbulent Combustion Simulations.pdf:pdf},
issn = {15219615},
journal = {Computing in Science and Engineering},
number = {2},
pages = {76--83},
title = {{Visualizing multivariate volume data from turbulent combustion simulations}},
volume = {9},
year = {2007}
}
@article{Jones2008,
abstract = {The authors describe a data exploration system that visualizes time-varying, multivariate, point-based data from gyrokinetic particle simulations. By using two interaction modes, their system lets researchers explore collections of densely packed particles and discover interesting aspects, such as the location and motion of particles trapped in turbulent plasma flow.},
annote = {Particle data},
author = {Jones, Chad and Ma, Kwan-Liu and Ethier, Stephane and Lee, Wei-Li},
doi = {10.1109/MCSE.2008.88},
file = {:Users/nsawada/Google Drive/Papers/An Integrated Exploration Approach to Visualizing Multivariate Particle Data.pdf:pdf},
journal = {Computing in Science Engineering},
keywords = {Data visualization,Geometry,Multidimensional systems,Particle visualization,Physics,Plasma confinement,Plasma devices,Plasma materials processing,Plasma simulation,Plasma temperature,Plasma transport processes,ata visualisation,data exploration system,gyrokinetic particle simulation,information visualization,multivariate particle data visualization,multivariate visualization,parallel coordinates,physics computing,plasma flow,plasma simulation,plasma transport processes,plasma turbulence,turbulent plasma flow,user interfaces},
number = {4},
pages = {20--29},
title = {{An Integrated Exploration Approach to Visualizing Multivariate Particle Data}},
volume = {10},
year = {2008}
}
@article{F.-Y.Tzeng2005,
abstract = {In volume data visualization, the classification step is used to determine voxel visibility and is usually carried out through the interactive editing of a transfer function that defines a mapping between voxel value and color/opacity. This approach is limited by the difficulties in working effectively in the transfer function space beyond two dimensions. We present a new approach to the volume classification problem which couples machine learning and a painting metaphor to allow more sophisticated classification in an intuitive manner. The user works in the volume data space by directly painting on sample slices of the volume and the painted voxels are used in an iterative training process. The trained system can then classify the entire volume. Both classification and rendering can be hardware accelerated, providing immediate visual feedback as painting progresses. Such an intelligent system approach enables the user to perform classification in a much higher dimensional space without explicitly specifying the mapping for every dimension used. Furthermore, the trained system for one data set may be reused to classify other data sets with similar characteristics.},
annote = {ããããï¼
a new approach to the volume classification problem, relying on an intelligent system to abstract high- 
dimensional mapping functions from the user
Differentiate/classify the region of volume data automatically?
Using ML},
author = {F.-Y.Tzeng and E.B.Lum and K.-L.Ma},
doi = {http://dx.doi.org/10.1109/TVCG.2005.38},
file = {:Users/nsawada/Google Drive/Papers/An intelligent system approach to higher-dimensional classification of volume data.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {User interface design,classification,graphics hardware,machine learning,transfer functions,visualization,volume rendering},
number = {3},
pages = {273--284},
title = {{An intelligent system approach to higher-dimensional classification of volume data}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp={\&}arnumber=1407860{\&}contentType=Journals+{\%}26+Magazines{\&}searchField{\%}3DSearch{\_}All{\%}26queryText{\%}3DAn+Intelligent+System+Approach+to+Higher-+Dimensional+Classification+of+Volume+Data},
volume = {11},
year = {2005}
}
@article{ChaoliWang2008,
abstract = {The ability to identify and present the most essential aspects of time-varying data is critically important in many areas of science and engineering. This paper introduces an importance-driven approach to time-varying volume data visualization for enhancing that ability. By conducting a block-wise analysis of the data in the joint feature-temporal space, we derive an importance curve for each data block based on the formulation of conditional entropy from information theory. Each curve characterizes the local temporal behavior of the respective block, and clustering the importance curves of all the volume blocks effectively classifies the underlying data. Based on different temporal trends exhibited by importance curves and their clustering results, we suggest several interesting and effective visualization techniques to reveal the important aspects of time-varying data.},
author = {{Chaoli Wang} and {Hongfeng Yu} and {Kwan-Liu Ma}},
doi = {10.1109/tvcg.2008.140},
file = {:Users/nsawada/Google Drive/Papers/Importance-Driven Time-Varying Data Visualization.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {6},
pages = {1547--1554},
title = {{Importance-driven time-varying data visualization}},
volume = {14},
year = {2008}
}
@inproceedings{Tzeng2005,
abstract = {Terascale simulations produce data that is vast in spatial, temporal, and variable domains, creating a formidable challenge for subsequent analysis. Feature extraction as a data reduction method offers a viable solution to this large data problem. This paper presents a new approach to the problem of extracting and visualizing 4D features within large volume data. Conventional methods requires either an analytical description of the feature of interest or tedious manual intervention throughout the feature extraction and tracking process. We show that it is possible for a visualization system to "learn" to extract and track features in complex 4D flow field according to their "visual" properties, location, shape, and size. The basic approach is to employ machine learning in the process of visualization. Such an intelligent system approach is powerful because it allows us to extract and track an feature of interest in a high-dimensional space without explicitly specifying the relations between those dimensions, resulting in a greatly simplified and intuitive visualization interface.},
author = {Tzeng, Fan Yin and Ma, Kwan Liu},
booktitle = {Proceedings of the ACM/IEEE 2005 Supercomputing Conference},
doi = {10.1109/SC.2005.37},
file = {:Users/nsawada/Google Drive/Papers/Intelligent Feature Extraction and Tracking for Visualizing Large-Scale 4D Flow Simulations.pdf:pdf},
isbn = {1595930612},
keywords = {Artificial neural networks,Feature extraction,Feature tracking,Flow visualization,Hardware acceleration,Machine learning,Time-varying volume data,User interface},
pages = {6:1--6:11},
title = {{Intelligent feature extraction and tracking for visualizing large-scale 4P flow simulations}},
year = {2005}
}
@article{Ma2003,
abstract = {Visualization exploration is the process of extracting insight from data via interaction with visual depictions of that data. Visualization exploration is more than presentation; the interaction with both the data and its depiction is as important as the data and depiction itself. Significant visualization research has focused on the generation of visualizations (the depiction); less effort has focused on the exploratory aspects of visualization (the process). However, without formal models of the process, visualization exploration sessions cannot be fully utilized to assist users and system designers. Toward this end, we introduce the P-Set model of visualization exploration for describing this process and a framework to encapsulate, share, and analyze visual explorations. In addition, systems utilizing the model and framework are more efficient as redundant exploration is avoided. Several examples drawn from visualization applications demonstrate these benefits. Taken together, the model and framework provide an effective means to exploit the information within the visual exploration process},
author = {Ma, Kwan-liu and Member, Senior},
doi = {10.1109/TVCG.2007.28},
file = {:Users/nsawada/Google Drive/Papers/A Model and Framework for Visualization Exploration.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Information Visualizatio,Scientific Visualization},
number = {2},
pages = {357--369},
title = {{Visualizing Visualization: A Model and Framework for Visualization Exploration}},
volume = {13},
year = {2003}
}
@article{Lum2006,
author = {Lum, Eric B. and Shearer, James and Ma, Kwan Liu},
doi = {10.1007/s00371-006-0049-8},
file = {:Users/nsawada/Google Drive/Papers/Interactive multi-scale exploration for volume classification.pdf:pdf},
issn = {01782789},
journal = {Visual Computer},
keywords = {Classification,Filter banks,Hardware acceleration,Interface design,Scale-space filtering,Transfer functions,Visualization,Volume rendering},
number = {9-11},
pages = {622--630},
title = {{Interactive multi-scale exploration for volume classification}},
volume = {22},
year = {2006}
}
@inproceedings{Teoh2005,
author = {Teoh, Soon Tee and Ma, Kwan Liu},
booktitle = {Proceedings of International Symposium on Visual Computing},
doi = {10.1007/11595755_29},
file = {:Users/nsawada/Google Drive/Papers/Hifocon Object and Dimensional Coherence and Correlation in Multidimensional Visualization.pdf:pdf},
isbn = {3540307508},
issn = {03029743},
pages = {235--242},
title = {{Hifocon: Object and dimensional coherence and correlation in multidimensional visualization}},
year = {2005}
}
@inproceedings{Tzeng2004,
abstract = {In volume visualization, users typically specify transfer functions to classify the data and assign visual attributes to each material class. Higher-dimensional classication makes it easier to differentiate material classes since more data properties are considered. One of the difculties in using higher-dimensional classication is the absence of appropriate user interfaces. We introduce an intuitive user interface that allows the user to work in the cluster space, which shows the material classes with a set of material widgets, rather than work in the transfer function space. This interface not only provides the user the capability to specify arbitrary-dimensional transfer functions, but also allows the user to operate directly on the classication and visualization results.},
author = {Tzeng, Fan-Yin and Ma, Kwan-Liu},
booktitle = {Proceedings of Eurographics / IEEE VGTC Symposium on Visualization},
doi = {10.2312/VisSym/VisSym04/017-024},
file = {:Users/nsawada/Google Drive/Papers/eScholarship UC item 4vm4s1sb.pdf:pdf},
pages = {17--24},
title = {{A cluster-space visual interface for arbitrary dimensional classification of volume data}},
year = {2004}
}
@article{Ogawa2009,
abstract = {In May of 2008, we published online a series of software visualization videos using a method called code{\_}swarm. Shortly thereafter, we made the code open source and its popularity took off. This paper is a study of our code swarm application, comprising its design, results and public response. We share our design methodology, including why we chose the organic information visualization technique, how we designed for both developers and a casual audience, and what lessons we learned from our experiment. We validate the results produced by code{\_}swarm through a qualitative analysis and by gathering online user comments. Furthermore, we successfully released the code as open source, and the software community used it to visualize their own projects and shared their results as well. In the end, we believe code{\_}swarm has positive implications for the future of organic information design and open source information visualization practice.},
author = {Ogawa, Michael and Ma, Kwan Liu},
doi = {10.1109/TVCG.2009.123},
file = {:Users/nsawada/Google Drive/Papers/code{\_}swarm A Design Study in Organic Software Visualization.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Software visualization,organic information visualization,software development history and evolution},
number = {6},
pages = {1097--1104},
publisher = {IEEE},
title = {{Code-swarm: A design study in organic software visualization}},
volume = {15},
year = {2009}
}
@inproceedings{Teoh2004,
address = {New York, New York, USA},
author = {Teoh, Soon Tee and Zhang, Ke and Tseng, Shih-Ming and Ma, Kwan-Liu and Wu, S. Felix},
booktitle = {Proceedings of the 2004 ACM workshop on Visualization and data mining for computer security  - VizSEC/DMSEC '04},
doi = {10.1145/1029208.1029215},
file = {:Users/nsawada/Google Drive/Papers/Combining visual and automated data mining for near-real-time anomaly detection and analysis in BGP.pdf:pdf},
isbn = {1581139748},
keywords = {information visualization,internet routing,network visualization},
pages = {35},
publisher = {ACM Press},
title = {{Combining visual and automated data mining for near-real-time anomaly detection and analysis in BGP}},
url = {http://portal.acm.org/citation.cfm?doid=1029208.1029215},
year = {2004}
}
@inproceedings{Muelder2009a,
abstract = {The ability to extract and follow time-varying flow features in volume data generated from large-scale numerical simulations enables scientists to effectively see and validate modeled phenomena and processes. Extracted features often take much less storage space and computing resources to visualize. Most feature extraction and tracking methods first identify features of interest in each time step independently, then correspond these features in consecutive time steps of the data. Since these methods handle each time step separately, they do not use the coherency of the feature along the time dimension in the extraction process. In this paper, we present a prediction-correction method that uses a prediction step to make the best guess of the feature region in the subsequent time step, followed by growing and shrinking the border of the predicted region to coherently extract the actual feature of interest. This method makes use of the temporal-space coherency of the data to accelerate the extraction process while implicitly solving the tedious correspondence problem that previous methods focus on. Our method is low cost with very little storage overhead, and thus facilitates interactive or runtime extraction and visualization, unlike previous methods which were largely suited for batch-mode processing due to high computational cost.},
author = {Muelder, Chris and Ma, Kwan Liu},
booktitle = {Proceedings of 2009 IEEE Pacific Visualization Symposium},
doi = {10.1109/PACIFICVIS.2009.4906833},
file = {:Users/nsawada/Google Drive/Papers/Interactive Feature Extraction and Tracking by utilizing region coherency.pdf:pdf},
isbn = {9781424444045},
keywords = {Feature representation,I.4.6 [computer graphics]: Segmentation,I.4.7 [computer grap,Region growing, partitioning; I.4.7 [computer grap,partitioning},
pages = {17--24},
title = {{Interactive feature extraction and tracking by utilizing region coherency}},
year = {2009}
}
@inproceedings{Jin2010,
abstract = {Finding patterns in temporal data is an important data analysis task in many domains. Static visualizations can help users easily see certain instances of patterns, but are not specially designed to support systematic analysis tasks, such as finding all instances of a pattern automatically. VizPattern is an interactive visual query environment that uses a comic strip metaphor to enable users to easily and quickly define and locate complex temporal patterns. Evaluations provide evidence that VizPattern is applicable in many domains, and that it enables a wide variety of users to answer questions about temporal data faster and with fewer errors than existing state-of-the-art visual analysis systems.},
annote = {Visual query for time series data (which should be about individuals or objects and have events)
The visual query system is based on icons or graphics},
author = {Jin, Jing and Szekely, Pedro},
booktitle = {Proceedings of IEEE Conference on Visual Analytics Science and Technology 2010},
doi = {10.1109/VAST.2010.5652890},
file = {:Users/nsawada/Google Drive/Papers/Interactive querying of temporal data using a comic strip metaphor.pdf:pdf},
isbn = {9781424494866},
keywords = {H.3.3 [Information Systems]: Information search an,H.5.2 [information Interfaces and Presentation]: U},
pages = {163--170},
publisher = {IEEE},
title = {{Interactive querying of temporal data using a comic strip metaphor}},
year = {2010}
}
@inproceedings{Browne2011,
annote = {a system that leverages 
hand-drawn input for exploring data through simple charts},
author = {Browne, Jeffrey and Lee, Bongshin and Carpendale, Sheelagh and Riche, Nathalie and Sherwood, Timothy},
booktitle = {Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces},
doi = {10.1145/2076354.2076383},
file = {:Users/nsawada/Google Drive/Papers/Data analysis on interactive whiteboards through sketch-based interaction.pdf:pdf},
isbn = {9781450308717},
keywords = {sketch-based interaction,visualization},
pages = {154--157},
title = {{Data analysis on interactive whiteboards through sketch-based interaction}},
year = {2011}
}
@article{Walny2012,
abstract = {Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.},
author = {Walny, Jagoda and Lee, Bongshin and Johns, Paul and {Henry Riche}, Nathalie and Carpendale, Sheelagh},
doi = {10.1109/TVCG.2012.275},
file = {:Users/nsawada/Google Drive/Papers/Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Pen and touch,Wizard of Oz,data exploration,interaction,whiteboard},
number = {12},
pages = {2779--2788},
publisher = {IEEE},
title = {{Understanding pen and touch interaction for data exploration on interactive whiteboards}},
volume = {18},
year = {2012}
}
@article{Lee2012,
abstract = {The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more ânaturalâ interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more ânatural,â interaction techniques for InfoVis. View full abstract},
author = {Lee, Bongshin and Isenberg, Petra and Riche, Nathalie Henry and Carpendale, Sheelagh},
doi = {10.1109/TVCG.2012.204},
file = {:Users/nsawada/Google Drive/Papers/Beyond Mouse and Keyboard Expanding Design Considerations for Information Visualization Interactions.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Design considerations,NUI (Natural User Interface),interaction,post-WIMP},
number = {12},
pages = {2689--2698},
publisher = {IEEE},
title = {{Beyond mouse and keyboard: Expanding design considerations for information visualization interactions}},
volume = {18},
year = {2012}
}
@article{Heer2012,
author = {Heer, Jeffrey and Shneiderman, Ben},
file = {:Users/nsawada/Google Drive/Papers/Interactive Dynamics for Visual Analysis.pdf:pdf},
journal = {Queue - Micoprocessors},
number = {2},
pages = {1--26},
title = {{Interactive dynamics for visual analysis}},
url = {https://queue.acm.org/detail.cfm?id=2146416},
volume = {10},
year = {2012}
}
@article{Walker2015,
abstract = {{\textcopyright} 2015, Springer-Verlag Berlin Heidelberg. Biologists studying animals in their natural environment are increasingly using sensors such as accelerometers in animal-attached âsmart' tags because it is widely acknowledged that this approach can enhance the understanding of ecological and behavioural processes. The potential of such tags is tempered by the difficulty of extracting animal behaviour from the sensors which is currently primarily dependent on the manual inspection of multiple time series graphs. This is time consuming and error-prone for the domain expert and is now the limiting factor for realising the value of tags in this area. We introduce TimeClassifier, a visual analytic system for the classification of time series data for movement ecologists. We deploy our system with biologists and report two real-world case studies of its use.},
annote = {Related 
provide a visual analytic system 
which assists in the labelling and understanding of animal 
behaviour.
Combination of domain knowledge and matching algorithms },
author = {Walker, James S. and Jones, Mark W. and Laramee, Robert S. and Bidder, Owen R. and Williams, Hannah J. and Scott, Rebecca and Shepard, Emily L.C. and Wilson, Rory P.},
doi = {10.1007/s00371-015-1112-0},
file = {:Users/nsawada/Google Drive/Papers/TimeClassifier a visual analytic system for the classification of multi-dimensional time series data.pdf:pdf},
issn = {01782789},
journal = {Visual Computer},
keywords = {Movement ecology,Time series analysis,Visual analytics},
number = {6-8},
pages = {1067--1078},
publisher = {Springer Berlin Heidelberg},
title = {{TimeClassifier: A visual analytic system for the classification of multi-dimensional time series data}},
volume = {31},
year = {2015}
}
@inproceedings{Rouxel2014,
abstract = {This paper presents a new type of gesture for identifying spatio-temporal patterns: the analog gesture. Analog gestures can be characterized by some features (speed, acceleration, direction, and angle) which describe the dynamic morphology of the gesture. At first, we detail interactive tasks that should benefit for the use of analog gestures. Then we give a state of the art concerning gesture recognition and investigate the specificity and the main properties of the analog gesture. Then, we propose a review of the surveillance maritime system called Hyperion which uses analog gestures. Finally, we give an example of the use of this type of gesture by the operator. It concerns the interactive detection of ship abnormal trajectories in the context of maritime surveillance.},
annote = {Helpful when thinking about querying gestures
System is based on predefined rules},
author = {Rouxel, Benoit and Poirier, Franck and Antoine, Jean Yves and Coppin, Gilles},
booktitle = {Proceedings of Human-Computer Interaction. Advanced Interaction Modalities and Techniques},
doi = {10.1007/978-3-319-07230-2_14},
file = {:Users/nsawada/Google Drive/Papers/What You Draw Is What You Search The Analog Gesture.pdf:pdf},
isbn = {9783319072296},
issn = {16113349},
keywords = {Gesture recognition,tabletop computing,time-space pattern search},
pages = {139--147},
title = {{What you draw is what you search: The analog gesture}},
year = {2014}
}
@inproceedings{Yifei2017,
abstract = {In recent years, the research community, inspired by its success in dealing with single-dimensional time series, has turned its attention to dealing with multidimensional time series. There are now a plethora of techniques for indexing, classification, and clustering of multidimensional time series. However, we argue that the difficulty of exploratory search in large multidimensional time series remains underappreciated. In essence, the problem reduces to the "chicken-and-egg" paradox that it is difficult to produce a meaningful query without knowing the best subset of dimensions to use, but finding the best subset of dimensions is itself query dependent. In this work we propose a solution to this problem. We introduce an algorithm that runs in the background, observing the user's search interactions. When appropriate, our algorithm suggests to the user a dimension that could be added or deleted to improve the user's satisfaction with the query. These query dependent suggestions may be useful to the user, even if she does not act on them (by reissuing the query), as they can hint at unexpected relationships or redundancies between the dimensions of the data. We evaluate our algorithm on several real-world datasets in medical, human activity, and industrial domains, showing that it produces subjectively sensible and objectively superior results.},
address = {Chicago, IL, USA},
annote = {Support dimension choice for querying 
suggests to the user a dimension that 
could be added or deleted to improve the user's satisfaction with the query},
author = {Yifei, Ding and Keogh, Eamonn},
booktitle = {PDC '18: Proceedings of the 15th Participatory Design Conference},
doi = {10.1145/3085504.3085522},
file = {:Users/nsawada/Google Drive/Papers/Query Suggestion to allow Intuitive Interactive Search in Multidimensional Time Series.pdf:pdf},
isbn = {978-1-4503-5282-6},
keywords = {Multidimensional Time Series,Query Suggestion},
pages = {18:1--18:11},
title = {{Query Suggestion to allow Intuitive Interactive Search in Multidimensional Time Series}},
year = {2017}
}
@article{Lee2019,
abstract = {The increasing availability of rich and complex data in a variety of scientific domains poses a pressing need for tools to enable scientists to rapidly make sense of and gather insights from data. One proposed solution is to design visual query systems (VQSs) that allow scientists to search for desired patterns in their datasets. While many existing VQSs promise to accelerate exploratory data analysis by facilitating this search, they are unfortunately not widely used in practice. Through a year-long collaboration with scientists in three distinct domains---astronomy, genetics, and material science---we study the impact of various features within VQSs that can aid rapid visual data analysis, and how VQSs fit into a scientists' analysis workflow. Our findings offer design guidelines for improving the usability and adoption of next-generation VQSs, paving the way for VQSs to be applied to a variety of scientific domains.},
annote = {Related!
How VQS works in the real world
What of VQS effective/ineffective
Three case studies},
archivePrefix = {arXiv},
arxivId = {1710.00763},
author = {Lee, Doris Jung-Lin and Lee, John and Siddiqui, Tarique and Kim, Jaewoo and Karahalios, Karrie and Parameswaran, Aditya},
eprint = {1710.00763},
file = {:Users/nsawada/Google Drive/Papers/You can't always sketch what you want Understanding Sensemaking in Visual Query Systems.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
title = {{You can't always sketch what you want: Understanding sensemaking in visual query systems}},
year={2020},
volume={26},
number={1},
pages={1267-1277},
}
@inproceedings{Mannino2018,
abstract = {We present Qetch, a tool where users freely sketch patterns on a scale-less canvas to query time series data without specifying query length or amplitude. We study how humans sketch time series patterns â humans preserve visually salient perceptual features but often non-uniformly scale and locally distort a pattern â and we develop a novel matching algorithm that accounts for human sketching errors. Qetch enables the easy construction of complex and expressive queries with two key features: regular expressions over sketches and relative po-sitioning of sketches to query multiple time-aligned series. Through user studies, we demonstrate the effectiveness of Qetch's different interaction features. We also demonstrate the effectiveness of Qetch's matching algorithm compared to popular algorithms on targeted, and exploratory query-by-sketch search tasks on a variety of data sets.},
annote = {present a new matching algorithm for sketch based query, which can deal with uncertain {\&} complex user-input sketch},
author = {Mannino, Miro and Abouzied, Azza},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3173574.3173962},
file = {:Users/nsawada/Google Drive/Papers/Expressive Time Series Querying with Hand-Drawn Scale-Free Sketches.pdf:pdf},
isbn = {9781450356206},
keywords = {Time series querying by sketching,regular expressions, scale-less sketches},
pages = {388:1--388:13},
title = {{Expressive time series querying with hand-drawn scale-free sketches}},
year = {2018}
}
@inproceedings{Mannino2018a,
abstract = {We present Qetch, a tool where users freely sketch patterns on a scale-less canvas to query time series data without specifying query length or amplitude. We study how humans sketch time series patterns â humans preserve visually salient perceptual features but often non-uniformly scale and locally distort a pattern â and we develop a novel matching algorithm that accounts for human sketching errors. Qetch enables the easy construction of complex and expressive queries with two key features: regular expressions over sketches and relative po-sitioning of sketches to query multiple time-aligned series. Through user studies, we demonstrate the effectiveness of Qetch's different interaction features. We also demonstrate the effectiveness of Qetch's matching algorithm compared to popular algorithms on targeted, and exploratory query-by-sketch search tasks on a variety of data sets.},
author = {Mannino, Miro and Abouzied, Azza},
booktitle = {Proceedings of the 2018 International Conference on Management of Data},
doi = {10.1145/3173574.3173962},
file = {:Users/nsawada/Google Drive/Papers/Qetch Time Series Querying with Expressive Sketches.pdf:pdf},
isbn = {9781450356206},
keywords = {Time series querying by sketching,regular expressions,scale-less sketches},
pages = {1741--1744},
title = {{Qetch: Time series querying with expressive sketches}},
url = {http://delivery.acm.org/10.1145/3180000/3173962/paper388.pdf?ip=133.87.180.22{\&}id=3173962{\&}acc=OPEN{\&}key=D2341B890AD12BFE.2F02CEF14B3C19D4.4D4702B0C3E38B35.6D218144511F3437{\&}{\_}{\_}acm{\_}{\_}=1526612510{\_}73700af34f0b34397a82f16a8c43e472},
year = {2018}
}
@article{Miranda2018,
abstract = {Broadway Av. Construction site Figure 1: Using Noise Profiler to analyze OLAP queries over acoustic data from sensors deployed in New York City. A group-by hour is used as a baseline for ambient noise (smooth line), highlighting the difference between the noise profile of two locations during weekdays. One sensor (blue) is close to a main road (Broadway Av.) and has a constant dB A level throughout the hours of the day; the other sensor (orange) is close to a major construction site and has a distinctly higher dB A level during construction hours between 7 a.m. and 5 p.m. The live streaming data (fluctuating line) can be used to get instantaneous information about the noise level captured by the sensors, and inform city agency noise enforcement teams about possible noise code violations such as construction sites operating outside of their allotted construction hours. Abstract Advances in technology coupled with the availability of low-cost sensors have resulted in the continuous generation of large time series from several sources. In order to visually explore and compare these time series at different scales, analysts need to execute online analytical processing (OLAP) queries that include constraints and group-by's at multiple temporal hierarchies. Effective visual analysis requires these queries to be interactive. However, while existing OLAP cube-based structures can support interactive query rates, the exponential memory requirement to materialize the data cube is often unsuitable for large data sets. Moreover, none of the recent space-efficient cube data structures allow for updates. Thus, the cube must be re-computed whenever there is new data, making them impractical in a streaming scenario. We propose Time Lattice, a memory-efficient data structure that makes use of the implicit temporal hierarchy to enable interactive OLAP queries over large time series. Time Lattice is a subset of a fully materialized cube and is designed to handle fast updates and streaming data. We perform an experimental evaluation which shows that the space efficiency of the data structure does not hamper its performance when compared to the state of the art. In collaboration with signal processing and acoustics research scientists, we use the Time Lattice data structure to design the Noise Profiler, a web-based visualization framework that supports the analysis of noise from cities. We demonstrate the utility of Noise Profiler through a set of case studies.},
annote = {Data structure
Time lattice: a memory-efficient data structure to enable interactive online analytical processing queries over large time series.},
author = {Miranda, Fabio and Lage, Marcos and Doraiswamy, Harish and Mydlarz, Charlie and Salamon, Justin and Lockerman, Yitzchak and Freire, Juliana and Silva, Claudio T.},
doi = {10.1111/cgf.13398},
file = {:Users/nsawada/Google Drive/Papers/Miranda{\_}et{\_}al-2018-Computer{\_}Graphics{\_}Forum.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {Computer Graphics Forum, EUROGRAPHICS,EUROGRAPHICS},
number = {3},
pages = {23--35},
title = {{Time Lattice: A data structure for the interactive visual analysis of large time series}},
volume = {37},
year = {2018}
}
@article{Zeckzer2018,
annote = {ï¼},
author = {Zeckzer, Dirk and Wiegreffe, Daniel and M{\"{u}}ller, Lydia},
doi = {10.24132/JWSCG.2018.26.1.1},
file = {:Users/nsawada/Google Drive/Papers/Analyzing Histone Modifications Using Tiled Binned Clustering and 3D Scatter Plots.pdf:pdf},
issn = {12136964},
journal = {Journal of WSCG},
keywords = {3D scatterplot,Binning,Biological visualization,Clustering,Histone modifications,Tiles},
number = {1},
pages = {1--10},
title = {{Analyzing histone modifications using tiled binned clustering and 3D scatter plots}},
volume = {26},
year = {2018}
}
@inproceedings{Perng2000,
abstract = {In this paper we present the landmark model, a model for time series that yields new techniques for similarity-based time series pattern querying. The landmark model does not follow traditional similarity models that rely on pointwise Euclidean distance. Instead, it leads to landmark similarity, a general model of similarity that is consistent with human intuition and episodic memory. By tracking different specific subsets of features of landmarks, we can efficiently compute different landmark similarity measures that are invariant under corresponding subsets of six transformations; namely, shifting, uniform amplitude scaling, uniform time scaling, uniform bi-scaling, time warping and non-uniform amplitude scaling. A method of identifying features that are invariant under these transformations is proposed. We also discuss a generalized approach for removing noise from raw time series without smoothing out the peaks and bottoms. Beside these new capabilities, our experiments show that landmark indexing is considerably fast},
annote = {New method for computing similarities 
More consistent with human intuition and episodic memory
Landmark similarity can measure similarities invariant of six transformations 
A little similar to âthe semantics of sketchâ},
author = {Perng, C.-S. and Wang, H. and Zhang, S.R. and Parker, D.S.},
booktitle = {Proceedings of 16th International Conference on Data Engineering},
doi = {10.1109/icde.2000.839385},
file = {:Users/nsawada/Google Drive/Papers/Landmarks a new model for similarity-based pattern querying in time series databases.pdf:pdf},
pages = {33--42},
title = {{Landmarks: A new model for similarity-based pattern querying in time series databases}},
year = {2000}
}
@article{Pan2002,
author = {Pan, Wei},
doi = {10.1093/bioinformatics/18.4.546},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Pan - 2002 - A comparative review of statistical methods for discovering differentially expressed genes in replicated microarray experim.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {apr},
number = {4},
pages = {546--554},
publisher = {Narnia},
title = {{A comparative review of statistical methods for discovering differentially expressed genes in replicated microarray experiments}},
url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/18.4.546},
volume = {18},
year = {2002}
}
@article{Morrill1998,
abstract = {rocket launch pad, to a hospital intensive care unit, arrays of sensors are producing large volumes of information on critical systems. These environments require data analysis to reduce and sum-marize the data. People often do the data analysis, and large amounts of data often require legions of people. Unfortunately, this work is often repetitive and mun-dane. This is particularly true in the manufacturing and aerospace industries, where the same patterns repeat over and over again. The interesting part is when the pattern does not occur or does not " look right. " This might be 2{\%} of the time or less. There is a tremendous need for pattern recognition software to perform the repetitive and mundane tasks, and to focus the experts on the interesting 2{\%}.},
author = {Morrill, Jeffrey P},
doi = {10.1145/274946.274955},
file = {:Users/nsawada/Google Drive/Papers/Distributed recognition of patterns in time series data.pdf:pdf},
journal = {Communications of the ACM},
number = {5},
pages = {45--51},
title = {{Distributed recognition of patterns in time series data}},
url = {http://delivery.acm.org/10.1145/280000/274955/p45-morrill.pdf?ip=150.214.75.140{\&}id=274955{\&}acc=ACTIVE SERVICE{\&}key=DD1EC5BCF38B3699.F69573521469D136.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}CFID=774667941{\&}CFTOKEN=26932584{\&}{\_}{\_}acm{\_}{\_}=1497543311{\_}6bdacd1680a6caeb19b42bc},
volume = {41},
year = {1998}
}
@inproceedings{Lin2004,
abstract = {Moments before the launch of every space vehicle, engineering discipline specialists must make a critical go/no-go decision. The cost of a false positive, allowing a launch in spite of a fault, or a false negative, stopping a potentially successful launch, can be measured in the tens of millions of dollars, not including the cost in morale and other more intangible detriments. The Aerospace Corporation is responsible for providing engineering assessments critical to the go/no-go decision for every Department of Defense (DoD) launch vehicle. These assessments are made by constantly monitoring streaming telemetry data in the hours before launch. For this demonstration, we will introduce VizTree, a novel time-series visualization tool to aid the Aerospace analysts who must make these engineering assessments. VizTree was developed at the University of California, Riverside and is unique in that the same tool is used for mining archival data and monitoring incoming live telemetry. Unlike other time series visualization tools, VizTree can scale to very large databases, giving it the potential to be a generally useful data mining and database tool.},
annote = {Utilize sax
Highly related
Visualize time series, which are converted into SAX symbol string, as tree map
Can be applied to single variable data},
author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Lankford, Jeffrey P. and Nystrom, Daonna M.},
booktitle = {Proceedings 2004 VLDB Conference},
doi = {10.1016/b978-012088469-8/50124-8},
file = {:Users/nsawada/Google Drive/Papers/VizTree A Tool for Visually Mining and Monitoring Massive Time Series Databases.PDF:PDF},
pages = {1269--1272},
title = {{VizTree: A tool for visually mining and monitoring massive time series databases}},
year = {2004}
}
@inproceedings{Liu2005,
abstract = {Finding motifs in time-series is proposed to make clustering of time-series subsequences meaningful, because most existing algorithms of clustering time-series subsequences are reported meaningless in recent studies. The existing motif finding algorithms emphasize the efficiency at the expense of quality, in terms of the number of time-series subse-quences in a motif and the total number of motifs found. In this paper, we formalize the problem as a continuous top-k motif balls problem in an m-dimensional space, and propose heuristic approaches that can significantly improve the quality of motifs with reasonable overhead, as shown in our experimental studies. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {Liu, Zheng and Yu, Jeffrey Xu and Lin, Xuemin and Lu, Hongjun and Wang, Wei},
booktitle = {Proceedings of Advances in Knowledge Discovery and Data Mining},
doi = {10.1007/11430919_41},
file = {:Users/nsawada/Google Drive/Papers/Locating motifs in time series.pdf:pdf},
pages = {343--353},
title = {{Locating motifs in time-series data}},
volume = {3518},
year = {2005}
}
@inproceedings{Lin2004a,
abstract = {Moments before the launch of every space vehicle, engineering discipline specialists must make a critical go/no-go decision. The cost of a false positive, allowing a launch in spite of a fault, or a false negative, stopping a potentially successful launch, can be measured in the tens of millions of dollars, not including the cost in morale and other more intangible detriments. The Aerospace Corporation is responsible for providing engineering assessments critical to the go/no-go decision for every Department of Defense space vehicle. These assessments are made by constantly monitoring streaming telemetry data in the hours before launch. We will introduce VizTree, a novel time-series visualization tool to aid the Aerospace analysts who must make these engineering assessments. VizTree was developed at the University of California, Riverside and is unique in that the same tool is used for mining archival data and monitoring incoming live telemetry. The use of a single tool for both aspects of the task allows a natural and intuitive transfer of mined knowledge to the monitoring task. Our visualization approach works by transforming the time series into a symbolic representation, and encoding the data in a modified suffix tree in which the frequency and other properties of patterns are mapped onto colors and other visual properties. We demonstrate the utility of our system by comparing it with state-of-the-art batch algorithms on several real and synthetic datasets.},
annote = {Utilize VizTree},
author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Lankford, Jeffrey P. and Nystrom, Donna M.},
booktitle = {Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
doi = {10.1145/1014052.1014104},
file = {:Users/nsawada/Google Drive/Papers/Visually mining and monitoring massive time series.pdf:pdf},
isbn = {1581138881},
pages = {460--469},
title = {{Visually mining and monitoring massive time series}},
year = {2004}
}
@inproceedings{Lin2003,
abstract = {The parallel explosions of interest in streaming data, and data mining of time series have had surprisingly little intersection. This is in spite of the fact that time series data are typically streaming data. The main reason for this apparent paradox is the fact that the vast majority of work on streaming data explicitly assumes that the data is discrete, whereas the vast majority of time series data is real valued.Many researchers have also considered transforming real valued time series into symbolic representations, nothing that such representations would potentially allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities, in addition to allowing formerly "batch-only" problems to be tackled by the streaming community. While many symbolic representations of time series have been introduced over the past decades, they all suffer from three fatal flaws. Firstly, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Secondly, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. Finally, most of these symbolic approaches require one to have access to all the data, before creating the symbolic representation. This last feature explicitly thwarts efforts to use the representations with streaming algorithms.In this work we introduce a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. Finally, our representation allows the real valued data to be converted in a streaming fashion, with only an infinitesimal time and space overhead.We will demonstrate the utility of our representation on the classic data mining tasks of clustering, classification, query by content and anomaly detection.},
annote = {Utilize SAX
Similarity computation for SAX symbolic representation},
author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill},
booktitle = {Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery},
file = {:Users/nsawada/Google Drive/Papers/A Symbolic Representation of Time Series, with Implications for streaming algorithms.pdf:pdf},
keywords = {data mining,data streams,discretize,symbolic,time series},
pages = {2--11},
title = {{A symbolic representation of time series with implication for streaming algorithms}},
year = {2003}
}
@incollection{Hochheiser2001,
abstract = {{\textcopyright} Springer-Verlag Berlin Heidelberg 2001.Widespread interest in discovering features and trends in time- series has generated a need for tools that support interactive exploration.This paper introduces timeboxes: a powerful direct-manipulation metaphor for the specification of queries over time series datasets. Our TimeSearcher implementation of timeboxes supports interactive formulation and modification of queries, thus speeding the process of exploring time series data sets and guiding data mining.},
annote = {TimeSearcher paper},
author = {Hochheiser, Harry and Shneiderman, Ben},
booktitle = {Discovery Science},
doi = {10.1016/b978-155860915-0/50039-1},
file = {:Users/nsawada/Google Drive/Papers/InteractiveExplorationOfTimeSe.pdf:pdf},
pages = {441----446},
title = {{Interactive exploration of time series data}},
volume = {2226},
year = {2001}
}
@inproceedings{Kincaid2006,
abstract = {Scientific measurements are often depicted as line graphs. State-of-the-art high throughput systems in life sciences, telemetry and electronics measurement rapidly generate hundreds to thousands of such graphs. Despite the increasing volume and ubiquity ...},
annote = {Kind of related to SAX navigator paper
Show a large collection of time series in one window
Can cluster them},
author = {Kincaid, Robert and Lam, Heidi},
booktitle = {Proceedings of the working conference on Advanced visual interfaces},
doi = {10.1145/1133265.1133348},
file = {:Users/nsawada/Google Drive/Papers/line graph explore scalable display of line graphs using Focus Context.pdf:pdf},
isbn = {1595933530},
keywords = {context,focus,line graph},
pages = {404--411},
title = {{Line graph explorer: Scalable display of line graphs using Focus+Context}},
year = {2006}
}
@article{Chakrabarti2002,
annote = {Dimensional reduction method for time series data
Similar to SAX},
author = {Chakrabarti, Kaushik and Keogh, Eamonn and Mehrotra, Sharad and Pazzani, Michael},
file = {:Users/nsawada/Google Drive/Papers/Locally adaptive dimensionality reduction for indexing large time series databases.pdf:pdf},
journal = {ACM Transactions on Database Systems},
number = {2},
pages = {188--228},
title = {{Locally adaptive dimensionality reduction for indexing large time series databases}},
volume = {27},
year = {2002}
}
@inproceedings{Shatkay1996,
abstract = {Many new database application domains such as experimental sciences and medicine are characterized by large sequences as their main form of data. Using approximate representation can significantly reduce the required storage and search space. A good choice of representation, can support a broad new class of approximate queries, needed in there domains. These queries are concerned with application dependent features of the data as opposed to the actual sampled points. We introduce a new notion of generalized approximate queries and a general divide and conquer approach that supports them. This approach uses families of real-valued functions as an approximate representation. We present an algorithm for realizing our technique, and the results of applying it to medical cardiology data},
annote = {Can be related when matching queries to the actual time series},
author = {Shatkay, Hagit and Zdonik, Stanley B.},
booktitle = {Proceedings of the Twelfth International Conference on Data Engineering},
doi = {10.1109/icde.1996.492204},
file = {:Users/nsawada/Google Drive/Papers/Approximate Queries and Representations for Large Data Sequences.pdf:pdf},
pages = {1063--6382},
title = {{Approximate queries and representations for large data sequences}},
year = {1996}
}
@inproceedings{Keogh2002,
abstract = {Relatively few query tools exist for data exploration and pattern identification in time series data sets. In previous work we introduced Time-boxes. Timeboxes are rectangular, direct-manipulation queries for studying time-series datasets. We demonstrated how Timeboxes can be used to support interactive exploration via dynamic queries, along with overviews of query results and drag-and-drop support for query-by-example. In this paper, we extend our work by introducing Variable Time Timeboxes (VTT). VTTs are a natural generalization of Timeboxes, which permit the specification of queries that allow a degree of uncertainty in the time axis. We carefully motivate the need for these more expressive queries, and demonstrate the utility of our approach on several data sets. {\textcopyright} Springer-Verlag Berlin Heidelberg 2002.},
annote = {Timesearcher paper},
author = {Keogh, Eamonn and Hochheiser, Harry and Shneiderman, Ben},
booktitle = {Proceedings of the 5th International Conference on Flexible Query Answering Systems},
doi = {10.1007/3-540-36109-x_19},
file = {:Users/nsawada/Google Drive/Papers/An Augmented Visual Query Mechanism for Finding Patterns in Time Series Data.pdf:pdf},
pages = {240--250},
title = {{An augmented visual query mechanism for finding patterns in time series data}},
year = {2002}
}
@article{Hochheiser2004,
abstract = {Timeboxes are rectangular widgets that can be used in direct-manipulation graphical user interfaces (GUIs) to specify query constraints on time series data sets. Timeboxes are used to specify simultaneously two sets of constraints: given a set of N time series profiles, a timebox covering time periods x1{\ldots}x2 (x1 â¤ x2) and values y1{\ldots}y2 (y1 â¤ y2) will retrieve only those nâN that have values y1 â¤ y2 during all times x1 â¤ x â¤ x2. TimeSearcher is an information visualization tool that combines timebox queries with overview displays, query-by-example facilities, and support for queries over multiple time-varying attributes. Query manipulation tools including pattern inversion and âleaders {\&} laggards' graphical bookmarks provide additional support for interactive exploration of data sets. Extensions to the basic timebox model that provide additional expressivity include variable time timeboxes, which can be used to express queries with variability in the time interval, and angular queries, which search for ranges of differentials, rather than absolute values. Analysis of the algorithmic requirements for providing dynamic query performance for timebox queries showed that a sequential search outperformed searches based on geometric indices. Design studies helped identify the strengths and weaknesses of the query tools. Extended case studies involving the analysis of two different types of data from molecular biology experiments provided valuable feedback and validated the utility of both the timebox model and the TimeSearcher tool. Timesearcher is available at http://www.cs.umd.edu/hcil/timesearcher. {\textcopyright} 2004, SAGE Publications. All rights reserved.},
annote = {The widget of timesearcher
Kind of filtering?
Very straightforward, just filter time series by value range (box metaphor)},
author = {Hochheiser, Harry and Shneiderman, Ben},
doi = {10.1057/palgrave.ivs.9500061},
file = {:Users/nsawada/Google Drive/Papers/Dynamic Query Tools for Time Series Data Sets Timebox Widgets for Interactive Exploration.pdf:pdf},
issn = {14738724},
journal = {Information Visualization},
keywords = {TimeSearcher,angular queries,bioinformatics,dynamic query,graphical user interfaces,temporal data,time series,timeboxes,visual query},
number = {1},
pages = {1--18},
title = {{Dynamic query tools for time series data sets: Timebox widgets for interactive exploration}},
volume = {3},
year = {2004}
}
@article{Hao2007,
abstract = {Time series data commonly occur when variables are monitored over time. Many real-world applications involve the comparison of long time series across multiple variables (multi-attributes). Often business people want to compare this year's monthly sales with last year's sales to make decisions. Data warehouse administrators (DBAs) want to know their daily data loading job performance. DBAs need to detect the outliers early enough to act upon them. In this paper, two new visual analytic techniques are introduced: The color cell-based Visual Time Series Line Charts and Maps highlight significant changes over time in a long time series data and the new Visual Content Query facilitates finding the contents and histories of interesting patterns and anomalies, which leads to root cause identification. We have applied both methods to two real-world applications to mine enterprise data warehouse and customer credit card fraud data to illustrate the wide applicability and usefulness of these techniques.},
annote = {Visual analytics for multi-attributes time series data
Cell-based visualization 
Color encodes other attributes },
author = {Hao, Ming C. and Dayal, Umeshwar and Keim, Daniel A.},
doi = {10.1117/12.768568},
file = {:Users/nsawada/Google Drive/Papers/Visual Analytics Techniques for large multi-attribute time series data.pdf:pdf},
journal = {Visualization and Data Analysis 2008},
keywords = {contents and relationships,multi-attribute data,time series,visual analytics,visual content query},
number = {680908},
pages = {680908:1--680908:10},
title = {{Visual analytics techniques for large multi-attribute time series data}},
volume = {6809},
year = {2007}
}
@inproceedings{Holz2009,
abstract = {Time-series graphs are often used to visualize phenomena that change over time. Common tasks include comparing values at different points in time and searching for specified patterns, either exact or approximate. However, tools that support time-series graphs typically separate query specification from the actual search process, allowing users to adapt the level of similarity only after specifying the pattern. We introduce relaxed selection techniques, in which users implicitly define a level of similarity that can vary across the search pattern, while creating a search query with a single-gesture interaction. Users sketch over part of the graph, establishing the level of similarity through either spatial deviations from the graph, or the speed at which they sketch (temporal deviations). In a user study, participants were significantly faster when using our temporally relaxed selection technique than when using traditional techniques. In addition, they achieved significantly higher precision and recall with our spatially relaxed selection technique compared to traditional techniques. Copyright 2009 ACM.},
annote = {Related! Interesting!
Unique way of drawing queries},
author = {Holz, Christian and Feiner, Steven},
booktitle = {Proceedings of the 22nd Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/1622176.1622217},
file = {:Users/nsawada/Google Drive/Papers/Relaxed Selection Techniques for Querying Time-Series Graphs.pdf:pdf},
isbn = {9781605587455},
keywords = {advantage and that copies,all or part of,for profit or commercial,is granted without fee,not made or distributed,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,similarity queries,this work for,time-series data},
pages = {213--222},
title = {{Relaxed selection techniques for querying time-series graphs}},
year = {2009}
}
@inproceedings{Gogolou2019,
author = {Gogolou, Anna and Tsandilas, Theophanis and Palpanas, Themis and Bezerianos, Anastasia},
booktitle = {Proceedings of the EDBT/ICDT 2019 Joint Conference},
file = {:Users/nsawada/Google Drive/Papers/Progressive Similarity Search on Time Series Data.pdf:pdf},
keywords = {analytics,progressive error,progressive similarity search,progressive visual,time series},
title = {{Progressive Similarity Search on Time Series Data [ Vision Paper ]}},
year = {2019}
}
@inproceedings{Haigh2004,
abstract = {Many scientific datasets archive a large number of variables over time. These timeseries data streams typically track many variables over relatively long periods of time, and therefore are often both wide and deep. In this paper, we describe the Visual Query Language (VQL) [3], a technology for locat- ing time series patterns in historical or real time data. The user interactively specifies a search pattern, VQL finds sim- ilar shapes, and returns a ranked list of matches. VQL sup- ports both univariate and multivariate queries, and allows the user to interactively specify the the quality of the match, in- cluding temporal warping, amplitude warping, and temporal constraints between features.},
annote = {Related! Interesting!},
author = {Haigh, Karen Zita and Foslien, Wendy and Guralnik, Valerie},
booktitle = {Proceedings of Seventh Workshop on Mining Scientific and Engineering Datasets},
file = {:Users/nsawada/Google Drive/Papers/Visual Query Language finding patterns in and relationships among time series data.pdf:pdf},
pages = {324--332},
title = {{Visual Query Language: Finding patterns in and relationships among time series data}},
year = {2004}
}
@article{Hochheiser2002,
abstract = {Few tools exist for data exploration and pattern iden-$\backslash$ntification in time series data sets. Timeboxes are rectan-$\backslash$ngular, direct-manipulation queries for studying time-series$\backslash$ndatasets. Timeboxes are the primary query tool in our Time-$\backslash$nSearcher application, which supports interactive explo-$\backslash$nration via dynamic queries, along with overviews of query$\backslash$nresults and drag-and-drop support for query-by-example.$\backslash$nThis paper describes the TimeSearcher application and pos-$\backslash$nsible extensions to the timebox query model, along with a$\backslash$ndiscussion of the use of TimeSearcher for exploring a time$\backslash$nseries data set involving gene expression profiles.},
annote = {Timesearcher paper},
author = {Hochheiser, H. and Shneiderman, B.},
file = {:Users/nsawada/Google Drive/Papers/Visual Queries for Finding Patterns in Time Series Data.pdf:pdf},
journal = {University of Maryland, Computer Science Dept. Tech Report, CS-TR-4365},
keywords = {dynamic,information visualization,time series data},
title = {{Visual queries for finding patterns in time series data}},
year = {2002}
}
@article{Subramonyam2019,
abstract = {Details-on-demand is a crucial feature in the visual information-seeking process but is often only implemented in highly constrained settings. The most common solution, hover queries (i.e., tooltips), are fast and expressive but are usually limited to single mark (e.g., a bar in a bar chart). âQueries' to retrieve details for more complex sets of objects (e.g., comparisons between pairs of elements, averages across multiple items, trend lines, etc.) are difficult for end-users to invoke explicitly. Further, the {\textless}italic{\textgreater}output{\textless}/italic{\textgreater} of these queries require complex annotations and overlays which need to be displayed and dismissed on demand to avoid clutter. In this work we introduce SmartCues, a library to support details-on-demand through dynamically computed overlays. For end-users, SmartCues provides multitouch interactions to construct complex queries for a variety of details. For designers, SmartCues offers an interaction library that can be used out-of-the-box, and can be extended for new charts and detail types. We demonstrate how SmartCues can be implemented across a wide array of visualization types and, through a lab study, show that end users can effectively use SmartCues.},
annote = {Various interactions to show details-on-demand},
author = {Subramonyam, Hariharan and Adar, Eytan},
doi = {10.1109/TVCG.2018.2865231},
file = {:Users/nsawada/Google Drive/Papers/SmartCues A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays.pdf:pdf},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Graphical overlays,details-on-demand,graph comprehension},
number = {1},
pages = {597--607},
title = {{SmartCues: A multitouch query approach for details-on-demand through dynamically computed overlays}},
volume = {25},
year = {2019}
}
@inproceedings{Nielsen2016,
author = {Nielsen, Matthias and Elmqvist, Niklas and Gr{\o}nb{\ae}k, Kaj},
doi = {10.1145/3010915.3010951},
file = {:Users/nsawada/Google Drive/Papers/Scribble Query Fluid Touch Brushing for Multivariate.pdf:pdf},
isbn = {9781450346184},
journal = {Proceedings of the 28th Australian Conference on Computer-Human Interaction},
keywords = {information visualization,interaction techniques,touch interaction},
pages = {381--390},
title = {{Scribble query: Fluid touch brushing for multivariate data visualization}},
year = {2016}
}
@article{Chen2018,
abstract = {Event sequences analysis plays an important role in many application domains such as customer behavior analysis, electronic health record analysis and vehicle fault diagnosis. Real-world event sequence data is often noisy and complex with high event cardinality, making it a challenging task to construct concise yet comprehensive overviews for such data. In this paper, we propose a novel visualization technique based on the minimum description length (MDL) principle to construct a coarse-level overview of event sequence data while balancing the information loss in it. The method addresses a fundamental trade-off in visualization design: reducing visual clutter vs. increasing the information content in a visualization. The method enables simultaneous sequence clustering and pattern extraction and is highly tolerant to noises such as missing or additional events in the data. Based on this approach we propose a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. We demonstrate the usability and effectiveness of our approach through case studies with two real-world datasets. One dataset showcases a new application domain for event sequence visualization, i.e., fault development path analysis in vehicles for predictive maintenance. We also discuss the strengths and limitations of the proposed method based on user feedback.},
author = {Chen, Yuanzhe and Xu, Panpan and Ren, Liu},
doi = {10.1109/TVCG.2017.2745083},
file = {:Users/nsawada/Google Drive/Papers/Sequence Synopsis Optimize Visual Summary of Temporal Event Data.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data Transformation and Representation,Time Series Data,Visual Analytics,Visual Knowledge Representation},
number = {1},
pages = {45--55},
publisher = {IEEE},
title = {{Sequence Synopsis: Optimize Visual Summary of Temporal Event Data}},
volume = {24},
year = {2018}
}
@article{Zhao2018,
abstract = {Skyline queries have wide-ranging applications in fields that involve multi-criteria decision making, including tourism, retail industry, and human resources. By automatically removing incompetent candidates, skyline queries allow users to focus on a subset of superior data items (i.e., the skyline), thus reducing the decision-making overhead. However, users are still required to interpret and compare these superior items manually before making a successful choice. This task is challenging because of two issues. First, people usually have fuzzy, unstable, and inconsistent preferences when presented with multiple candidates. Second, skyline queries do not reveal the reasons for the superiority of certain skyline points in a multi-dimensional space. To address these issues, we propose SkyLens, a visual analytic system aiming at revealing the superiority of skyline points from different perspectives and at different scales to aid users in their decision making. Two scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of attributes. A qualitative study is also conducted to show that users can efficiently accomplish skyline understanding and comparison tasks with SkyLens.},
author = {Zhao, Xun and Wu, Yanhong and Cui, Weiwei and Du, Xinnan and Chen, Yuan and Wang, Yong and Lee, Dik Lun and Qu, Huamin},
doi = {10.1109/TVCG.2017.2744738},
file = {:Users/nsawada/Google Drive/Papers/SkyLens Visual Analysis of Skyline on Multi-Dimensional Data.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Skyline query,multi-criteria decision making,multi-dimensional data,skyline visualization,visual analytics},
number = {1},
pages = {246--255},
publisher = {IEEE},
title = {{SkyLens: Visual Analysis of Skyline on Multi-Dimensional Data}},
volume = {24},
year = {2018}
}
@article{Zhu2017,
abstract = {{\textcopyright} 2017 IEEE. We investigate a subgraph mining framework, that can connect similar entities according to their structure and attribute similarities. We take one mapping between two related points chosen from the query and target graph as one vertex in the correspondence graph and decide the weight of the edge based on the similarity score. In this way, we transform the problem to a dense subgraph discovery problem. To adapt this method to large scale, we choose the candidate group by some effective pruning methods. We also add some techniques to make our method more flexible to fit uncertain user sketched input. We investigate how changes to certain parameters in the algorithm can influence the results. By integrating all these adjustments into the framework, we can provide a method that exhibits both accuracy and flexibility in many situations with a degree of generality. Experiments on both certain and uncertain query graphs can give satisfactory and informative results.},
author = {Zhu, Lingheng and Liu, Wu and Chu, Lingyang and Liu, Peiye and Gu, Xiaoyan},
doi = {10.1109/BigMM.2017.80},
file = {:Users/nsawada/Google Drive/Papers/Query from Sketch A Common Subgraph Correspondence Mining Framework.pdf:pdf},
isbn = {9781509065493},
journal = {Proceedings - 2017 IEEE 3rd International Conference on Multimedia Big Data, BigMM 2017},
keywords = {data mining,graph search,pattern recognition,similarity search},
pages = {413--418},
publisher = {IEEE},
title = {{Query from Sketch: A Common Subgraph Correspondence Mining Framework}},
year = {2017}
}
@inproceedings{Muthumanickam2016,
abstract = {{\textcopyright} 2016 IEEE. Long time-series, involving thousands or even millions of time steps, are common in many application domains but remain very difficult to explore interactively. Often the analytical task in such data is to identify specific patterns, but this is a very complex and computationally difficult problem and so focusing the search in order to only identify interesting patterns is a common solution. We propose an efficient method for exploring user-sketched patterns, incorporating the domain expert's knowledge, in time series data through a shape grammar based approach. The shape grammar is extracted from the time series by considering the data as a combination of basic elementary shapes positioned across different amplitudes. We represent these basic shapes using a ratio value, perform binning on ratio values and apply a symbolic approximation. Our proposed method for pattern matching is amplitude-, scale- and translation-invariant and, since the pattern search and pattern constraint relaxation happen at the symbolic level, is very efficient permitting its use in a real-time/online system. We demonstrate the effectiveness of our method in a case study on stock market data although it is applicable to any numeric time series data.},
annote = {Related! Interesting!},
author = {Muthumanickam, Prithiviraj K. and Vrotsou, Katerina and Cooper, Matthew and Johansson, Jimmy},
booktitle = {Proceedings of 2016 IEEE Conference on Visual Analytics Science and Technology},
doi = {10.1109/VAST.2016.7883518},
file = {:Users/nsawada/Google Drive/Papers/Shape grammar extraction for efficient query-by-sketch pattern matching in long time series.pdf:pdf},
isbn = {9781509056613},
keywords = {Regular Expression,Shape Grammar,Sketching,Symbolic approximation,Time Series,User-queries},
pages = {121--130},
title = {{Shape grammar extraction for efficient query-by-sketch pattern matching in long time series}},
year = {2016}
}
@inproceedings{Gupta2009,
author = {Gupta, Sudhanshu and Garg, Deepak},
booktitle = {Proceedings of 2009 IEEE International Advance Computing Conference},
file = {:Users/nsawada/Google Drive/Papers/Survey on Query Estimation in Data Streams.pdf:pdf},
keywords = {data streams,query estimation},
number = {March},
pages = {6--7},
title = {{Survey on query estimation in data streams}},
year = {2009}
}
@article{Egenhofer1997,
author = {Egenhofer, Max J.},
file = {:Users/nsawada/Google Drive/Papers/Query Processing in Spatial-Query-by-Sketch.pdf:pdf},
journal = {Journal of Visual Language and Computing},
number = {4},
pages = {403--424},
title = {{Query processing in spatial-query-by-sketch}},
volume = {8},
year = {1997}
}
@article{Scheidegger2007,
abstract = {Sc07},
author = {Scheidegger, Carlos E. and Vo, Huy T. and Koop, David and Freire, Juliana and Silva, Cl{\'{a}}udio T.},
doi = {10.1109/TVCG.2007.70584},
file = {:Users/nsawada/Google Drive/Papers/Querying and Creating Visualizations by Analogy.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Analogy,Query-by-example,Visualization systems},
number = {6},
pages = {1560--1567},
title = {{Querying and creating visualizations by analogy}},
volume = {13},
year = {2007}
}
@inproceedings{Wen-SyanLi2002,
author = {{Wen-Syan Li} and Candan, K.S. and Hirata, K. and Hara, Y.},
booktitle = {Proceedings of IEEE International Conference on Multimedia Computing and Systems},
doi = {10.1109/mmcs.1997.609635},
file = {:Users/nsawada/Google Drive/Papers/IFQ a visual query interface and query generator for object-based media retrieval.pdf:pdf},
isbn = {0818678194},
keywords = {dia databases,multime-,object-based media retrieval,query language,visual query interface},
pages = {353--361},
title = {{IFQ: A visual query interface and query generator for object-based media retrieval}},
year = {2002}
}
@article{Gosink2008,
abstract = {The visualization and analysis of AMR-based simulations is integral to the process of obtaining new insight in scientific research. We present a new method for performing query-driven visualization and analysis on AMR data, with specific emphasis on time-varying AMR data. Our work introduces a new method that directly addresses the dynamic spatial and temporal properties of AMR grids that challenge many existing visualization techniques. Further, we present the first implementation of query-driven visualization on the GPU that uses a GPU-based indexing structure to both answer queries and efficiently utilize GPU memory. We apply our method to two different science domains to demonstrate its broad applicability.},
author = {Gosink, Luke J. and Anderson, John C. and Bethel, E. Wes and Joy, Kenneth I.},
doi = {10.1109/TVCG.2008.157},
file = {:Users/nsawada/Google Drive/Papers/Query-Driven Visualization of Time-Varying Adaptive Mesh Refinement Data.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {AMR,Multitemporal visualization,Query-driven visualization},
number = {6},
pages = {1715--1722},
title = {{Query-driven visualization of time-varying adaptive mesh refinement data}},
volume = {14},
year = {2008}
}
@article{Gosink2007,
abstract = {Our ability to generate ever-larger, increasingly-complex data, has established the need for scalable methods that identify, and provide insight into, important variable trends and interactions. Query-driven methods are among the small subset of techniques that are able to address both large and highly complex datasets. This paper presents a new method that increases the utility of query-driven techniques by visually conveying statistical information about the trends that exist between variables in a query. In this method, correlation fields, created between pairs of variables, are used with the cumulative distribution functions of variables expressed in a user's query. This integrated use of cumulative distribution functions and correlation fields visually reveals, with respect to the solution space of the query, statistically important interactions between any three variables, and allows for trends between these variables to be readily identified. We demonstrate our method by analyzing interactions between variables in two flame-front simulations.},
author = {Gosink, Luke J. and Anderson, John C. and {Wes Bethel}, E. and Joy, Kenneth I.},
doi = {10.1109/TVCG.2007.70519},
file = {:Users/nsawada/Google Drive/Papers/Variable Interactions in Query-Driven Visualization.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Multivariate data,Query-driven visualization},
number = {6},
pages = {1400--1407},
title = {{Variable interactions in query-driven visualization}},
volume = {13},
year = {2007}
}
@article{Gosink2011,
abstract = {Driven by the ability to generate ever-larger, increasingly complex data, there is an urgent need in the scientific community for scalable analysis methods that can rapidly identify salient trends in scientific data. Query-Driven Visualization (QDV) strategies are among the small subset of techniques that can address both large and highly complex data sets. This paper extends the utility of QDV strategies with a statistics-based framework that integrates nonparametric distribution estimation techniques with a new segmentation strategy to visually identify statistically significant trends and features within the solution space of a query. In this framework, query distribution estimates help users to interactively explore their query's solution and visually identify the regions where the combined behavior of constrained variables is most important, statistically, to their inquiry. Our new segmentation strategy extends the distribution estimation analysis by visually conveying the individual importance of each variable to these regions of high statistical significance. We demonstrate the analysis benefits these two strategies provide and show how they maybe used to facilitate the refinement of constraints over variables expressed in a user's query. We apply our method to data sets from two different scientific domains to demonstrate its broad applicability. {\textcopyright} 2011 IEEE.},
author = {Gosink, Luke J. and Garth, Christoph and Anderson, John C. and Bethel, E. Wes and Joy, Kenneth I.},
doi = {10.1109/TVCG.2010.80},
file = {:Users/nsawada/Google Drive/Papers/An Application of Multivariate Statistical Analysis for Query-Driven Visualization.pdf:pdf},
isbn = {2009080165},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Query-driven visualization,kernel density estimation,kernel density estimation.,multivariate analysis},
number = {3},
pages = {264--275},
publisher = {IEEE},
title = {{An application of multivariate statistical analysis for query-driven visualization}},
volume = {17},
year = {2011}
}
@article{Assfalg2002,
abstract = {Image databases are widely exploited in a number of different contexts, ranging from history of art, through medicine, to education. Existing querying paradigms are based either on the usage of textual strings, for high-level semantic queries or on 2D visual examples for the expression of perceptual queries. Semantic queries require manual annotation of the database images. Instead, perceptual queries only require that image analysis is performed on the database images in order to extract salient perceptual features that are matched with those of the example. However, usage of 2D examples is generally inadequate as effective authoring of query images, attaining a realistic reproduction of complex scenes, needs manual editing and sketching ability. Investigation of new querying paradigms is therefore an important-yet still marginally investigated-factor for the success of content-based image retrieval. In this paper, a novel querying paradigm is presented which is based on usage of 3D interfaces exploiting navigation and editing of 3D virtual environments. Query images are obtained by taking a snapshot of the framed environment and by using the snapshot as an example to retrieve similar database images. A comparative analysis is carried out between the usage of 3D and 2D interfaces and their related query paradigms. This analysis develops on a user test on retrieval efficiency and effectiveness, as well as on an evaluation of users' satisfaction},
author = {Assfalg, J{\"{u}}rgen and {Del Bimbo}, Alberto and Pala, Pietro},
doi = {10.1109/TVCG.2002.1044517},
file = {:Users/nsawada/Google Drive/Papers/Three-dimensional interfaces for querying by example in content-based image retrieval.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {3D user interfaces,Content-based image retrieval},
number = {4},
pages = {305--318},
publisher = {IEEE},
title = {{Three-dimensional interfaces for querying by example in content-based image retrieval}},
volume = {8},
year = {2002}
}
@article{Riesenfeld2016,
author = {Riesenfeld, Richard F and Draper, Geoffrey M and Riesenfeld, Richard F},
doi = {10.1109/TVCG.2008.187},
file = {:Users/nsawada/Google Drive/Papers/Who Votes For What A Visual Query Language for Opinion Data.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {6},
pages = {1197--1204},
title = {{Who votes for what ? A visual query language for opinion data}},
volume = {14},
year = {2016}
}
@article{Rautek2014,
abstract = {{\textcopyright} 1995-2012 IEEE. Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.},
author = {Rautek, Peter and Bruckner, Stefan and Gr{\"{o}}ller, M. Eduard and Hadwiger, Markus},
doi = {10.1109/TVCG.2014.2346318},
file = {:Users/nsawada/Google Drive/Papers/ViSlang A System for Interpreted Domain-Specific Languages for Scientific Visualization.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Domain-specific languages,Volume visualization,Volume visualization framework},
number = {12},
pages = {2388--2396},
title = {{ViSlang: A system for interpreted domain-specific languages for scientific visualization}},
volume = {20},
year = {2014}
}
@article{Stolte2002,
abstract = {In the last several years, large multidimensional databases have$\backslash$nbecome common in a variety of applications, such as data warehousing and$\backslash$nscientific computing. Analysis and exploration tasks place significant$\backslash$ndemands on the interfaces to these databases. Because of the size of the$\backslash$ndata sets, dense graphical representations are more effective for$\backslash$nexploration than spreadsheets and charts. Furthermore, because of the$\backslash$nexploratory nature of the analysis, it must be possible for the analysts$\backslash$nto change visualizations rapidly as they pursue a cycle involving first$\backslash$nhypothesis and then experimentation. In this paper, we present Polaris,$\backslash$nan interface for exploring large multidimensional databases that extends$\backslash$nthe well-known pivot table interface. The novel features of Polaris$\backslash$ninclude an interface for constructing visual specifications of$\backslash$ntable-based graphical displays and the ability to generate a precise set$\backslash$nof relational queries from the visual specifications. The visual$\backslash$nspecifications can be rapidly and incrementally developed, giving the$\backslash$nanalyst visual feedback as he constructs complex queries and$\backslash$nvisualizations},
author = {Stolte, Chris and Tang, Diane and Hanrahan, Pat},
doi = {10.1109/2945.981851},
file = {:Users/nsawada/Google Drive/Papers/Polaris a system for query, analysis, and visualization of multidimensional relational databases.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Database analysis,Database visualization,Multidimensional databases,Visualization formalism},
number = {1},
pages = {52--65},
publisher = {IEEE},
title = {{Polaris: A system for query, analysis, and visualization of multidimensional relational databases}},
volume = {8},
year = {2002}
}
@article{Bruckner2009,
abstract = {Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented BrainGazer, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.},
author = {Bruckner, Stefan and \v{S}olteszova, Veronika and Groller, Eduard and Hlad\r{u}vka, Ji\v{r}\'{\i} and Buhler, Katja and Yu, Jai Y. and Dickson, Barry J.},
doi = {10.1109/TVCG.2009.121},
file = {:Users/nsawada/Google Drive/Papers/BrainGazer - Visual Queries for Neurobiology Research.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Biomedical visualization,neurobiology,visual queries,volume visualization},
number = {6},
pages = {1497--1504},
title = {{BrainGazer - Visual queries for neurobiology research}},
volume = {15},
year = {2009}
}
@article{Weaver2010,
abstract = {Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: 1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views and 2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. We also identify several important limitations of the approach. The demonstrated analytic utility of these examples suggests that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools.},
author = {Weaver, Chris},
doi = {10.1109/TVCG.2009.94},
file = {:Users/nsawada/Google Drive/Papers/Cross-Filtered Views for Multidimensional Visual Analysis.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Coordinated views,Information visualization,Interactive data exploration and discovery,Multidimensional visual analysis.},
number = {2},
pages = {192--204},
publisher = {IEEE},
title = {{Cross-filtered views for multidimensional visual analysis}},
volume = {16},
year = {2010}
}
@article{Pienta2018,
abstract = {{\textcopyright} 1995-2012 IEEE. Finding patterns in graphs has become a vital challenge in many domains from biological systems, network security, to finance (e.g., finding money laundering rings of bankers and business owners). While there is significant interest in graph databases and querying techniques, less research has focused on helping analysts make sense of underlying patterns within a group of subgraph results. Visualizing graph query results is challenging, requiring effective summarization of a large number of subgraphs, each having potentially shared node-values, rich node features, and flexible structure across queries. We present VIGOR, a novel interactive visual analytics system, for exploring and making sense of query results. VIGOR uses multiple coordinated views, leveraging different data representations and organizations to streamline analysts sensemaking process. VIGOR contributes: (1) an exemplar-based interaction technique, where an analyst starts with a specific result and relaxes constraints to find other similar results or starts with only the structure (i.e., without node value constraints), and adds constraints to narrow in on specific results; and (2) a novel feature-aware subgraph result summarization. Through a collaboration with Symantec, we demonstrate how VIGOR helps tackle real-world problems through the discovery of security blindspots in a cybersecurity dataset with over 11,000 incidents. We also evaluate VIGOR with a within-subjects study, demonstrating VIGOR's ease of use over a leading graph database management system, and its ability to help analysts understand their results at higher speed and make fewer errors.},
author = {Pienta, Robert and Hohman, Fred and Endert, Alex and Tamersoy, Acar and Roundy, Kevin and Gates, Chris and Navathe, Shamkant and Chau, Duen Horng},
doi = {10.1109/TVCG.2017.2744898},
file = {:Users/nsawada/Google Drive/Papers/VIGOR Interactive Visual Exploration of Graph Query Results.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {graph querying,query result visualization,subgraph results},
number = {1},
pages = {215--225},
publisher = {IEEE},
title = {{VIGOR: Interactive visual exploration of graph query results}},
volume = {24},
year = {2018}
}
@article{Krause2016,
abstract = {Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.},
author = {Krause, Josua and Perer, Adam and Stavropoulos, Harry},
doi = {10.1109/TVCG.2015.2467622},
file = {:Users/nsawada/Google Drive/Papers/Supporting Iterative Cohort Construction with Visual Temporal Queries.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Databases,Diseases,Junctions,Medical diagnostic imaging,Sociology,Statistics,Visualization},
number = {1},
pages = {91--100},
publisher = {IEEE},
title = {{Supporting iterative cohort construction with visual temporal queries}},
volume = {22},
year = {2016}
}
@article{Xia2018,
abstract = {{\textcopyright} 1995-2012 IEEE. Many approaches for analyzing a high-dimensional dataset assume that the dataset contains specific structures, e.g., clusters in linear subspaces or non-linear manifolds. This yields a trial-and-error process to verify the appropriate model and parameters. This paper contributes an exploratory interface that supports visual identification of low-dimensional structures in a high-dimensional dataset, and facilitates the optimized selection of data models and configurations. Our key idea is to abstract a set of global and local feature descriptors from the neighborhood graph-based representation of the latent low-dimensional structure, such as pairwise geodesic distance (GD) among points and pairwise local tangent space divergence (LTSD) among pointwise local tangent spaces (LTS). We propose a new LTSD-GD view, which is constructed by mapping LTSD and GD to the x axis and y axis using 1D multidimensional scaling, respectively. Unlike traditional dimensionality reduction methods that preserve various kinds of distances among points, the LTSD-GD view presents the distribution of pointwise LTS (x axis) and the variation of LTS in structures (the combination of x axis and y axis). We design and implement a suite of visual tools for navigating and reasoning about intrinsic structures of a high-dimensional dataset. Three case studies verify the effectiveness of our approach.},
author = {Xia, Jiazhi and Ye, Fenjin and Chen, Wei and Wang, Yusi and Chen, Weifeng and Ma, Yuxin and Tung, Anthony K.H.},
doi = {10.1109/TVCG.2017.2744098},
file = {:Users/nsawada/Google Drive/Papers/LDSSCANNER EXPLORATORY ANALYSIS OF LOW-DIMENSIONAL STRUCTURES IN HIGH-DIMENSIONAL DATASETS.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {High-dimensional data,low-dimensional structure,manifold,subspace,visual exploration},
number = {1},
pages = {236--245},
publisher = {IEEE},
title = {{LDSScanner: Exploratory analysis of low-dimensional structures in high-dimensional datasets}},
volume = {24},
year = {2018}
}
@inproceedings{Haag2016,
address = {Rome, Italy},
author = {Haag, Florian and Kr{\"{u}}ger, Robert and Ertl, Thomas},
booktitle = {Proceedings of the 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
doi = {10.5220/0005716900480059},
file = {:Users/nsawada/Google Drive/Papers/VESPa A Pattern-based Visual Query Language for Event Sequences.pdf:pdf},
isbn = {9789897581755},
pages = {48--59},
title = {{VESPa: A Pattern-based Visual Query Language for Event Sequences}},
volume = {2},
year = {2016}
}
@inproceedings{Haag2016a,
author = {Haag, Florian and Kr{\"{u}}eger, Robert and Ertl, Thomas},
booktitle = {Proceedings of International Joint Conference on Computer Vision, Imaging and Computer Graphics},
doi = {10.1007/978-3-319-64870-5},
file = {:Users/nsawada/Google Drive/Papers/Visual Querying of Semantically Enriched movement data.pdf:pdf},
isbn = {978-3-319-64869-9},
keywords = {semantic movement analysis,visual query language},
pages = {242--263},
publisher = {Springer, Cham},
title = {{Visual querying of semantically enriched movement data}},
url = {http://link.springer.com/10.1007/978-3-319-64870-5},
volume = {693},
year = {2016}
}
@inproceedings{Krueger2016,
abstract = {Geo-tagged microblog data covers billions of movement patterns on a global and local scale. Understanding these patterns could guide urban and traffic planning or help coping with disaster situations. We present a visual analytics system to investigate travel trajectories of people reconstructed from microblog messages. To analyze seasonal changes and events and to validate movement patterns against other data sources, we contribute highly interactive visual comparison methods that normalize and contrast trajectories as well as density maps within a single view. We also compute an adaptive hierarchical graph from the trajectories to abstract individual movements into higher-level structures. Specific challenges that we tackle are, among others, the spatio-temporal sparsity of the data, the volume of data varying by region, and a diverse mix of means of transportation. The applicability of our approach is presented in three case studies.},
author = {Kr{\"{u}}eger, Robert and Sun, Guodao and Beck, Fabian and Liang, Ronghua and Ertl, Thomas},
booktitle = {Proceedings of 2016 IEEE Pacific Visualization Symposium},
doi = {10.1109/PACIFICVIS.2016.7465266},
file = {:Users/nsawada/Google Drive/Papers/TravelDiff Visual comparison analytics for massive movement patterns derived from Twitter.pdf:pdf},
isbn = {9781509014514},
issn = {21658773},
pages = {176--183},
publisher = {IEEE},
title = {{TravelDiff: Visual comparison analytics for massive movement patterns derived from Twitter}},
year = {2016}
}
@article{Seo2002,
abstract = {To date, work in microarrays, sequenced genomes, and bioinformatics has focused largely on algorithmic methods for processing and manipulating vast biological data sets. Future improvements will likely provide users with guidance in selecting the most appropriate algorithms and metrics for identifying meaningful clusters-interesting patterns in large data sets, such as groups of genes with similar profiles. Hierarchical clustering has been shown to be effective in microarray data analysis for identifying genes with similar profiles and thus possibly with similar functions. Users also need an efficient visualization tool, however, to facilitate pattern extraction from microarray data sets. The Hierarchical Clustering Explorer integrates four interactive features to provide information visualization techniques that allow users to control the processes and interact with the results. Thus, hybrid approaches that combine powerful algorithms with interactive visualization tools will join the strengths of fast processors with the detailed understanding of domain experts.},
author = {Seo, Jinwook and Shneiderman, Ben},
doi = {10.1109/MC.2002.1016905},
file = {:Users/nsawada/Google Drive/Papers/Interactively exploring hierarchical clustering results.pdf:pdf},
issn = {00189162},
journal = {Computer},
number = {7},
pages = {80--86},
publisher = {IEEE},
title = {{Interactively exploring hierarchical clustering results [gene identification]}},
volume = {35},
year = {2002}
}
@article{Kwon2018,
abstract = {Clustering, the process of grouping together similar items into distinct partitions, is a common type of unsupervised machine learning that can be useful for summarizing and aggregating complex multi-dimensional data. However, data can be clustered in many ways, and there exist a large body of algorithms designed to reveal different patterns. While having access to a wide variety of algorithms is helpful, in practice, it is quite difficult for data scientists to choose and parameterize algorithms to get the clustering results relevant for their dataset and analytical tasks. To alleviate this problem, we built Clustervision, a visual analytics tool that helps ensure data scientists find the right clustering among the large amount of techniques and parameters available. Our system clusters data using a variety of clustering techniques and parameters and then ranks clustering results utilizing five quality metrics. In addition, users can guide the system to produce more relevant results by providing task-relevant constraints on the data. Our visual user interface allows users to find high quality clustering results, explore the clusters using several coordinated visualization techniques, and select the cluster result that best suits their task. We demonstrate this novel approach using a case study with a team of researchers in the medical domain and showcase that our system empowers users to choose an effective representation of their complex data.},
author = {Kwon, Bum Chul and Eysenbach, Ben and Verma, Janu and Ng, Kenney and {De Filippi}, Christopher and Stewart, Walter F. and Perer, Adam},
doi = {10.1109/TVCG.2017.2745085},
file = {:Users/nsawada/Google Drive/Papers/Clustervision Visual Supervision of Unsupervised Clustering.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Interactive Visual Clustering,Quality Metrics,Unsupervised Clustering,Visual Analytics},
number = {1},
pages = {142--151},
title = {{Clustervision: Visual Supervision of Unsupervised Clustering}},
volume = {24},
year = {2018}
}
@article{Cavallo2019,
abstract = {Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce $\backslash$textit{\{}Clustrophile{\~{}}2{\}}, a new interactive tool for guided clustering analysis. $\backslash$textit{\{}Clustrophile{\~{}}2{\}} guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, $\backslash$textit{\{}Clustrophile{\~{}}2{\}} contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate $\backslash$textit{\{}Clustrophile{\~{}}2{\}} through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson's disease patients. Results suggest that $\backslash$textit{\{}Clustrophile{\~{}}2{\}} improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.},
author = {Cavallo, Marco and Demiralp, {\c{C}}aÇ§atay},
doi = {10.1109/TVCG.2018.2864477},
file = {:Users/nsawada/Google Drive/Papers/Clustrophile 2 Guided Visual Clustering Analysis.pdf:pdf},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Clustering tour,Clustrophile,Dimensionality reduction,Explainability,Exploratory data analysis,Guided data analysis,Interactive clustering analysis,Interpretability,Unsupervised learning,Visual data exploration recommendation,What-if analysis},
number = {1},
pages = {267--276},
publisher = {IEEE},
title = {{Clustrophile 2: Guided Visual Clustering Analysis}},
volume = {25},
year = {2019}
}
@article{Aigner2005,
abstract = {Dealing with temporal uncertainties is a key issue in domains like project management or medical treatment planning. However, support for temporal indeterminacies is not very well integrated in current methods, techniques, and tools. In this paper, we present a visualization technique called PlanningLines that allows for representing temporal uncertainties and aims at supporting project managers in their difficult planning and controlling tasks. We conducted a controlled experiment to gather empirical evidence on the strengths and limitations of our approach. Main results are that PlanningLine users make fewer mistakes and are faster in conducting tasks than users of a traditional visualization technique.},
author = {Aigner, Wolfgang and Miksch, Silvia and Thurnher, Bettina and Biffl, Stefan},
doi = {10.1109/IV.2005.97},
file = {:Users/nsawada/Google Drive/Papers/PlanningLines novel glyphs for representing temporal uncertainties and their evaluation.pdf:pdf},
isbn = {0769523978},
issn = {10939547},
journal = {Proceedings of the International Conference on Information Visualisation},
keywords = {Glyph,Project management,Temporal data,Uncertainty,Usability study},
pages = {457--463},
title = {{PlanningLines: Novel glyphs for representing temporal uncertainties and their evaluation}},
volume = {2005},
year = {2005}
}
@article{Lammarsch2009,
abstract = {Many real-world problems involve time-oriented data. Time data is different from other kinds of data--explicitly harnessing the structures of time in visualizations can guide and support userspsila visual analysis processes. State-of-the-art visualizations hardly take advantage of the structures of time to aid users in understanding and exploring the data. To bring more flexibility to the analysis process, we have developed interactive visual methods incorporating the structures of time within a pixel-based visualization called GROOVE (granular overview overlay). GROOVE uses different techniques to visualize time-oriented data by overlaying several time granularities in one visualization and provides interactive operators, which utilize the structures of time in different ways to capture and explore time-oriented data.},
author = {Lammarsch, T. and Aigner, W. and Bertone, A. and G{\"{a}}rtner, J. and Mayr, E. and Miksch, S. and Smuc, M.},
doi = {10.1109/IV.2009.52},
file = {:Users/nsawada/Google Drive/Papers/Hierarchical Temporal Patterns and Interactive Aggregated Views.pdf:pdf},
isbn = {9780769537337},
issn = {10939547},
journal = {Proceedings of the International Conference on Information Visualisation},
pages = {44--50},
title = {{Hierarchical temporal patterns and interactive aggregated views for pixel-based visualizations}},
year = {2009}
}
@article{Liu2013a,
abstract = {Data analysts must make sense of increasingly large data sets, sometimes with billions or more records.We present methods for interactive visualization of big data, following the principle that perceptual and interactive scalability should be limited by the chosen resolution of the visualized data, not the number of records. We first describe a design space of scalable visual summaries that use data reduction methods (such as binned aggregation or sampling) to visualize a variety of data types. We then contribute methods for interactive querying (e.g., brushing {\&}linking) among binned plots through a combination of multivariate data tiles and parallel query processing.We implement our techniques in imMens, a browser-based visual analysis system that usesWebGL for data processing and rendering on the GPU. In benchmarks imMens sustains 50 frames-per-second brushing {\&} linking among dozens of visualizations, with invariant performance on data sizes ranging from thousands to billions of records.},
author = {Liu, Zhicheng and Jiang, Biye and Heer, Jeffrey},
doi = {10.1111/cgf.12129},
file = {:Users/nsawada/Google Drive/Papers/Liu{\_}et{\_}al-2013-Computer{\_}Graphics{\_}Forum.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
number = {3 PART4},
pages = {421--430},
title = {{imMens: Real-time visual querying of big data}},
volume = {32},
year = {2013}
}
@article{Wongsuphasawat2018,
abstract = {IEEE We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model {\&} {\#}x0027;s modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.},
author = {Wongsuphasawat, Kanit and Smilkov, Daniel and Wexler, James and Wilson, Jimbo and Man{\'{e}}, Dandelion and Fritz, Doug and Krishnan, Dilip and Vi{\'{e}}gas, Fernanda B. and Wattenberg, Martin},
doi = {10.1109/TVCG.2017.2744878},
file = {:Users/nsawada/Google Drive/Papers/Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Clustered Graph,Dataflow Graph,Graph Visualization,Neural Network},
number = {1},
pages = {1--12},
title = {{Visualizing dataflow graphs of deep learning models in TensorFlow}},
volume = {24},
year = {2018}
}
@article{Strobelt2019,
abstract = {Neural Sequence-to-Sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work in a five stage blackbox process that involves encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction with a trained sequence-to-sequence model through each stage of the translation process. The aim is to identify which patterns have been learned and to detect model errors. We demonstrate the utility of our tool through several real-world large-scale sequence-to-sequence use cases.},
archivePrefix = {arXiv},
arxivId = {arXiv:1804.09299v2},
author = {Strobelt, Hendrik and Gehrmann, Sebastian and Behrisch, Michael and Perer, Adam and Pfister, Hanspeter and Rush, Alexander M.},
doi = {10.1109/TVCG.2018.2865044},
eprint = {arXiv:1804.09299v2},
file = {:Users/nsawada/Google Drive/Papers/Seq2Seq-Vis A Visual Debugging Tool for Sequence-to-Sequence Models.pdf:pdf},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Deep Learning,Explainable AI,Machine Learning,NLP,Visual Analytics,Visual Debugging},
number = {1},
pages = {353--363},
title = {{Seq2seq-Vis: A visual debugging tool for sequence-to-sequence models}},
volume = {25},
year = {2019}
}
@article{Szafir2018,
abstract = {Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples' abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.},
author = {Szafir, Danielle Albers},
doi = {10.1109/TVCG.2017.2744359},
file = {:Users/nsawada/Google Drive/Papers/Modeling Color Difference for Visualization Design.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Color Models,Color Perception,Crowdsourcing,Graphical Perception},
number = {1},
pages = {392--401},
publisher = {IEEE},
title = {{Modeling color difference for visualization design}},
volume = {24},
year = {2018}
}
@article{Isenberg2013,
abstract = {We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90{\%} of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.},
author = {Isenberg, Tobias and Isenberg, Petra and Chen, Jian and Sedlmair, Michael and Moller, Torsten},
doi = {10.1109/TVCG.2013.126},
file = {:Users/nsawada/Google Drive/Papers/A Systematic Review on the Practice of Evaluating Visualization.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Evaluation,information visualization,scientific visualization,systematic review,validation,visualization},
number = {12},
pages = {2818--2827},
title = {{A systematic review on the practice of evaluating visualization}},
volume = {19},
year = {2013}
}
@article{Im2017,
annote = {like!},
author = {Im, Hyejin and Kim, Nam Wook and Schriber, Sasha and Pfister, Hanspeter and Bach, Benjamin and Gross, Markus},
doi = {10.1109/tvcg.2017.2744118},
file = {:Users/nsawada/Google Drive/Papers/Visualizing Nonlinear Narratives with Story Curves.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {595--604},
publisher = {IEEE},
title = {{Visualizing nonlinear narratives with story curves}},
volume = {24},
year = {2017}
}
@article{Stopar2018,
author = {Stopar, Luka and Skraba, Primoz and Grobelnik, Marko and Mladenic, Dunja},
doi = {10.1109/TVCG.2018.2825424},
file = {:Users/nsawada/Google Drive/Papers/StreamStory Exploring Multivariate Time Series on Multiple Scales.pdf:pdf},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data and knowledge visualization,Data mining,Markov processes,Multivariate visualization,Time series analysis,Visualization systems and software},
number = {4},
pages = {1788--1802},
publisher = {IEEE},
title = {{StreamStory: Exploring multivariate time series on multiple scales}},
volume = {25},
year = {2018}
}
@article{Dang2013,
abstract = {We introduce a method (Scagnostic time series) and an application (TimeSeer) for organizing multivariate time series and for guiding interactive exploration through high-dimensional data. The method is based on nine characterizations of the 2D distributions of orthogonal pairwise projections on a set of points in multidimensional euclidean space. These characterizations include measures, such as, density, skewness, shape, outliers, and texture. Working directly with these Scagnostic measures, we can locate anomalous or interesting subseries for further analysis. Our application is designed to handle the types of doubly multivariate data series that are often found in security, financial, social, and other sectors.},
author = {Dang, Tuan Nhon and Anand, Anushka and Wilkinson, Leland},
doi = {10.1109/TVCG.2012.128},
file = {:Users/nsawada/Google Drive/Papers/TimeSeer Scagnostics for High-Dimensional Time Series.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Scagnostics,high-dimensional visual analytics,multiple time series,scatterplot matrix},
number = {3},
pages = {470--483},
publisher = {IEEE},
title = {{TimeSeer: Scagnostics for high-dimensional time series}},
volume = {19},
year = {2013}
}
@article{Bogl2013,
abstract = {Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.},
author = {Bogl, Markus and Aigner, Wolfgang and Filzmoser, Peter and Lammarsch, Tim and Miksch, Silvia and Rind, Alexander},
doi = {10.1109/TVCG.2013.222},
file = {:Users/nsawada/Google Drive/Papers/Visual Analytics for Model Selection in Time Series Analysis.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Visual analytics,coordinated and multiple views,model selection,time series analysis,visual interaction},
number = {12},
pages = {2237--2246},
title = {{Visual analytics for model selection in time series analysis}},
volume = {19},
year = {2013}
}
@article{Javed2010,
abstract = {Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time seriesâsuch as small multiples and horizon graphsâare generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniquesâlike standard line graphsâare typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.},
author = {Javed, Waqas and McDonnel, Bryan and Elmqvist, Niklas},
doi = {10.1109/TVCG.2010.162},
file = {:Users/nsawada/Google Drive/Papers/Graphical Perception of Multiple Time Series.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Line graphs,braided graphs,design guidelines,evaluation,horizon graphs,small multiples,stacked graphs},
number = {6},
pages = {927--934},
publisher = {IEEE},
title = {{Graphical perception of multiple time series}},
volume = {16},
year = {2010}
}
@article{Cuenca2018,
abstract = {Multiple time series are a set of multiple quantitative variables occurring at the same interval. They are present in many domains such as medicine, finance, and manufacturing for analytical purposes. In recent years, streamgraph visualization (evolved from ThemeRiver) has been widely used for representing temporal evolution patterns in multiple time series. However, streamgraph as well as ThemeRiver suffer from scalability problems when dealing with several time series. To solve this problem, multiple time series can be organized into a hierarchical structure where individual time series are grouped hierarchically according to their proximity. In this paper, we present a new streamgraph-based approach to convey the hierarchical structure of multiple time series to facilitate the exploration and comparisons of temporal evolution. Based on a focus+context technique, our method allows time series exploration at different granularities (e.g., from overview to details). To illustrate our approach, two usage examples are presented.},
author = {Cuenca, Erick and Sallaberry, Arnaud and Wang, Florence Y. and Poncelet, Pascal},
doi = {10.1109/TVCG.2018.2796591},
file = {:Users/nsawada/Google Drive/Papers/MultiStream A Multiresolution Streamgraph Approach to Explore Hierarchical Time Series.pdf:pdf},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Streamgraph,aggregation,fisheye,focus+context,multiresolution visualization,overview+detail,stacked graph,time series},
number = {12},
pages = {3160--3173},
publisher = {IEEE},
title = {{MultiStream: A multiresolution streamgraph approach to explore hierarchical time series}},
volume = {24},
year = {2018}
}
@article{Lawonn2016,
abstract = {Cognitive science/Computer science},
author = {Lawonn, Kai and Gla{\ss}er, Sylvia and Vilanova, Anna and Preim, Bernhard and Isenberg, Tobias},
doi = {10.1109/TVCG.2015.2467961},
file = {:Users/nsawada/Google Drive/Papers/Occlusion-free Blood Flow Animation with Wall Thickness Visualization.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Aneurysm,Biomedical imaging,Blood,Data visualization,Morphology,Surface morphology,Visualization},
number = {1},
pages = {728--737},
title = {{Occlusion-free blood flow animation with wall thickness visualization}},
volume = {22},
year = {2016}
}
@inproceedings{VanWijk2002,
abstract = {A new method for the visualization of two-dimensional fluid flow is presented. The method is based on the advection and decay of dye. These processes are simulated by defining each frame of a flow animation as a blend between a warped version of the previous image and a number of background images. For the latter a sequence of filtered white noise images is used: filtered in time and space to remove high frequency components. Because all steps are done using images, the method is named Image Based Flow Visualization (IBFV). With IBFV a wide variety of visualization techniques can be emulated. Flow can be visualized as moving textures with line integral convolution and spot noise. Arrow plots, streamlines, particles, and topological images can be generated by adding extra dye to the image. Unsteady flows, defined on arbitrary meshes, can be handled. IBFV achieves a high performance by using standard features of graphics hardware. Typically fifty frames per second are generated using standard graphics cards on PCs. Finally, IBFV is easy to understand, analyse, and implement.},
address = {San Antonio, Texas},
author = {{Van Wijk}, Jarke J},
booktitle = {Proceedings of the 29th annual conference on Computer graphics and interactive techniques},
doi = {10.1145/566654.566646},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Van Wijk - 2002 - Image based flow visualization.pdf:pdf},
pages = {745--754},
title = {{Image based flow visualization}},
url = {http://delivery.acm.org.ezp-prod1.hul.harvard.edu/10.1145/570000/566646/p745-van{\_}wijk.pdf?ip=206.253.207.235{\&}id=566646{\&}acc=ACTIVE SERVICE{\&}key=AA86BE8B6928DDC7.C82FBC3DCC335AD2.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}{\_}{\_}acm{\_}{\_}=1552330927{\_}a3a5fb379cdca04796},
year = {2002}
}
@article{Bruckner,
author = {Bruckner, S. and Groller, M.E.},
doi = {10.1109/VISUAL.2005.1532856},
file = {:Users/nsawada/Google Drive/Papers/VolumeShop An Interactive System for Direct Volume Illustration.pdf:pdf},
isbn = {0-7803-9462-3},
journal = {VIS 05. IEEE Visualization, 2005.},
keywords = {context techniques,cus,fo-,illustrative visualization,volume rendering},
pages = {671--678},
title = {{VolumeShop: An Interactive System for Direct Volume Illustration}},
url = {http://ieeexplore.ieee.org/document/1532856/},
volume = {Ill}
}
@article{Lin2009,
abstract = {For more than one decade, time series similarity search has been given a great deal of attention by data mining researchers. As a result, many time series representations and distance measures have been proposed. However, most existing work on time series similarity search focuses on finding shape-based similarity. While some of the existing approaches work well for short time series data, they typically fail to produce satisfactory results when the sequence is long. For long sequences, it is more appropriate to consider the similarity based on the higher-level structures. In this work, we present a histogram-based representation for time series data, similar to the "bag of words" approach that is widely accepted by the text mining and information retrieval communities. We show that our approach outperforms the existing methods in clustering, classification, and anomaly detection on several real datasets.},
author = {Lin, Jessica and Li, Yuan},
doi = {10.1007/978-3-642-02279-1_33},
file = {:Users/nsawada/Google Drive/Papers/Finding Structural Similarity in Time Series Data Using Bag-of-Patterns Representation.pdf:pdf},
isbn = {3642022782},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Data mining,Similarity Search,Time series},
pages = {461--477},
pmid = {1000285866},
title = {{Finding structural similarity in time series data using bag-of-patterns representation}},
volume = {5566 LNCS},
year = {2009}
}

@inproceedings{Wattenberg2001,
abstract = {[PDF]},
author = {Wattenberg, Martin},
booktitle = {Proceedings of CHI '01 Extended Abstracts on Human Factors in Computing Systems},
doi = {10.1145/634288.634292},
file = {:Users/nsawada/Google Drive/Papers/Sketching a Graph to Query a Time-Series Database.pdf:pdf},
keywords = {database,dynamic queries,freehand sketch,stock market,time series,user interface,visual query},
pages = {381--382},
title = {{Sketching a graph to query a time-series database}},
year = {2001}
}

@inproceedings{Ryall2005,
abstract = {We introduce approximate query techniques for searching and analyzing two-dimensional data sets such as line or scatter plots. Our techniques allow users to explore a dataset by defining QueryLines: soft constraints and preferences for selecting and sorting a subset of the data. By using both preferences and soft constraints for query composition, we allow greater flexibility and expressiveness than previous visual query systems. When the user over-constrains a query, for example, a system using approximate techniques can display "near misses" to enable users to quickly and continuously refine queries.},
author = {Ryall, Kathy and Lesh, Neal and Lanning, Tom and Leigh, Darren and Miyashita, Hiroaki and Makino, Shigeru},
booktitle = {Proceedings of CHI '05 Extended Abstracts on Human Factors in Computing Systems},
doi = {10.1145/1056808.1057017},
file = {:Users/nsawada/Google Drive/Papers/QueryLines Approximate Query for Visual Browsing.pdf:pdf},
isbn = {1595930027},
keywords = {approximate query,visual query},
pages = {1765--1768},
title = {{Querylines: Approximate query for visual browsing}},
year = {2005}
}
@article{Al-Awami2014,
abstract = {We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.},
annote = {Visual abstraction
Task analysis},
author = {Al-Awami, Ali K. and Beyer, Johanna and Strobelt, Hendrik and Kasthuri, Narayanan and Lichtman, Jeff W. and Pfister, Hanspeter and Hadwiger, Markus},
doi = {10.1109/TVCG.2014.2346312},
file = {:Users/nsawada/Google Drive/Papers/NeuroLines A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Connectomics,Data abstraction,Focus+Context,Multi-Trees,Neuroscience},
number = {12},
pages = {2369--2378},
publisher = {IEEE},
title = {{NeuroLines: A subway map metaphor for visualizing nanoscale neuronal connectivity}},
volume = {20},
year = {2014}
}
@article{Wattenberg2006,
abstract = {This paper introduces PivotGraph, a software tool that uses a new technique for visualizing and analyzing graph structures. The technique is designed specifically for graphs that are âmultivariate,â i.e., where each node is associated with several attributes. Unlike visualizations which emphasize global graph topology, PivotGraph uses a simple grid-based approach to focus on the relationship between node attributes and connections. The interaction technique is derived from an analogy with methods seen in spreadsheet pivot tables and in online analytical processing (OLAP). Finally, several examples are presented in which PivotGraph was applied to real-world data sets.},
author = {Wattenberg, Martin},
doi = {10.1145/1124772.1124891},
file = {:Users/nsawada/Google Drive/Papers/Visual exploration of multivariate graphs.pdf:pdf},
isbn = {1595931783},
pages = {811},
title = {{Visual exploration of multivariate graphs}},
year = {2006}
}
@article{VanDenElzen2016,
abstract = {We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.},
author = {{Van Den Elzen}, Stef and Holten, Danny and Blaas, Jorik and {Van Wijk}, Jarke J.},
doi = {10.1109/TVCG.2015.2468078},
file = {:Users/nsawada/Google Drive/Papers/Reducing Snapshots to Points a visual analytics approach to dynamic network exploration.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Animation,Data visualization,Indexes,Manganese,Principal component analysis,Visual analytics},
number = {1},
pages = {1--10},
publisher = {IEEE},
title = {{Reducing snapshots to points: A visual analytics approach to dynamic network exploration}},
volume = {22},
year = {2016}
}
@article{Henry2007,
abstract = {The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.},
author = {Henry, Nathalie and Fekete, Jean Daniel and McGuffin, Michael J.},
doi = {10.1109/TVCG.2007.70582},
file = {:Users/nsawada/Google Drive/Papers/NodeTrix a Hybrid Visualization of Social Networks.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Aggregation,Hybrid visualization,Interaction,Matrix visualization,Network visualization},
number = {6},
pages = {1302--1309},
title = {{NodeTrix: A hybrid visualization of social networks}},
volume = {13},
year = {2007}
}
@article{Blumenschein2018,
abstract = {Figure 1: The visual representation of SMARTEXPLORE is a so-called SMARTABLE. Descriptors such as mean, variance, or deviation are computed, normalized per dimension or subspace, and mapped to a bi-polar or linear colormap. Manual and (semi-)automatic algorithms are executed through the visualization and support analysts in identifying and understanding clusters, correlations, outliers, and application-specific patterns in subspaces of the data. To increase trust in the patterns, statistical measures are computed on-the-fly and visualized along with missing values as visual overlays. Details on demand and a stacked SMARTABLE support detail analysis. ABSTRACT We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations , and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, sub-space analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.},
author = {Blumenschein, Michael and Behrisch, Michael and Schmid, Stefanie and Butscher, Simon and Wahl, Deborah R and Villinger, Karoline and Renner, Britta and Reiterer, Harald and Keim, Daniel A},
file = {:Users/nsawada/Google Drive/Papers/SMARTexplore Simplifying High-Dimensional Data Analysist through a table-based visual analytics approach.pdf:pdf},
isbn = {9781538668610},
journal = {IEEE Conference on Visual Analytics},
keywords = {aggregation,driven analysis,high-dimensional data,pattern-,subspace,tabular visualization,visual exploration},
number = {October},
pages = {21--26},
title = {{SMARTexplore: Simplifying high-dimensional data analysis through a table-based visual analytics approach}},
year = {2018}
}
@article{Zhao2015,
abstract = {Visualization of hierarchical data is of great importance in information visualization. We present variational circular treemaps with a novel layout algorithm by solving disk packing as a continuous optimization problem. Our variational circular treemaps achieve higher space utilization ratio compared with the traditional circular treemaps and support natural interactions as focus+context distortions and drill-down and roll-up operations for data navigation. Experimental results show the effectiveness of our method for visualization and interaction.},
author = {Zhao, Haisen and Lu, Lin},
doi = {10.1109/PACIFICVIS.2015.7156360},
file = {:Users/nsawada/Google Drive/Papers/Variational circular treemaps for interactive visualization of hierarchical data.pdf:pdf},
isbn = {9781467368797},
issn = {21658773},
journal = {IEEE Pacific Visualization Symposium},
keywords = {Computer Graphics [I.3.5]: Computational Geometry},
pages = {81--85},
publisher = {IEEE},
title = {{Variational circular treemaps for interactive visualization of hierarchical data}},
volume = {2015-July},
year = {2015}
}
@article{Gratzl2013,
abstract = {Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp--a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.},
annote = {REQUIREMENT ANALYSIS
Paper type: Design study},
author = {Gratzl, Samuel and Lex, Alexander and Gehlenborg, Nils and Pfister, Hanspeter and Streit, Marc},
doi = {10.1109/TVCG.2013.173},
file = {:Users/nsawada/Google Drive/Papers/LineUp Visual Analysis of Multi-Attribute Rankings.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Ranking visualization,multi-attribute,multi-faceted,multifactorial,ranking,scoring,stacked bar charts},
number = {12},
pages = {2277--2286},
publisher = {IEEE},
title = {{LineUp: Visual analysis of multi-attribute rankings}},
volume = {19},
year = {2013}
}
@article{Viegas2013,
abstract = {G+ Ripples is a visualization of information flow that shows users how public posts are shared on Google+. Unlike other social network visualizations, Ripples exists as a "native" visualization: it is directly accessible from public posts on Google+. This unique position leads to both new constraints and new possibilities for design. We describe the visualization technique, which is a new mix of node-and-link and circular treemap metaphors. We then describe user reactions as well as some of the patterns of sharing that are made evident by the Ripples visualization.},
author = {Vi{\'{e}}gas, Fernanda and Wattenberg, Martin},
doi = {10.1145/2488388.2488504},
file = {:Users/nsawada/Google Drive/Papers/Google+ Ripples a native visualization of information flow.pdf:pdf},
isbn = {9781450320351},
journal = {Proceedings of the 22nd international conference on World Wide Web},
keywords = {Visualization,social data analysis.,social networks},
pages = {1389--1398},
title = {{Google+ ripples: A native visualization of information flow}},
url = {http://dl.acm.org/citation.cfm?id=2488504},
year = {2013}
}
@article{Maguire2013,
abstract = {This paper is concerned with the creation of 'macros' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.},
author = {Maguire, Eamonn and Rocca-Serra, Philippe and Sansone, Susanna Assunta and Davies, Jim and Chen, Min},
doi = {10.1109/TVCG.2013.225},
file = {:Users/nsawada/Google Drive/Papers/Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Workflow visualization,glyph generation,glyph-based visualization,motif detection,state-transition-based algorithm},
number = {12},
pages = {2576--2585},
pmid = {24051824},
publisher = {IEEE},
title = {{Visual compression of workflow visualizations with automated detection of macro motifs}},
volume = {19},
year = {2013}
}
@article{Chen2014,
abstract = {Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.},
author = {Chen, Haidong and Chen, Wei and Mei, Honghui and Liu, Zhiqi and Zhou, Kun and Chen, Weifeng and Gu, Wentao and Ma, Kwan Liu},
doi = {10.1109/TVCG.2014.2346594},
file = {:Users/nsawada/Google Drive/Papers/Visual Abstraction and Exploration of Multi-class Scatterplots.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Scatterplot,overdraw reduction,sampling,visual abstraction},
number = {12},
pages = {1683--1692},
pmid = {25429218},
publisher = {IEEE},
title = {{Visual abstraction and exploration of multi-class scatterplots}},
volume = {20},
year = {2014}
}
@article{Tennekes2014,
abstract = {We present a method to map tree structures to colors from the Hue-Chroma-Luminance color model, which is known for its well balanced perceptual properties. The Tree Colors method can be tuned with several parameters, whose effect on the resulting color schemes is discussed in detail. We provide a free and open source implementation with sensible parameter defaults. Categorical data are very common in statistical graphics, and often these categories form a classification tree. We evaluate applying Tree Colors to tree structured data with a survey on a large group of users from a national statistical institute. Our user study suggests that Tree Colors are useful, not only for improving node-link diagrams, but also for unveiling tree structure in non-hierarchical visualizations.},
author = {Tennekes, Martijn and {De Jonge}, Edwin},
doi = {10.1109/TVCG.2014.2346277},
file = {:Users/nsawada/Google Drive/Papers/Tree Colors Color Schemes for Tree-Structured Data.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Color schemes,Hierarchical data,Statistical graphics},
number = {12},
pages = {2072--2081},
pmid = {26356921},
publisher = {IEEE},
title = {{Tree colors: Color schemes for tree-structured data}},
volume = {20},
year = {2014}
}
@article{Beham2014,
abstract = {Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.},
author = {Beham, Michael and Herzner, Wolfgang and Gr{\"{o}}ller, M. Eduard and Kehrer, Johannes},
doi = {10.1109/TVCG.2014.2346626},
file = {:Users/nsawada/Google Drive/Papers/Cupid Cluster-based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {3D shape analysis,Composite visualization,Hierarchical clustering,Illustrative parallel coordinates,Radial trees},
number = {12},
pages = {1693--1702},
title = {{Cupid: Cluster-based exploration of geometry generators with parallel coordinates and radial trees}},
volume = {20},
year = {2014}
}
@article{Veras2017,
abstract = {In this paper we examine how the Minimum Description Length (MDL) principle can be used to efficiently select aggregated views of hierarchical datasets that feature a good balance between clutter and information. We present MDL formulae for generating uneven tree cuts tailored to treemap and sunburst diagrams, taking into account the available display space and information content of the data. We present the results of a proof-of-concept implementation. In addition, we demonstrate how such tree cuts can be used to enhance drill-down interaction in hierarchical visualizations by implementing our approach in an existing visualization tool. Validation is done with the feature congestion measure of clutter in views of a subset of the current DMOZ web directory, which contains nearly half million categories. The results show that MDL views achieve near constant clutter level across display resolutions. We also present the results of a crowdsourced user study where participants were asked to find targets in views of DMOZ generated by our approach and a set of baseline aggregation methods. The results suggest that, in some conditions, participants are able to locate targets (in particular, outliers) faster using the proposed approach.},
author = {Veras, Rafael and Collins, Christopher},
doi = {10.1109/TVCG.2016.2598591},
file = {:Users/nsawada/Google Drive/Papers/Optimizing Hierarchical Visualizations with the minimum description length principle.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Hierarchy data,antichain,data aggregation,multiscale visualization,tree cut},
number = {1},
pages = {631--640},
title = {{Optimizing hierarchical visualizations with the minimum description length principle}},
volume = {23},
year = {2017}
}
@article{Srinivasan2018,
abstract = {IEEE Network visualizations, often in the form of node-link diagrams, are an effective means to understand relationships between entities, discover entities with interesting characteristics, and to identify clusters. While several existing tools allow users to visualize pre-defined networks, creating these networks from raw data remains a challenging task, often requiring users to program custom scripts or write complex SQL commands. Some existing tools also allow users to both visualize and model networks. Interaction techniques adopted by these tools often assume users know the exact conditions for defining edges in the resulting networks. This assumption may not always hold true, however. In cases where users do not know much about attributes in the dataset or when there are several attributes to choose from, users may not know which attributes they could use to formulate linking conditions. We propose an alternate interaction technique to model networks that allows users to demonstrate to the system a subset of nodes and links they wish to see in the resulting network. The system, in response, recommends conditions that can be used to model networks based on the specified nodes and links. In this paper, we show how such a demonstration-based interaction technique can be used to model networks by employing it in a prototype tool, Graphiti. Through multiple usage scenarios, we show how Graphiti not only allows users to model networks from a tabular dataset but also facilitates updating a pre-defined network with additional edge types.},
author = {Srinivasan, Arjun and Park, Hyunwoo and Endert, Alex and Basole, Rahul C.},
doi = {10.1109/TVCG.2017.2744843},
file = {:Users/nsawada/Google Drive/Papers/Graphiti Interactive Specification of Attribute-Based Edges for Network Modeling and Visualization.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Network modeling,user interaction,visual analytics},
number = {1},
pages = {226--235},
publisher = {IEEE},
title = {{Graphiti: Interactive specification of attribute-based edges for network modeling and visualization}},
volume = {24},
year = {2018}
}
@inproceedings{Bruls2000,
abstract = {An extension to the treemapmethod for the visualization of hierarchi- cal information, such as directory structures and organization structures, is pre- sented. The standard treemap method often gives thin, elongated rectangles. As a result, rectangles are difficult to compare and to select.Anewmethod is presented to generate lay-outs in which the rectangles approximate squares. To strenghten the visualization of the structure, shaded frames are used around groups of related nodes.},
author = {Bruls, Mark and Huizing, Kees and van Wijk, Jarke J.},
booktitle = {Proceedings of the Eurographics / IEEE VGTC Symposium on Visualization},
doi = {10.1007/978-3-7091-6783-0_4},
file = {:Users/nsawada/Google Drive/Papers/Squarified treemaps.pdf:pdf},
isbn = {3211835156},
issn = {17275296},
pages = {33--42},
pmid = {326885},
title = {{Squarified treemaps}},
url = {http://link.springer.com/10.1007/978-3-7091-6783-0{\_}4},
year = {2000}
}
@article{Blanch2007,
author = {Blanch, Renaud and Lecolinet, {\'{E}}ric},
file = {:Users/nsawada/Google Drive/Papers/Browsing Zoomable Treemaps Structure-Aware multi-scale navigation technique.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {6},
pages = {1248--1253},
title = {{Browsing zoomable treemaps: structure-aware multi-scale navigation techniques}},
volume = {13},
year = {2007}
}
@article{Behrisch2018,
abstract = {Pattern extraction algorithms are enabling insights into the ever-growing amount of today's datasets by translating reoccurring data properties into compact representations. Yet, a practical problem arises: With increasing data volumes and complexity also the number of patterns increases, leaving the analyst with a vast result space. Current algorithmic and especially visualization approaches often fail to answer central overview questions essential for a comprehensive understanding of pattern distributions and support, their quality, and relevance to the analysis task. To address these challenges, we contribute a visual analytics pipeline targeted on the pattern-driven exploration of result spaces in a semi-automatic fashion. Specifically, we combine image feature analysis and unsupervised learning to partition the pattern space into interpretable, coherent chunks, which should be given priority in a subsequent in-depth analysis. In our analysis scenarios, no ground-truth is given. Thus, we employ and evaluate novel quality metrics derived from the distance distributions of our image feature vectors and the derived cluster model to guide the feature selection process. We visualize our results interactively, allowing the user to drill down from overview to detail into the pattern space and demonstrate our techniques in a case study on biomedical genomic data.},
annote = {a visual analytics pipeline targeted on the pattern-driven exploration of result spaces in a semi-automatic fashion},
archivePrefix = {arXiv},
arxivId = {1807.01364},
author = {Behrisch, Michael and Krueger, Robert and Lekschas, Fritz and Schreck, Tobias and Gehlenborg, Nils and Pfister, Hanspeter},
doi = {10.1109/BDVA.2018.8534028},
eprint = {1807.01364},
file = {:Users/nsawada/Google Drive/Papers/Visual Pattern-Driven Exploration of Big Data.pdf:pdf},
isbn = {1-55899-399-1},
number = {C},
title = {{Visual pattern-driven exploration of big data}},
url = {http://arxiv.org/abs/1807.01364},
year = {2018}
}
@misc{Johnson,
abstract = {A method for visualizing hierarchically structured information is described. The tree-map visualization technique makes 100{\%} use of the available display space, mapping the full hierarchy onto a rectangular region in a space-filling manner. This efficient use of space allows very large hierarchies to be displayed in their entirety and facilitates the presentation of semantic information. Tree-maps can depict both the structure and content of the hierarchy. However, the approach is best suited to hierarchies in which the content of the leaf nodes and the structure of the hierarchy are of primary importance, and the content information associated with internal nodes is largely derived from their children},
author = {Johnson, B. and Shneiderman, B.},
booktitle = {Proceeding Visualization '91},
doi = {10.1109/VISUAL.1991.175815},
file = {:Users/nsawada/Google Drive/Papers/Tree-maps a space-filling approach to the visualization of hierarchical information structures.pdf:pdf},
isbn = {0-8186-2245-8},
issn = {0818622458},
pages = {284--291},
pmid = {8322783},
title = {{Tree-maps: A space-filling approach to the visualization of hierarchical information structures}},
url = {http://ieeexplore.ieee.org/document/175815/}
}
@article{VonLandesberger2011,
abstract = {The analysis of large graphs plays a prominent role in various fields of research and is relevant in many important application areas. Effective visual analysis of graphs requires appropriate visual presentations in combination with respective user interaction facilities and algorithmic graph analysis methods. How to design appropriate graph analysis systems depends on many factors, including the type of graph describing the data, the analytical task at hand and the applicability of graph analysis methods. The most recent surveys of graph visualization and navigation techniques cover techniques that had been introduced until 2000 or concentrate only on graph layouts published until 2002. Recently, new techniques have been developed covering a broader range of graph types, such as time-varying graphs. Also, in accordance with ever growing amounts of graph-structured data becoming available, the inclusion of algorithmic graph analysis and interaction techniques becomes increasingly important. In this State-of-the-Art Report, we survey available techniques for the visual analysis of large graphs. Our review first considers graph visualization techniques according to the type of graphs supported. The visualization techniques form the basis for the presentation of interaction approaches suitable for visual graph exploration. As an important component of visual graph analysis, we discuss various graph algorithmic aspects useful for the different stages of the visual graph analysis process. We also present main open research challenges in this field. {\textcopyright} 2011 The Authors Computer Graphics Forum {\textcopyright} 2011 The Eurographics Association and Blackwell Publishing Ltd.},
author = {von Landesberger, T. and Kuijper, A. and Schreck, T. and Kohlhammer, J. and van Wijk, J. J. and Fekete, J. D. and Fellner, D. W.},
doi = {10.1111/j.1467-8659.2011.01898.x},
file = {:Users/nsawada/Google Drive/Papers/Visual Analysis of Large Graphs StateoftheArt and Future Research Challenges.pdf:pdf},
isbn = {0167-7055},
issn = {17278384},
journal = {Eurographics Symposium on Geometry Processing},
keywords = {Graph interaction,Graph visualization,Visual analytics,Visual graph analysis},
number = {6},
pages = {1719--1749},
pmid = {3433122},
title = {{Visual analysis of large graphs: State-of-the-art and future research challenges}},
volume = {30},
year = {2011}
}
@article{Dunn2017,
abstract = {The unprecedented advances in technology and scientific research over the past few years have provided the scientific community with new and more complex forms of data. Large data sets collected from single groups or cross-institution consortiums containing hundreds of omic and clinical variables corresponding to thousands of patients are becoming increasingly commonplace in the research setting. Before any core analyses are performed, visualization often plays a key role in the initial phases of research, especially for projects where no initial hypotheses are dominant. Proper visualization of data at a high level facilitates researcher's abilities to find trends, identify outliers and perform quality checks. In addition, research has uncovered the important role of visualization in data analysis and its implied benefits facilitating our understanding of disease and ultimately improving patient care. In this work, we present a review of the current landscape of existing tools designed to facilitate the visualization of multidimensional data in translational research platforms. Specifically, we reviewed the biomedical literature for translational platforms allowing the visualization and exploration of clinical and omics data, and identified 11 platforms: cBioPortal, interactive genomics patient stratification explorer, Igloo-Plot, The Georgetown Database of Cancer Plus, tranSMART, an unnamed data-cube-based model supporting heterogeneous data, Papilio, Caleydo Domino, Qlucore Omics, Oracle Health Sciences Translational Research Center and OmicsOffice({\textregistered}) powered by TIBCO Spotfire. In a health sector continuously witnessing an increase in data from multifarious sources, visualization tools used to better grasp these data will grow in their importance, and we believe our work will be useful in guiding investigators in similar situations.},
author = {Dunn, William and Burgun, Anita and Krebs, Marie Odile and Rance, Bastien},
doi = {10.1093/bib/bbw080},
file = {:Users/nsawada/Google Drive/Papers/Exploring and visualizing multidimensional data in translational research platforms.pdf:pdf},
isbn = {14774054 (Electronic)},
issn = {14774054},
journal = {Briefings in Bioinformatics},
keywords = {Data analytics,High-dimensional data,Omics,Translational research,Visualization},
number = {6},
pages = {1044--1056},
pmid = {27585944},
title = {{Exploring and visualizing multidimensional data in translational research platforms}},
volume = {18},
year = {2017}
}
@article{Gibson2013,
abstract = {Many algorithms for graph layout have been devised over the last 30 years $\backslash$nspanning both the graph drawing and information visualisation communities. This article first $\backslash$nreviews the advances made in the field of graph drawing that have then often been applied by $\backslash$nthe information visualisation community. There then follows a discussion of a range of $\backslash$ntechniques developed specifically for graph visualisations. Graph drawing algorithms are $\backslash$ncategorised into the following approaches: force-directed layouts, the use of dimension $\backslash$nreduction in graph layout and computational improvements including multi-level techniques. $\backslash$nMethods developed specifically for graph visualisation often make use of node-attributes and $\backslash$nare categorised based on whether the attributes are used to introduce constraints to the $\backslash$nlayout, provide a clustered view or define an explicit representation in two-dimensional space. $\backslash$nThe similarities and distinctions between these techniques are examined and the aim is to $\backslash$nprovide a detailed assessment of currently available graph layout techniques, specifically how $\backslash$nthey can be used by visualisation practitioners, and to motivate further research in the $\backslash$narea.},
author = {Gibson, Helen and Faith, Joe and Vickers, Paul},
doi = {10.1177/1473871612455749},
file = {:Users/nsawada/Google Drive/Papers/A survey of two-dimensional graph layout techniques for information visualisation.pdf:pdf},
isbn = {14738716},
issn = {14738716},
journal = {Information Visualization},
keywords = {2D,Force-directed layout,Graph and network visualisation,Graph layout,Multi-attribute visualisation,Network layout visualisation},
number = {3-4},
pages = {324--357},
title = {{A survey of two-dimensional graph layout techniques for information visualisation}},
volume = {12},
year = {2013}
}
@article{Zhao2013,
abstract = {Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.},
author = {Zhao, Jian and Collins, Christopher and Chevalier, Fanny and Balakrishnan, Ravin},
doi = {10.1109/TVCG.2013.167},
file = {:Users/nsawada/Google Drive/Papers/Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets.pdf:pdf},
isbn = {1077-2626 VO  - 19},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Faceted browsing,dynamic query,information visualization,interaction,network exploration,visual analytics},
number = {12},
pages = {2080--2089},
pmid = {24051774},
publisher = {IEEE},
title = {{Interactive exploration of implicit and explicit relations in faceted datasets}},
volume = {19},
year = {2013}
}
@article{Schulz2011,
abstract = {Apart from explicit node-link representations, implicit visualizations and especially the Treemap as their frontrunner have acquired a solid position among the available techniques to visualize hierarchies. Their advantage is a highly space-efficient graphical representation that does not require explicit drawing of edges. In this paper, we survey the design space for this class of visualization techniques. We establish the design space along the four axes of dimensionality, edge representation, node representation, and layout by examining existing implicit hierarchy visualization techniques. The survey is completed by casting some light into regions of the design space that have not yet been explored. Our design space is not a mere theoretical construct, but a practically usable tool for rapid visualization development. To that end, we discuss a software implementation of the introduced design space.},
author = {Schulz, Hans J{\"{o}}rg and Hadlak, Steffen and Schumann, Heidrun},
doi = {10.1109/TVCG.2010.79},
file = {:Users/nsawada/Google Drive/Papers/The Design Space of Implicit Hierarchy Visualization A Survey.pdf:pdf},
isbn = {2009080181},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Information visualization,Treemaps,hierarchy visualization,rapid visualization prototyping,visualization design space},
number = {4},
pages = {393--411},
pmid = {20498508},
title = {{The design space of implicit hierarchy visualization: A survey}},
volume = {17},
year = {2011}
}
@article{Aggarwal2009,
abstract = {In recent years, a number of indirect data collection methodologies have lead to the proliferation of uncertain data. Such data points are often represented in the form of a probabilistic function, since the corresponding deterministic value is not known. This increases the challenge of mining and managing uncertain data, since the precise behavior of the underlying data is no longer known. In this paper, we provide a survey of uncertain data mining and management applications. In the field of uncertain data management, we will examine traditional methods such as join processing, query processing, selectivity estimation, OLAP queries, and indexing. In the field of uncertain data mining, we will examine traditional mining problems such as classification and clustering. We will also examine a general transform based technique for mining uncertain data. We discuss the models for uncertain data, and how they can be leveraged in a variety of applications. We discuss different methodologies to process and mine uncertain data in a variety of forms.},
author = {Aggarwal, Charu C. and Yu, Philip S.},
doi = {10.1109/TKDE.2008.190},
file = {:Users/nsawada/Google Drive/Papers/A Survey of Uncertain Data Algorithms and Applications.pdf:pdf},
isbn = {1041-4347},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Database applications,Database management,Information technology and systems,Mining methods and algorithms},
number = {5},
pages = {609--623},
publisher = {IEEE},
title = {{A survey of uncertain data algorithms and applications}},
volume = {21},
year = {2009}
}
@inproceedings{CorreaCarlosD.ChanYu-HsuanMa2009,
abstract = {Visual analytics has become an important tool for gaining insight on big data. Numerous statistical tools have been integrated with visualization to help analysts understand big data better and faster. However, data is inherently uncertain, due to sampling error, noise, latency, approximate measurement or unreliable sources. It is very important and vital to quantify and visualize uncertainties for analysts to improve the results of decision making process and gain valuable insights during analytic process on big data. In this paper, we propose a new framework to support uncertainty in the visual analytics process through a fuzzy self-organizing map algorithm running in MapReduce framework for parallel computations on massive amounts of data. This framework uses an interactive data mining module, uncertainty modeling and knowledge representation that supports insertion of the user's experience and knowledge for uncertainty modeling and visualization in the big data.},
author = {{Correa, Carlos D., Chan, Yu-Hsuan, Ma}, Kwan-Liu},
booktitle = {Proceedings of 2009 IEEE Symposium on Visual Analytics Science and Technology},
doi = {10.1109/VAST.2009.5332611},
file = {:Users/nsawada/Google Drive/Papers/A framework for uncertainty- aware visual analytics.pdf:pdf},
isbn = {9781424452835},
issn = {16130073},
keywords = {data transformations,model fitting,nent analysis,principal compo-,uncertainty},
pages = {51--58},
title = {{A framework for uncertainty-aware visual analytics in big data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961256966{\&}partnerID=40{\&}md5=2bacef75ac6d5b74fb21422e1c250ea7},
year = {2009}
}
@incollection{Brodlie2012,
abstract = {Most visualization techniques have been designed on the assumption that the data to be represented are free from uncertainty. Yet this is rarely the case. Recently the visualization community has risen to the challenge of incorporating an indication of uncertainty into visual representations, and in this article we review their work. We place the work in the context of a reference model for data visualization, that sees data pass through a pipeline of processes. This allows us to distinguish the visualization of uncertaintyâwhich considers how we depict uncertainty specified with the dataâand the uncertainty of visualizationâwhich considers how much inaccuracy occurs as we process data through the pipeline. It has taken some time for uncertain visualization methods to be developed, and we explore why uncertainty visualization is hardâone explanation is that we typically need to find another display dimension and we may have used these up already! To organize the material we return to a typology developed by one of us in the early days of visualization, and make use of this to present a catalog of visualization techniques describing the research that has been done to extend each method to handle uncertainty. Finally we note the responsibility on us all to incorporate any known uncertainty into a visualization, so that integrity of the discipline is maintained.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Brodlie, Ken and Osorio, Rodolfo Allendes and Lopes, Adriano},
booktitle = {Expanding the Frontiers of Visual Analytics and Visualization},
chapter = {6},
doi = {10.1007/978-1-4471-2804-5},
eprint = {9809069v1},
file = {:Users/nsawada/Google Drive/Papers/A Review of Uncertainty in Data Visualization.pdf:pdf},
isbn = {978-1-4471-2803-8},
issn = {0717-6163},
pages = {81--109},
pmid = {15003161},
primaryClass = {arXiv:gr-qc},
title = {{A review of uncertainty in data visualization}},
url = {http://link.springer.com/10.1007/978-1-4471-2804-5},
year = {2012}
}
@article{Yusof2016,
abstract = {Wind speed and direction vary over space and time due to the interactions between different pressures and temperature gradi- ents within the atmospheric layers. Near the earth's surface, these interactions are modulated by topography and artificial structures. Hence, characterizing wind behaviour over large areas and long periods is a complex but essential task for various energy-related applications. In this study, we present a novel approach to dis- cover wind patterns by integrating sequential pattern mining and interactive visualization techniques. The approach relies on the use of the Linear time Closed pattern Miner sequence algorithm in conjunction with a time sliding window that allows the discov- ery of all sequential patterns present in the data. These patterns are then visualized using integrated 2D and 3D coordinated multi- ple views and visually explored to gain insight into the character- istics of the wind from a spatial, temporal and attribute (type of wind pattern) point of view. This proposed approach is used to analyse 10 years of hourly wind speed and direction data for 29 weather stations in the Netherlands. The results show that there are 15 main sequential patterns in the data. The spatial task shows that weather stations located in the same region do not necessa- rily experience similar wind pattern. For within the selected time interval, similar wind patterns can be observed in different stations and in the same station at different times of occurrence. The attribute task discovered that the repetitive occurrences of chosen pattern indicate as regular wind behaviour at different weather stations that persisted continuously over time. The results of these tasks show that the proposed interactive discovery facilitates the understanding of wind dynamics in space and time.},
author = {Yusof, Norhakim and Zurita-Milla, Raul and Kraak, Menno Jan and Retsios, Bas},
doi = {10.1080/13658816.2015.1135928},
file = {:Users/nsawada/Google Drive/Papers/Interactive discovery of sequential patterns in time series of wind data.pdf:pdf},
issn = {13623087},
journal = {International Journal of Geographical Information Science},
keywords = {Wind speed,coordinated multiple views,direction,frequent patterns,interactive visualization,sequential pattern mining,sliding window},
number = {8},
pages = {1486--1506},
publisher = {Taylor {\&} Francis},
title = {{Interactive discovery of sequential patterns in time series of wind data}},
url = {http://dx.doi.org/10.1080/13658816.2015.1135928},
volume = {30},
year = {2016}
}
@article{Gortler2018,
abstract = {We present a novel type of circular treemap, where we intentionally allocate extra space for additional visual variables. With this extended visual design space, we encode hierarchically structured data along with their uncertainties in a combined diagram. We introduce a hierarchical and force-based circle-packing algorithm to compute Bubble Treemaps, where each node is visualized using nested contour arcs. Bubble Treemaps do not require any color or shading, which offers additional design choices. We explore uncertainty visualization as an application of our treemaps using standard error and Monte Carlo-based statistical models. To this end, we discuss how uncertainty propagates within hierarchies. Furthermore, we show the effectiveness of our visualization using three different examples: the package structure of Flare, the S{\&}P 500 index, and the US consumer expenditure survey.},
annote = {Paper type: Design study
Contributions: a novel type of circular treemap, where we intentionally allocate extra space for additional visual variables},
author = {G{\"{o}}rtler, Jochen and Schulz, Christoph and Weiskopf, Daniel and Deussen, Oliver},
doi = {10.1109/TVCG.2017.2743959},
file = {:Users/nsawada/Google Drive/Papers/Bubble Treemaps for Uncertainty Visualization.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Uncertainty visualization,circle packing,contours,hierarchy visualization,tree layout,treemaps},
number = {1},
pages = {719--728},
title = {{Bubble treemaps for uncertainty visualization}},
volume = {24},
year = {2018}
}
@article{Zhou2018,
author = {Zhou, Liang and Weiskopf, Daniel},
doi = {10.1109/TVCG.2017.2698041},
file = {:Users/nsawada/Google Drive/Papers/Indexed-Points Parallel Coordinates Visualization of Multivariate Correlations.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Multidimensional data visualization,multivariate correlations,parallel coordinates},
number = {6},
pages = {1997--2010},
publisher = {IEEE},
title = {{Indexed-points parallel coordinates visualization of multivariate correlations}},
volume = {24},
year = {2018}
}
@article{Ziemkiewicz2010,
abstract = {Many of the pressing questions in information visualization deal with how exactly a user reads a collection of visual marks as information about relationships between entities. Previous research has suggested that people see parts of a visualization as objects, and may metaphorically interpret apparent physical relationships between these objects as suggestive of data relationships. We explored this hypothesis in detail in a series of user experiments. Inspired by the concept of implied dynamics in psychology, we first studied whether perceived gravity acting on a mark in a scatterplot can lead to errors in a participant's recall of the mark's position. The results of this study suggested that such position errors exist, but may be more strongly influenced by attraction between marks. We hypothesized that such apparent attraction may be influenced by elements used to suggest relationship between objects, such as connecting lines, grouping elements, and visual similarity. We further studied what visual elements are most likely to cause this attraction effect, and whether the elements that best predicted attraction errors were also those which suggested conceptual relationships most strongly. Our findings show a correlation between attraction errors and intuitions about relatedness, pointing towards a possible mechanism by which the perception of visual marks becomes an interpretation of data relationships.},
author = {Ziemkiewicz, Caroline and Kosara, Robert},
doi = {10.1109/TVCG.2010.174},
file = {:Users/nsawada/Google Drive/Papers/Laws of Attraction From Perceived Forces to Conceptual Similarity.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Perceptual cognition,cognition theory,laboratory studies,visualization models},
number = {6},
pages = {1009--1016},
pmid = {20975138},
publisher = {IEEE},
title = {{Laws of attraction: From perceptual forces to conceptual similarity}},
volume = {16},
year = {2010}
}
@article{JornKohlhammer2012,
abstract = {Nishimura reviews SPSS Inc's DeltaGraph 4.5.},
author = {et al. {Jorn Kohlhammer}, K. Nazemi},
doi = {10.1109/MCG.2008.114},
file = {:Users/nsawada/Google Drive/Papers/Treevis.net A Tree Visualization Reference.pdf:pdf},
isbn = {00368075},
issn = {0272-1716},
journal = {IEEE Computer Graphics and ApplicationsComputer},
number = {6},
pages = {11--15},
pmid = {24808297},
title = {{Treevis.net: A tree visualization reference}},
volume = {31},
year = {2012}
}
@article{Yuan2010,
author = {Yuan, Xiaoru and Wang, Zuchao and Guo, Cong},
doi = {10.1145/122974.122993},
file = {:Users/nsawada/Google Drive/Papers/MDS-Tree and MDS-Matrix for High Dimensional Data Visualization.pdf:pdf},
isbn = {0897914619},
journal = {Proceedings of the IEEE},
pages = {2--3},
title = {{MDS-Tree and MDS-Matrix for High Dimensional Data Visualization}},
year = {2010}
}
@article{Hollt2018,
abstract = {IEEE Single-cell analysis through mass cytometry has become an increasingly important tool for immunologists to study the immune system in health and disease. Mass cytometry creates a high-dimensional description vector for single cells by time-of-flight measurement. Recently, t-Distributed Stochastic Neighborhood Embedding (t-SNE) has emerged as one of the state-of-the-art techniques for the visualization and exploration of single-cell data. Ever increasing amounts of data lead to the adoption of Hierarchical Stochastic Neighborhood Embedding (HSNE), enabling the hierarchical representation of the data. Here, the hierarchy is explored selectively by the analyst, who can request more and more detail in areas of interest. Such hierarchies are usually explored by visualizing disconnected plots of selections in different levels of the hierarchy. This poses problems for navigation, by imposing a high cognitive load on the analyst. In this work, we present an interactive summary-visualization to tackle this problem. CyteGuide guides the analyst through the exploration of hierarchically represented single-cell data, and provides a complete overview of the current state of the analysis. We conducted a two-phase user study with domain experts that use HSNE for data exploration. We first studied their problems with their current workflow using HSNE and the requirements to ease this workflow in a field study. These requirements have been the basis for our visual design. In the second phase, we verified our proposed solution in a user evaluation.},
author = {Hollt, Thomas and Pezzotti, Nicola and {Van Unen}, Vincent and Koning, Frits and Lelieveldt, Boudewijn P.F. and Vilanova, Anna},
doi = {10.1109/TVCG.2017.2744318},
file = {:Users/nsawada/Google Drive/Papers/CyteGuide Visual Guidance for Hierarchical Single-Cell Analysis.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {HSNE,Hierarchical Data,Single-Cell Analysis,Visual Guidance},
number = {1},
pages = {739--748},
pmid = {11274410},
publisher = {IEEE},
title = {{CyteGuide: Visual guidance for hierarchical single-cell analysis}},
volume = {24},
year = {2018}
}
@article{Pezzotti2016,
abstract = {In recent years, dimensionality-reduction techniques have been developed and are widely used for hypothesis generation in Exploratory Data Analysis. However, these techniques are confronted with overcoming the trade-off between computation time and the quality of the provided dimensionality reduction. In this work, we address this limitation, by introducing Hierarchical Stochastic Neighbor Embedding (Hierarchical-SNE). Using a hierarchical representation of the data, we incorporate the well-known mantra of Overview-First, Details-On-Demand in non-linear dimensionality reduction. First, the analysis shows an embedding, that reveals only the dominant structures in the data (Overview). Then, by selecting structures that are visible in the overview, the user can filter the data and drill down in the hierarchy. While the user descends into the hierarchy, detailed visualizations of the high-dimensional structures will lead to new insights. In this paper, we explain how Hierarchical-SNE scales to the analysis of big datasets. In addition, we show its application potential in the visualization of Deep-Learning architectures and the analysis of hyperspectral images.},
author = {Pezzotti, N. and H{\"{o}}llt, T. and Lelieveldt, B. and Eisemann, E. and Vilanova, A.},
doi = {10.1111/cgf.12878},
file = {:Users/nsawada/Google Drive/Papers/Pezzotti{\_}et{\_}al-2016-Computer{\_}Graphics{\_}Forum.pdf:pdf},
isbn = {0033-2917 (Print)},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {Categories and Subject Descriptors (according to A,I.3.0 [Computer Graphics]: General},
number = {3},
pages = {21--30},
pmid = {17112401},
title = {{Hierarchical stochastic neighbor embedding}},
volume = {35},
year = {2016}
}
@article{Lekschas2018,
abstract = {This paper presents an interactive visualization interface - HiPiler - for the exploration and visualization of regions-of-interest in large genome interaction matrices. Genome interaction matrices approximate the physical distance of pairs of genomic regions to each other and can contain up to 3 million rows and columns with many sparse regions. Traditional matrix aggregation or pan-and-zoom interfaces largely fail in supporting search, inspection, and comparison of local regions-of-interest (ROIs). ROIs can be defined, e.g., by sets of adjacent rows and columns, or by specific visual patterns in the matrix. ROIs are first-class objects in HiPiler, which represents them as thumbnail-like âsnippetsâ. Snippets can be laid out automatically based on their data and meta attributes. They are linked back to the matrix and can be explored interactively. The design of HiPiler is based on a series of semi-structured interviews with 10 domain experts involved in the analysis and interpretation of genome interaction matrices. We describe six exploration tasks that are crucial for analysis of interaction matrices and demonstrate how HiPiler supports these tasks. We report on a user study with a series of data exploration sessions with domain experts to assess the usability of HiPiler as well as to demonstrate respective findings in the data.},
annote = {an interactive visualization interfaceâHiPilerâfor the exploration and visualization of regions-of-interest in large genome interaction matrices},
author = {Lekschas, Fritz and Bach, Benjamin and Kerpedjiev, Peter and Gehlenborg, Nils and Pfister, Hanspeter},
doi = {10.1109/TVCG.2017.2745978},
file = {:Users/nsawada/Google Drive/Papers/HiPiler Visual Exploration of Large Genome Interaction Matrices with Interactive Small Multiples.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Biomedical Visualization,Genomics,Interactive Small Multiples,Matrix Comparison},
number = {1},
pages = {522--531},
publisher = {IEEE},
title = {{HiPiler: Visual exploration of large genome interaction matrices with interactive small multiples}},
volume = {24},
year = {2018}
}
@article{Sacha2018,
abstract = {Clustering is a core building block for data analysis, aiming to extract otherwise hidden structures and relations from raw datasets, such as particular groups that can be effectively related, compared, and interpreted. A plethora of visual-interactive cluster analysis techniques has been proposed to date, however, arriving at useful clusterings often requires several rounds of user interactions to fine-tune the data preprocessing and algorithms. We present a multi-stage Visual Analytics (VA) approach for iterative cluster refinement together with an implementation (SOMFlow) that uses Self-Organizing Maps (SOM) to analyze time series data. It supports exploration by offering the analyst a visual platform to analyze intermediate results, adapt the underlying computations, iteratively partition the data, and to reflect previous analytical activities. The history of previous decisions is explicitly visualized within a flow graph, allowing to compare earlier cluster refinements and to explore relations. We further leverage quality and interestingness measures to guide the analyst in the discovery of useful patterns, relations, and data partitions. We conducted two pair analytics experiments together with a subject matter expert in speech intonation research to demonstrate that the approach is effective for interactive data analysis, supporting enhanced understanding of clustering results as well as the interactive process itself.},
author = {Sacha, Dominik and Kraus, Matthias and Bernard, J{\"{u}}rgen and Behrisch, Michael and Schreck, Tobias and Asano, Yuki and Keim, Daniel A.},
doi = {10.1109/TVCG.2017.2744805},
file = {:Users/nsawada/Google Drive/Papers/SOMFlow Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Guidance,Interaction,Quality Metrics,Self-Organizing Maps,Time Series,Visual Analytics,Visual Cluster Analysis},
number = {1},
pages = {120--130},
pmid = {28866559},
title = {{SOMFlow: Guided exploratory cluster analysis with self-organizing maps and analytic provenance}},
volume = {24},
year = {2018}
}
@article{Buono2005,
abstract = {The need for pattern discovery in long time series data led researchers to develop algorithms for similarity search. Most of the literature about time series focuses on algorithms that index time series and bring the data into the main storage, thus providing fast information retrieval on large time series. This paper reviews the state of the art in visualizing time series, and focuses on techniques that enable users to visually and interactively query time series. Then, it presents TimeSearcher 2, a tool that enables users to explore multidimensional data using synchronized tables and graphs with overview+detail, filter the time series data to reduce the scope of the search, select an existing pattern to find similar occurrences, and interactively adjust similarity parameters to narrow the result set. This tool is an extension of previous work, TimeSearcher 1, which uses graphical timeboxes to interactively query time series data.},
author = {Buono, Paolo and Aris, Aleks and Plaisant, Catherine and Khella, Amir and Shneiderman, Ben},
doi = {10.1117/12.587537},
file = {:Users/nsawada/Google Drive/Papers/Interactive Pattern Search in Time Series.pdf:pdf},
isbn = {1301405272},
issn = {0277786X},
journal = {Visualization and Data Analysis},
keywords = {dynamic queries,information visualization,pattern search,time series,visual interaction},
pages = {5669:1--5669:12},
title = {{Interactive pattern search in time series}},
volume = {5669},
year = {2005}
}
@inproceedings{Dang2013a,
abstract = {The analysis of different time series is an important activity in many areas of science and engineering. In this paper, we introduce a new method feature extraction for time series and an application TimeExplorer for similarity-based time series querying. The method is based on eleven characterizations of line graphs presenting time series. These characterizations include measures, such as, means, standard deviations, differences, and periodicities. A similarity metric is then computed on these measures. Finally, we use the similarity metric to search for similar time series in the database.},
address = {Berlin, Heidelberg},
author = {Dang, Tuan Nhon and Wilkinson, Leland},
booktitle = {Proceedings of the 9th International Symposium on Advances in Visual Computing},
doi = {10.1007/978-3-642-41914-0_28},
file = {:Users/nsawada/Google Drive/Papers/TimeExplorer Similarity Search Time Series by their signatures.pdf:pdf},
pages = {280--289},
publisher = {Springer-Verlag},
title = {{TimeExplorer: Similarity search time series}},
url = {https://doi.org/10.1007/978-3-642-41914-0{\_}28},
volume = {8033},
year = {2013}
}
@article{Healey1999,
author = {Healey, Christopher G},
file = {:Users/nsawada/Google Drive/Papers/Perceptual Techniques for Scientific Visualization.pdf:pdf},
journal = {SIGGRAPH'99 Course},
pages = {1--26},
title = {{Perceptual techniques for scientific visualization}},
url = {http://www.csc.ncsu.edu/faculty/healey/download/sig-course.99.pdf},
year = {1999}
}
@article{Gleicher2018,
abstract = {Supporting comparison is a common and diverse challenge in visualization. Such support is difficult to design because solutions must address both the specifics of their scenario as well as the general issues of comparison. This paper aids designers by providing a strategy for considering those general issues. It presents four considerations that abstract comparison. These considerations identify issues and categorize solutions in a domain independent manner. The first considers how the common elements of comparison-a target set of items that are related and an action the user wants to perform on that relationship-are present in an analysis problem. The second considers why these elements lead to challenges because of their scale, in number of items, complexity of items, or complexity of relationship. The third considers what strategies address the identified scaling challenges, grouping solutions into three broad categories. The fourth considers which visual designs map to these strategies to provide solutions for a comparison analysis problem. In sequence, these considerations provide a process for developers to consider support for comparison in the design of visualization tools. Case studies show how these considerations can help in the design and evaluation of visualization solutions for comparison problems.},
author = {Gleicher, Michael},
doi = {10.1109/TVCG.2017.2744199},
file = {:Users/nsawada/Google Drive/Papers/Considerations for Visualizing Comparison.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Comparison,Information Visualization,Task Analysis,Taxonomies,Visualization Models},
number = {1},
pages = {413--423},
pmid = {28866530},
publisher = {IEEE},
title = {{Considerations for visualizing comparison}},
volume = {24},
year = {2018}
}
@article{Li2018,
author = {Li, Jie and Chen, Siming and Chen, Wei and Andrienko, Gennady and Andrienko, Natalia},
doi = {10.1109/TVCG.2018.2882449},
file = {:Users/nsawada/Google Drive/Papers/Semantics-Space-Time Cube A Conceptual Framework for Systematic Analysis of Texts in Space and Time.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {8},
pages = {1--1},
title = {{Semantics-Space-Time Cube. A Conceptual Framework for Systematic Analysis of Texts in Space and Time}},
url = {https://ieeexplore.ieee.org/document/8540796/},
volume = {14},
year = {2018}
}
@article{Hibino1999,
abstract = {Previous research in information visualization has primarily focused on providing novel views and frameworks to aid users in exploring or accessing data; very little work has been done to support users through the full analysis processâfrom the raw data to the final results. But what tasks do users perform when analyzing data using an information visualization (infoVis) environment? A task analysis of experts' use of an existing infoVis system was conducted to examine this question. Results indicate that users work on various tasks outside of data explorationâtasks such as conditioning and preparing data, collecting results, and gathering evidence for a presentation. This pilot study identifies key data analysis tasks that expert users perform when using an infoVis environment to analyze some real-life data.},
author = {Hibino, Stacie L},
doi = {10.1007/3-540-48762-X_18},
file = {:Users/nsawada/Google Drive/Papers/Task Analysis for Information Visualization.pdf:pdf},
isbn = {978-3-540-48762-3},
issn = {16113349},
journal = {Visual Information and Information Systems},
pages = {139--146},
pmid = {16979382},
title = {{Task analysis for information visualization}},
year = {1999}
}
@article{Lin2005,
abstract = {Data visualization techniques are very important for data analysis, since the human eye has been frequently advocated as the ultimate data-mining tool. However, there has been surprisingly little work on visualizing massive time series datasets. To this end, we developed VizTree, a time series pattern discovery and visualization system based on augmenting suffix trees. VizTree visually summarizes both the global and local structures of time series data at the same time. In addition, it provides novel interactive solutions to many pattern discovery problems, including the discovery of frequently occurring patterns (motif discovery), surprising patterns (anomaly detection), and query by content. VizTree works by transforming the time series into a symbolic representation, and encoding the data in a modified suffix tree in which the frequency and other properties of patterns are mapped onto colors and other visual properties. We demonstrate the utility of our system by comparing it with state-of-the-art batch algorithms on several real and synthetic datasets. Based on the tree structure, we further device a coefficient which measures the dissimilarity between any two time series. This coefficient is shown to be competitive with the well-known Euclidean distance.},
author = {Lin, Jessica and Lonardi, Stefano},
doi = {10.1057/palgrave.ivs.9500089},
file = {:Users/nsawada/Google Drive/Papers/Visualizing and Discovering Non-Trivial Patterns in Large Time Series Databases.pdf:pdf},
issn = {1473-8716},
journal = {Information Visualization},
number = {2},
pages = {61--82},
title = {{Visualizing and discovering non-trivial patterns in large time series databases}},
url = {http://journals.sagepub.com/doi/abs/10.1057/palgrave.ivs.9500089},
volume = {4},
year = {2005}
}
@inproceedings{Jiang2003,
abstract = {Discovering coherent gene expression patterns in time-series gene expression data is an important task in bioinformatics research and biomedical applications. In this paper, we propose an interactive exploration framework for mining coherent expression patterns in time-series gene expression data. We develop a novel tool, coherent pattern index graph, to give users highly confident indications of the existences of coherent patterns. To derive a coherent pattern index graph, we devise an attraction tree structure to record the genes in the data set and summarize the information needed for the interactive exploration. We present fast and scalable algorithms to construct attraction trees and coherent pattern index graphs from gene expression data sets. We conduct an extensive performance study on some real data sets to verify our design. The experimental results strongly show that our approach is more effective than the state-of-the-art methods in mining real gene expression data, and is scalable in mining large data sets.},
address = {Washington, D.C.},
author = {Jiang, Daxin and Pei, Jian and Zhang, Aidong},
booktitle = {Proceedings of the 9th SIGKDD Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/956750.956820},
file = {:Users/nsawada/Google Drive/Papers/Interactive Exploration of Coherent Patterns in Time-series gene expression daya.pdf:pdf},
isbn = {1581137370},
keywords = {bioinformatics,coherent patterns,gene expression data},
pages = {565},
title = {{Interactive exploration of coherent patterns in time-series gene expression data}},
url = {http://portal.acm.org/citation.cfm?doid=956750.956820},
year = {2003}
}
@inproceedings{Buono2008,
author = {Buono, Paolo and Simeone, Adalberto Lafcadio},
booktitle = {Proceedings of the Working Conference on Advanced Visual Interfaces},
doi = {10.1145/1385569.1385666},
file = {:Users/nsawada/Google Drive/Papers/Interactive shape specification for pattern search in time series.pdf:pdf},
isbn = {9781605581415},
keywords = {interactive,interactive visualization,visual querying,visualization},
pages = {480--481},
title = {{Interactive shape specification for pattern search in time series}},
year = {2008}
}
@article{Nonato2018,
author = {Nonato, Luis Gustavo and Aupetit, Michael},
doi = {10.1109/TVCG.2018.2846735},
file = {:Users/nsawada/Google Drive/Papers/Multidimensional Projection for Visual Analytics linking techniques with distortions, tasks, and layout enrichment.pdf:pdf},
isbn = {9787010056166},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data visualization,Dimensionality Reduction,Distortion,Error Analysis,Layout,Layout Enrichment,Multidimensional Projection,Multidimensional Scaling,Task analysis,Taxonomy,Visual perception,Visualization},
number = {c},
pages = {1},
publisher = {IEEE},
title = {{Multidimensional projection for visual analytics: linking techniques with distortions, tasks, and layout enrichment}},
volume = {PP},
year = {2018}
}
@article{Cuadros2007,
abstract = {The task of building effective representations to visualize and explore collections with moderate to large number of documents is hard. It depends on the evaluation of some distance measure among texts and also on the representation of such relationships in bi- dimensional spaces. In this paper we introduce an alternative approach for building visual maps of documents based on their content similarity, through reconstruction of phylogenetic trees. The tree is capable of representing relationships that allows the user to quickly recover information detected by the similarity metric. For a variety of text collections of different natures we show that we can achieve improved exploration capability and more clear visualization of relationships amongst documents.},
author = {Cuadros, Ana M. and Paulovich, Fernando V. and Minghim, Rosane and Telles, Guilherme P.},
doi = {10.1109/VAST.2007.4389002},
file = {:Users/nsawada/Google Drive/Papers/Point Placement by Phylogenetic Trees and its Application for Visual Analysis of Document Collections.pdf:pdf;:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Cuadros et al. - 2007 - Point placement by phylogenetic trees and its application to visual analysis of document collections.pdf:pdf},
isbn = {9781424416592},
issn = {00063495},
journal = {VAST IEEE Symposium on Visual Analytics Science and Technology 2007, Proceedings},
keywords = {Document analysis,Document visualization,Multidimensional visualization,Phylogenetic trees,Text analytics},
pages = {99--106},
title = {{Point placement by phylogenetic trees and its application to visual analysis of document collections}},
year = {2007}
}
@article{Watanabe2015,
author = {Watanabe, Kazuho and Wu, Hsiang Yun and Niibe, Yusuke and Takahashi, Shigeo and Fujishiro, Issei},
doi = {10.1109/PACIFICVIS.2015.7156389},
file = {:Users/nsawada/Google Drive/Papers/Biclustering Multivariate Data for Correlated Subspace Mining.pdf:pdf},
isbn = {9781467368797},
issn = {21658773},
journal = {IEEE Pacific Visualization Symposium},
keywords = {Multivariate data,biclustering,correlation,subspaces},
pages = {287--294},
publisher = {IEEE},
title = {{Biclustering multivariate data for correlated subspace mining}},
volume = {2015-July},
year = {2015}
}
@article{BarnettT2006,
abstract = {Tennis features among the most popular sports internationally, with professional matches played for 11 months of the year around the globe. The rise of the internet has stimulated a dramatic increase in tennis-related financial activity, much of which depends on quantitative models. This paper presents a hierarchical Markov model which yields a pre-play estimate of the probability of each player winning a professional singles tennis match. Crucially, the model provides a fair basis of comparison between players by analysing match statistics for opponents that both players have encountered in the past. Subsequently the model exploits elements of transitivity to compute the probability of each player winning a point on their serve, and hence the match. When evaluated using a data set of historical match statistics and bookmakers odds, the model yields a 3.8{\%} return on investment over 2173 ATP matches played on a variety of surfaces during 2011. ?? 2012 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1011.1761},
author = {{Barnett T} and {Brown A} and {Clarke S}},
doi = {10.1093/imaman/dpi001},
eprint = {1011.1761},
file = {:Users/nsawada/Google Drive/Papers/Parameter estimation in large dynamic paired comparison experiments.pdf:pdf},
isbn = {1049-5258},
issn = {08981221},
journal = {Proceedings of the 8th Australasian Conference on Mathematics and Computers in Sport},
keywords = {approximate bayesian estimation,bradley,chess,ranking,state space,terry model},
pages = {178--188},
pmid = {18268290},
title = {{Developing a Model That Relects Outcomes of Tennis Matches}},
url = {http://strategicgames.com.au/8mcs.pdf},
year = {2006}
}
@article{Kim2018,
author = {Kim, Donguk and Lee, Mokwon and Cho, Youngsong and Kim, Deok-Soo},
doi = {10.1109/TVCG.2018.2873633},
file = {:Users/nsawada/Google Drive/Papers/Beta-complex vs. Alpha-complex similarities and dissimilarities.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {c},
pages = {1--1},
publisher = {IEEE},
title = {{Beta-complex vs. alpha-complex: Similarities and dissimilarities}},
url = {https://ieeexplore.ieee.org/document/8496780/},
volume = {PP},
year = {2018}
}
@article{Schmidt2013,
abstract = {Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.},
author = {Schmidt, Johanna and Groller, M. Eduard and Bruckner, Stefan},
doi = {10.1109/TVCG.2013.213},
file = {:Users/nsawada/Google Drive/Papers/VAICo Visual Analysis for Image Comparison.pdf:pdf},
isbn = {1077-2626 VO  - 19},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Comparative visualization,focus+context visualization,image set comparison},
number = {12},
pages = {2090--2099},
pmid = {24051775},
title = {{VAICo: Visual analysis for image comparison}},
volume = {19},
year = {2013}
}
@article{Jang2016,
abstract = {Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge.},
author = {Jang, Sujin and Elmqvist, Niklas and Ramani, Karthik},
doi = {10.1109/TVCG.2015.2468292},
file = {:Users/nsawada/Google Drive/Papers/MotionFlow Visual Abstraction and Aggregation of Sequential patterns in human motion tracking data.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Context,Data visualization,Layout,Pattern analysis,Three-dimensional displays,Tracking,Visualization},
number = {1},
pages = {21--30},
pmid = {26529685},
publisher = {IEEE},
title = {{MotionFlow: Visual abstraction and aggregation of sequential patterns in human motion tracking data}},
volume = {22},
year = {2016}
}
@article{Jang2012,
abstract = {In many scientific simulations, the temporal variation and analysis of features are important. Visualization and visual analysis of time series data is still a significant challenge because of the large volume of data. Irregular and scattered time series data sets are even more problematic to visualize interactively. Previous work proposed functional representation using basis functions as one solution for interactively visualizing scattered data by harnessing the power of modern PC graphics boards. In this paper, we use the functional representation approach for time-varying data sets and develop an efficient encoding technique utilizing temporal similarity between time steps. Our system utilizes a graduated approach of three methods with increasing time complexity based on the lack of similarity of the evolving data sets. Using this system, we are able to enhance the encoding performance for the time-varying data sets, reduce the data storage by saving only changed or additional basis functions over time, and interactively visualize the time-varying encoding results. Moreover, we present efficient rendering of the functional representations using binary space partitioning tree textures to increase the rendering performance.},
author = {Jang, Yun and Ebert, David S. and Gaither, Kelly},
doi = {10.1109/TVCG.2011.54},
file = {:Users/nsawada/Google Drive/Papers/Time-Varying Data Visualization Using functional representations.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Basis functions,functional representation,time-varying data,volume rendering},
number = {3},
pages = {421--433},
pmid = {21383403},
publisher = {IEEE},
title = {{Time-varying data visualization using functional representations}},
volume = {18},
year = {2012}
}
@article{Frey2012,
abstract = {This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.},
author = {Frey, Steffen and Sadlo, Filip and Ertl, Thomas},
doi = {10.1109/TVCG.2012.284},
file = {:Users/nsawada/Google Drive/Papers/Visualization of Temporal Similarity in Field Data.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Time-dependent fields,comparative visualization,interactive recurrence analysis,similarity analysis},
number = {12},
pages = {2023--2032},
pmid = {26357108},
publisher = {IEEE},
title = {{Visualization of temporal similarity in field data}},
volume = {18},
year = {2012}
}
@article{Ma2018,
author = {Ma, Yuxin and Tung, Anthony K.H. and Wang, Wei and Gao, Xiang and Pan, Zhigeng and Chen, Wei},
doi = {10.1109/TVCG.2018.2875702},
file = {:Users/nsawada/Google Drive/Papers/ScatterNet A Deep Subjective Similarity Model for visual analysis of scatterplots.pdf:pdf},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Computational modeling,Feature extraction,Measurement,Neural networks,Personal area networks,Scatterplot,Visual perception,Visualization,deep learning,similarity measuring,visual exploration,visualization},
number = {8},
pages = {1--14},
title = {{ScatterNet: A deep subjective similarity model for visual analysis of scatterplots}},
volume = {14},
year = {2018}
}
@article{Chen2007,
author = {Chen, Yuan and Cohen, Jonathan D and Krolik, Julian},
file = {:Users/nsawada/Google Drive/Papers/Similarity-Guided Streamline Placement with Error Evaluation.pdf:pdf},
journal = {{\{}IEEE{\}} Trans. Vis. Comput. Graph.},
number = {6},
pages = {1448--1455},
title = {{Similarity-guided streamline placement with error evaluation}},
volume = {13},
year = {2007}
}
@article{Gogolou2018,
abstract = {A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.},
annote = {Paper type: Evaluation
Contribution: Inventigate how visualization techniques affect users' similarity perception},
author = {Gogolou, Anna and Tsandilas, Theophanis and Palpanas, Themis and Bezerianos, Anastasia},
doi = {10.1109/TVCG.2018.2865077},
file = {:Users/nsawada/Google Drive/Papers/Comparing Similarity Perception in Time Series Visualizations.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data visualization,Electroencephalography,Encoding,Task analysis,Time measurement,Time series,Time series analysis,Visualization,automatic similarity search,colorfields,evaluation,horizon graphs,line charts,similarity perception},
number = {1},
pages = {523--533},
publisher = {IEEE},
title = {{Comparing similarity perception in time series visualizations}},
volume = {25},
year = {2018}
}
@article{Tao2018,
author = {Tao, Jun and Imre, Martin and Wang, Chaoli and Chawla, Nitesh V. and Guo, Hanqi and Sever, Gokhan and Kim, Seung Hyun},
doi = {10.1109/TVCG.2018.2864808},
file = {:Users/nsawada/Google Drive/Papers/Exploring Time-Varying Multivariate Volume Data Using matrix of isosurface similarity maps.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Time-varying multivariate data visualization,isosurface,path recommendation,similarity map,visual interface},
number = {1},
pages = {1236--1245},
title = {{Exploring time-varying multivariate volume data using matrix of isosurfaces similarity maps}},
volume = {25},
year = {2018}
}
@article{Paiva2011,
abstract = {An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.},
author = {Paiva, Jose Gustavo S. and Florian, Laura and Pedrini, Helio and Telles, Guilherme P. and Minghim, Rosane},
doi = {10.1109/TVCG.2011.212},
file = {:Users/nsawada/Google Drive/Papers/Improved Similarity Trees and their Application to visual data classification.pdf:pdf},
isbn = {1941-0506 (Electronic)$\backslash$r1077-2626 (Linking)},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Image Classification,Multidimensional Projections,Similarity Trees},
number = {12},
pages = {2459--2468},
pmid = {22034367},
publisher = {IEEE},
title = {{Improved similarity trees and their application to visual data classification}},
volume = {17},
year = {2011}
}
@article{McLoughlin2013,
abstract = {Streamline seeding rakes are widely used in vector field visualization. We present new approaches for calculating similarity between integral curves (streamlines and pathlines). While others have used similarity distance measures, the computational expense involved with existing techniques is relatively high due to the vast number of euclidean distance tests, restricting interactivity and their use for streamline seeding rakes. We introduce the novel idea of computing streamline signatures based on a set of curve-based attributes. A signature produces a compact representation for describing a streamline. Similarity comparisons are performed by using a popular statistical measure on the derived signatures. We demonstrate that this novel scheme, including a hierarchical variant, produces good clustering results and is computed over two orders of magnitude faster than previous methods. Similarity-based clustering enables filtering of the streamlines to provide a nonuniform seeding distribution along the seeding object. We show that this method preserves the overall flow behavior while using only a small subset of the original streamline set. We apply focus + context rendering using the clusters which allows for faster and easier analysis in cases of high visual complexity and occlusion. The method provides a high level of interactivity and allows the user to easily fine tune the clustering results at runtime while avoiding any time-consuming recomputation. Our method maintains interactive rates even when hundreds of streamlines are used.},
author = {McLoughlin, Tony and Jones, Mark W. and Laramee, Robert S. and Malki, Rami and Masters, Ian and Hansen, Charles D.},
doi = {10.1109/TVCG.2012.150},
file = {:Users/nsawada/Google Drive/Papers/Similarity Measures for Enhancing interactive streamline seeding.pdf:pdf},
isbn = {2011080177},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Flow visualization,clustering,focus+context,similarity measures,streamlines},
number = {8},
pages = {1342--1353},
pmid = {23744264},
publisher = {IEEE},
title = {{Similarity measures for enhancing interactive streamline seeding}},
volume = {19},
year = {2013}
}
@article{Song2012,
abstract = {Line graphs have been commonly used for visualizing temporal trends in time series data. Since comparing trends is one of the main tasks for analyzing multiple temporal trends, many efforts have been made to enhance visual representations of line graphs to help people efficiently compare multiple temporal trends. However, as the number of line graphs increases, the overlap makes it difficult to perform comparison and other analyses. In this paper, we introduce DiffMatrix, a matrix-based interactive visualization designed to support effective analyses of a large number of time series data. It employs four visual representations for each cell in the matrix to show the difference between two time series-dual lines, diff line, diff area, diff heatmap-and a detail view to support more indepth analyses on individual line graphs. DiffMatrix allows users to seamlessly switch between these representations that best support their tasks. We also report possible future work we identified through case studies with three real-world time series datasets with a large number of series.},
annote = {Like!
Paper type: Design study
Contribution: Propose a new interactive comparison tool for visualizing the differences between multiple tables at multiple levels of detail over time to address the difficulty in understanding exact changes between versions and problems of other comparison tools (difficult to interpret, scalability)
Task analysis},
author = {Song, Hyunjoo and Lee, Bongshin and Kim, Bohyoung and Seo, Jinwook},
doi = {10.2312/PE/EuroVisShort/EuroVisShort2012/103-107},
file = {:Users/nsawada/Google Drive/Papers/DiffMatrix Matrix-based Interactive Visualization for Comparing Temporal Trends.pdf:pdf},
journal = {Eurographics Conference on Visualization (EuroVis)},
keywords = {General,H50 [Information Interfaces and Presentation (eg,HCI)]},
title = {{DiffMatrix: Matrix-based Interactive Visualization for Comparing Temporal Trends}},
year = {2012}
}
@article{Johnson2004,
abstract = {Scientific visualization as currently understood and practiced is still a relatively new discipline. As a result, we visualization researchers are not necessarily accustomed to undertaking the sorts of self-examinations that other scientists routinely undergo in relation to their work. Yet if we are to create a disciplinary culture focused on matters of real scientific importance and committed to real progress, it is essential that we ask ourselves hard questions on an ongoing basis. What are the most important research issues facing us? What underlying assumptions need to be challenged and perhaps abandoned? What practices need to be reviewed? In this article, I attempt to start a discussion of these issues by proposing a list of top research problems and issues in scientific visualization.},
author = {Johnson, Chris},
doi = {10.1109/MCG.2004.20},
file = {:Users/nsawada/Google Drive/Papers/Top scientific visualization research problems.pdf:pdf},
isbn = {0272-1716 VO - 24},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {4},
pages = {13--17},
title = {{Top scientific visualization research problems}},
volume = {24},
year = {2004}
}
@article{Jackle2016,
abstract = {Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns.},
author = {J{\"{a}}ckle, Dominik and Fischer, Fabian and Schreck, Tobias and Keim, Daniel A.},
doi = {10.1109/TVCG.2015.2467553},
file = {:Users/nsawada/Google Drive/Papers/temporal MDS plots for analysis of multivariate data.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Communication networks,Correlation,Data visualization,Indexes,Layout,Security,Visualization},
number = {1},
pages = {141--150},
pmid = {26529694},
title = {{Temporal MDS plots for analysis of multivariate data}},
volume = {22},
year = {2016}
}
@article{Fujishiro2018,
abstract = {{\textcopyright} Published under licence by IOP Publishing Ltd. Blazars are attractive objects for astronomers to observe in order to burrow into the magnetic field in the relativistic jet. This paper presents TimeTubes as a novel visualization scheme that allows astronomers to interactively explore characteristic temporal variation patterns in observed blazar datasets. In the TimeTubes spatialization, the two Stokes parameters and their errors with a common timestamp are transformed into an ellipse. A series of such ellipses are aligned in parallel along the timeline to form a 3D volumetric tube. The resulting tube is then colorized by the observed intensities and colors of the blazar, and finally volume-rendered. A designated user interface is provided with visual exploration functions according to Shneiderman's Visual Information Seeking Mantra. In the latest version, an auxiliary mechanism, called visual data fusion, was incorporated to ameliorate data- and mapping-inherent uncertainties for more efficient and effective visual exploration.},
author = {Fujishiro, Issei and Sawada, Naoko and Nakayama, Masanori and Wu, H.-Y. Hsiang-Yun and Watanabe, Kazuho and Takahashi, Shigeo and Uemura, Makoto},
journal = {Journal of Physics: Conference Series},
doi = {10.1088/1742-6596/1036/1/012011},
issn = {17426596},
pages = {012011:1--012011:12},
publisher = {IOP Publishing},
title = {{TimeTubes: Visual exploration of observed blazar datasets}},
volume = {1036},
year = {2018}
}
@article{VanGoethem2017a,
abstract = {Time series (such as stock prices) and ensembles (such as model runs for weather forecasts) are two important types of one-dimensional time-varying data. Such data is readily available in large quantities but visual analysis of the raw data quickly becomes infeasible, even for moderately sized data sets. Trend detection is an effective way to simplify time-varying data and to summarize salient information for visual display and interactive analysis. We propose a geometric model for trend-detection in one-dimensional time-varying data, inspired by topological grouping structures for moving objects in two- or higher-dimensional space. Our model gives provable guarantees on the trends detected and uses three natural parameters: granularity, support-size, and duration. These parameters can be changed on-demand. Our system also supports a variety of selection brushes and a time-sweep to facilitate refined searches and interactive visualization of (sub-)trends. We explore different visual styles and interactions through which trends, their persistence, and evolution can be explored.},
annote = {From Duplicate 2 (Multi-Granular Trend Detection for Time-Series Analysis - Van Goethem, Arthur; Staals, Frank; L??ffler, Maarten; Dykes, Jason; Speckmann, Bettina; L{\"{o}}ffler, Maarten; Dykes, Jason; Speckmann, Bettina)

From Duplicate 2 (Multi-granular trend detection for time-series analysis - Van Goethem, Arthur; Staals, Frank; L??ffler, Maarten; Dykes, Jason; Speckmann, Bettina)

æç³»åãã¼ã¿ã®å¾ååæã«é¢ããè«æ},
author = {{Van Goethem}, Arthur and Staals, Frank and L??ffler, Maarten and Dykes, Jason and Speckmann, Bettina and L{\"{o}}ffler, Maarten and Dykes, Jason and Speckmann, Bettina},
doi = {10.1109/TVCG.2016.2598619},
file = {:Users/nsawada/Google Drive/Papers/Multi-Granular Trend Detection for Time-Series Analysis.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Interactive Exploration,Time Series,Trend Detection},
number = {1},
pages = {661--670},
title = {{Multi-Granular Trend Detection for Time-Series Analysis}},
volume = {23},
year = {2017}
}
@article{Biswas2017,
abstract = {{\textcopyright} 2016 IEEE.Uncertainty quantification in climate ensembles is an important topic for the domain scientists, especially for decision making in the real-world scenarios. With powerful computers, simulations now produce time-varying and multi-resolution ensemble data sets. It is of extreme importance to understand the model sensitivity given the input parameters such that more computation power can be allocated to the parameters with higher influence on the output. Also, when ensemble data is produced at different resolutions, understanding the accuracy of different resolutions helps the total time required to produce a desired quality solution with improved storage and computation cost. In this work, we propose to tackle these non-trivial problems on the Weather Research and Forecasting (WRF) model output. We employ a moment independent sensitivity measure to quantify and analyze parameter sensitivity across spatial regions and time domain. A comparison of clustering structures across three resolutions enables the users to investigate the sensitivity variation over the spatial regions of the five input parameters. The temporal trend in the sensitivity values is explored via an MDS view linked with a line chart for interactive brushing. The spatial and temporal views are connected to provide a full exploration system for complete spatio-temporal sensitivity analysis. To analyze the accuracy across varying resolutions, we formulate a Bayesian approach to identify which regions are better predicted at which resolutions compared to the observed precipitation. This information is aggregated over the time domain and finally encoded in an output image through a custom color map that guides the domain experts towards an adaptive grid implementation given a cost model. Users can select and further analyze the spatial and temporal error patterns for multi-resolution accuracy analysis via brushing and linking on the produced image. In this work, we collaborate with a domain expert whose feedback shows the effectiveness of our proposed exploration work-flow.},
author = {Biswas, Ayan and Lin, Guang and Liu, Xiaotong and Shen, Han-Wei Wei},
doi = {10.1109/TVCG.2016.2598869},
file = {:Users/nsawada/Google Drive/Papers/Visualization of Time-Varying Weather Ensembles Across Multiple Resolutions.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Ensemble,multi-resolution,sensitivity analysis,time-varying},
month = {jan},
number = {1},
pages = {841--850},
title = {{Visualization of time-varying weather ensembles across multiple resolutions}},
url = {http://ieeexplore.ieee.org/document/7539581/},
volume = {23},
year = {2017}
}
@article{Torgerson1952a,
abstract = {Multidimensional scaling can be considered as involving three basic steps. In the first step, a scale of comparative distances between all pairs of stimuli is obtained. This scale is analogous to the scale of stimuli obtained in the traditional paired comparisons methods. In this scale, however, instead of locating each stimulus-object on a given continuum, the distances between each pair of stimuli are located on a distance continuum. As in paired comparisons, the procedures for obtaining a scale of comparative distances leave the true zero point undetermined. Hence, a comparative distance is not a distance in the usual sense of the term, but is a distance minus an unknown constant. The second step involves estimating this unknown constant. When the unknown constant is obtained, the comparative distances can be converted into absolute distances. In the third step, the dimensionality of the psychological space necessary to account for these absolute distances is determined, and the projections of stimuli on axes of this space are obtained. A set of analytical procedures was developed for each of the three steps given above, including a least-squares solution for obtaining comparative distances by the complete method of triads, two practical methods for estimating the additive constant, and an extension of Young and Householder's Euclidean model to include procedures for obtaining the projections of stimuli on axes from fallible absolute distances.},
author = {Torgerson, Warren S},
doi = {10.1007/BF02288916},
file = {:Users/nsawada/Google Drive/Papers/Multidimentional Scaling.pdf:pdf},
isbn = {0033-3123},
issn = {0033-3123},
journal = {Psychometrica},
number = {4},
pages = {401--419},
title = {{Multidimensional scaling: I. Theory and method}},
volume = {17},
year = {1952}
}
@article{Sacha2017b,
abstract = {Trajectory-based visualization of coordinated movement data within a bounded area, such as player and ball movement within a soccer pitch, can easily result in visual crossings, overplotting, and clutter. Trajectory abstraction can help to cope with these issues, but it is a challenging problem to select the right level of abstraction (LoA) for a given data set and analysis task. We present a novel dynamic approach that combines trajectory simplification and clustering techniques with the goal to support interpretation and understanding of movement patterns. Our technique provides smooth transitions between different abstraction types that can be computed dynamically and on-the-fly. This enables the analyst to effectively navigate and explore the space of possible abstractions in large trajectory data sets. Additionally, we provide a proof of concept for supporting the analyst in determining the LoA semi-automatically with a recommender system. Our approach is illustrated and evaluated by case studies, quantitative measures, and expert feedback. We further demonstrate that it allows analysts to solve a variety of analysis tasks in the domain of soccer},
annote = {Paper type: Design study? Technique?
Contributions: Propose a novel dynamic VA approach that combines trajectory simplification and clustering techniques with the goal to support interpretation and understanding ofmovement patterns
requirement},
author = {Sacha, D. and Al-Masoudi, F. and Stein, M. and Schreck, T. and Keim, D. A. and Andrienko, G. and Janetzko, H.},
doi = {10.1111/cgf.13189},
file = {:Users/nsawada/Google Drive/Papers/Sacha{\_}et{\_}al-2017-Computer{\_}Graphics{\_}Forum.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {1.3.3 [Computer Graphics]: Picture/Image Generatio,1.3.6 [Computer Graphics]: Methodology and Techniq,Categories and Subject Descriptors (according to A,H.5.2 [Information Interfaces and Presentation]: U},
number = {3},
pages = {305--315},
pmid = {23319318},
title = {{Dynamic visual abstraction of soccer movement}},
volume = {36},
year = {2017}
}
@article{Monroe2013,
abstract = {Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.},
annote = {Paper type: Technique/design study
Contributions: the design of a series of intuitive and effective controls that allow users to quickly simplify an event record dataset down to its most meaningful elements and most accurate rep- resentation
sparse modeling, abstraction, symplification},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Monroe, Megan and Lan, Rongjian and Lee, Hanseung and Plaisant, Catherine and Shneiderman, Ben},
doi = {10.1109/TVCG.2013.200},
eprint = {15334406},
file = {:Users/nsawada/Google Drive/Papers/Temporal Event Sequence Simplification.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Event sequences,electronic heath records,simplification,temporal query},
number = {12},
pages = {2227--2236},
pmid = {24051789},
publisher = {IEEE},
title = {{Temporal event sequence simplification}},
volume = {19},
year = {2013}
}
@article{Kern2018,
author = {Kern, Michael and Hewson, Tim and Schafler, Andreas and Westermann, Rudiger and Rautenhaus, Marc},
doi = {10.1109/TVCG.2018.2864806},
file = {:Users/nsawada/Google Drive/Papers/Interactive 3D Visual Analysis of Atmospheric Fronts.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Atmospheric Fronts,Feature Detection,Meteorology},
number = {1},
pages = {1080--1090},
title = {{Interactive 3D visual analysis of atmospheric fronts}},
volume = {25},
year = {2018}
}
@article{Rautenhaus2015,
abstract = {We present Met.3D, a new open-source tool for the interactive 3-D visualization of numerical ensemble weather predictions. The tool has been developed to support weather forecasting during aircraft-based atmospheric field campaigns, however, is applicable to further forecasting, research and teaching activities. Our work approaches challenging topics related to the visual analysis of numerical atmospheric model output - 3-D visualization, ensemble visualization, and how both can be used in a meaningful way suited to weather forecasting. Met.3D builds a bridge from proven 2-D visualization methods commonly used in meteorology to 3-D visualization by combining both visualization types in a 3-D context. We address the issue of spatial perception in the 3-D view and present approaches to using the ensemble to allow the user to assess forecast uncertainty. Interactivity is key to our approach. Met.3D uses modern graphics technology to achieve interactive visualization on standard consumer hardware. The tool supports forecast data from the European Centre for Medium Range Weather Forecasts and can operate directly on ECMWF hybrid sigma-pressure level grids. We describe the employed visualization algorithms, and analyse the impact of the ECMWF grid topology on computing 3-D ensemble statistical quantitites. Our techniques are demonstrated with examples from the T-NAWDEX-Falcon 2012 campaign. [ABSTRACT FROM AUTHOR]},
author = {Rautenhaus, M. and Kern, M. and Sch{\"{a}}fler, A. and Westermann, R.},
doi = {10.5194/gmd-8-2329-2015},
file = {:Users/nsawada/Google Drive/Papers/Three-dimensional visualization of ensemble weather forecasts.pdf:pdf},
issn = {19919603},
journal = {Geoscientific Model Development},
number = {7},
pages = {2329--2353},
title = {{Three-dimensional visualization of ensemble weather forecasts - Part 1: The visualization tool Met.3D (version 1.0)}},
volume = {8},
year = {2015}
}
@article{Pousman2007,
abstract = {Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose Casual Information Visualization (or Casual Infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization [32], social visualization, and also from artistic work that visualizes information [41]. We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative proper ties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.},
archivePrefix = {arXiv},
arxivId = {00006199-199103000-00014.},
author = {Pousman, Zachary and Stasko, John T. and Mateas, Michael},
doi = {10.1109/TVCG.2007.70541},
eprint = {00006199-199103000-00014.},
file = {:Users/nsawada/Google Drive/Papers/Casual Information Visualization Depictions of Data in Everyday Life.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Ambient infovis,Casual information visualization,Design,Editorial,Evaluation,Social infovis},
number = {6},
pages = {1145--1152},
pmid = {17968058},
title = {{Casual information visualization: Depictions of data in everyday life}},
volume = {13},
year = {2007}
}
@article{Dimara2018,
author = {Dimara, Evanthia and Bezerianos, Anastasia and Dragicevic, Pierre},
doi = {10.1109/TVCG.2017.2745138},
file = {:Users/nsawada/Google Drive/Papers/Conceptual and Methodological Issues in Evaluating Multidimensional Visualizations for Decision Support.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {749--759},
publisher = {IEEE},
title = {{Conceptual and methodological issues in evaluating multidimensional visualizations for decision support}},
volume = {24},
year = {2018}
}
@article{Cao2018,
author = {Cao, Nan and Lin, Chaoguang and Zhu, Qiuhan and Lin, Yu-ru and Teng, Xian and Wen, Xidao},
doi = {10.1109/TVCG.2017.2744419},
file = {:Users/nsawada/Google Drive/Papers/Voila Visual Anomaly Detection and Monitoring with Streaming Spatiotemporal Data.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {23--33},
publisher = {IEEE},
title = {{Voila : Visual anomaly detection and monitoring with streaming spatiotemporal data}},
volume = {24},
year = {2018}
}
@article{Andrienko2018,
author = {Andrienko, Gennady and Andrienko, Natalia and Fuchs, Georg and Manuel, Jose and Garcia, Cordero},
doi = {10.1109/TVCG.2017.2744322},
file = {:Users/nsawada/Google Drive/Papers/Clustering Trajectories by Relevant Parts for Air Traffic Analysis.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {34--44},
publisher = {IEEE},
title = {{Clustering trajectories by relevant parts for air traffic analysis}},
volume = {24},
year = {2018}
}
@article{Kim2018a,
author = {Kim, Seokyeon and Jeong, Seongmin and Woo, Insoo and Jang, Yun and Maciejewski, Ross and Ebert, David S},
doi = {10.1109/TVCG.2017.2666146},
file = {:Users/nsawada/Google Drive/Papers/Data Flow Analysis and Visualization for Spatiotemporal Statistical Data without Trajectory Information.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {3},
pages = {1287--1300},
publisher = {IEEE},
title = {{Data flow analysis and visualization for spatiotemporal statistical data without trajectory information}},
volume = {24},
year = {2018}
}
@article{Perin2018,
author = {Perin, Charles and Wun, Tiffany and Pusch, Richard and Carpendale, Sheelagh},
doi = {10.1109/TVCG.2017.2743918},
file = {:Users/nsawada/Google Drive/Papers/Assessing the Graphical Perception of Time and Speed on 2D + Time Trajectories.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {698--708},
publisher = {IEEE},
title = {{Assessing the graphical perception of time and speed on 2D + time trajectories}},
volume = {24},
year = {2018}
}
@article{Brehmer2017,
author = {Brehmer, Matthew and Lee, Bongshin and Bach, Benjamin and Riche, Nathalie Henry and Munzner, Tamara},
file = {:Users/nsawada/Google Drive/Papers/Timelines Revisited A Design Space and Considerations for Expressive Storytelling.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {9},
pages = {2151--2164},
title = {{Timelines revisited : A design space and considerations for expressive storytelling}},
volume = {23},
year = {2017}
}
@article{Miranda2018a,
author = {Miranda, Fabio and Lins, Lauro and Klosowski, James T and Silva, Claudio T},
doi = {10.1109/TVCG.2017.2671341},
file = {:Users/nsawada/Google Drive/Papers/TopKube A Rank-Aware Data Cube for Real-Time Exploration of Spatiotemporal Data.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {3},
pages = {1394--1407},
publisher = {IEEE},
title = {{TOPKUBE : A rank-aware data cube for real-time exploration of spatiotemporal data}},
volume = {24},
year = {2018}
}
@article{Loorak2016,
author = {Loorak, Mona Hosseinkhani and Perin, Charles and Kamal, Noreen and Hill, Michael and Carpendale, Sheelagh},
doi = {10.1109/TVCG.2015.2467325},
file = {:Users/nsawada/Google Drive/Papers/TimeSpan Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {409--418},
publisher = {IEEE},
title = {{TimeSpan : Using visualization to explore temporal multi-dimensional data of stroke patients}},
volume = {22},
year = {2016}
}
@article{Kern2018a,
annote = {Paper type: Design paper
Contributions: propose a method that exploits directional information in the wind field to extract core lines in a robust and numerically less involved manner than traditional 3D ridge detection},
author = {Kern, Michael and Hewson, Tim and Sadlo, Filip and Rautenhaus, Marc},
doi = {10.1109/TVCG.2017.2743989},
file = {:Users/nsawada/Google Drive/Papers/Robust Detection and Visualization of Jet-Stream Core Lines in Atmospheric Flow.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {893--902},
title = {{Robust detection and visualization of jet-stream core lines in atmospheric flow}},
volume = {24},
year = {2018}
}
@article{Saket2017,
abstract = {Although data visualization tools continue to improve, during the data exploration process many of them require users to manually specify visualization techniques, mappings, and parameters. In response, we present the Visualization by Demonstration paradigm, a novel interaction method for visual data exploration. A system which adopts this paradigm allows users to provide visual demonstrations of incremental changes to the visual representation. The system then recommends potential transformations (Visual Representation, Data Mapping, Axes, and View Specification transformations) from the given demonstrations. The user and the system continue to collaborate, incrementally producing more demonstrations and refining the transformations, until the most effective possible visualization is created. As a proof of concept, we present VisExemplar, a mixed-initiative prototype that allows users to explore their data by recommending appropriate transformations in response to the given demonstrations.},
annote = {Paper type:
Contributions: Present a novel interaction method for visual data exploration to allow users to provide visual demonstrations of incremental changes to the visual representation},
author = {Saket, Bahador and Kim, Hannah and Brown, Eli T and Endert, Alex},
doi = {10.1109/TVCG.2016.2598839},
file = {:Users/nsawada/Google Drive/Papers/Visualization by Demonstration An Interaction Paradigm for Visual Data Exploration.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Automobiles,Bars,Data visualization,Encoding,Image color analysis,Spatial databases,Visualization},
mendeley-tags = {Automobiles,Bars,Data visualization,Encoding,Image color analysis,Spatial databases,Visualization},
number = {1},
pages = {331--340},
title = {{Visualization by demonstration: An interaction paradigm for visual data exploration}},
volume = {23},
year = {2017}
}
@article{Niederer2018,
annote = {Like!
Paper type: Design study
Contribution: Propose a new interactive comparison tool for visualizing the differences between multiple tables at multiple levels of detail over time to address the difficulty in understanding exact changes between versions and problems of other comparison tools (difficult to interpret, scalability)
Task analysis},
author = {Niederer, Christina and Stitz, Holger and Hourieh, Reem and Grassinger, Florian and Aigner, Wolfgang and Streit, Marc},
doi = {10.1109/TVCG.2017.2745298},
file = {:Users/nsawada/Google Drive/Papers/TACO Visualizing Changes in Tables Over Time.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {677--686},
publisher = {IEEE},
title = {{TACO : Visualizing changes in tables over time}},
volume = {24},
year = {2018}
}
@article{Wattenberg2006a,
abstract = {The NameVoyager, a Web-based visualization of historical trends in baby naming, has proven remarkably popular. We describe design decisions behind the application and lessons learned in creating an application that makes do-it-yourself data mining popular. The prime lesson, it is hypothesized, is that an information visualization tool may be fruitfully viewed not as a tool but as part of an online social environment. In other words, to design a successful exploratory data analysis tool, one good strategy is to create a system that enables "social" data analysis. We end by discussing the design of an extension of the NameVoyager to a more complex data set, in which the principles of social data analysis played a guiding role.},
annote = {Contributions: Evaluate the authors' previous work, named the "NameVoyager", through the analysis of web comments from users and hypothesize the factors which encourage users' social data analysis. And then, it presents a new case study on book sales data.},
author = {Wattenberg, Martin and Kriss, Jesse},
doi = {10.1109/TVCG.2006.65},
file = {:Users/nsawada/Google Drive/Papers/Designing for Social Data Analysis.pdf:pdf},
isbn = {078039464X},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Design study,Human-computer interaction,Social data analysis,Time-varying data visualization},
number = {4},
pages = {549--557},
pmid = {16805263},
publisher = {IEEE},
title = {{Designing for social data analysis}},
volume = {12},
year = {2006}
}
@article{Borkin2011,
abstract = {Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.},
author = {Borkin, Michelle A. and Gajos, Krzysztof Z. and Peters, Amanda and Mitsouras, Dimitrios and Melchionna, Simone and Rybicki, Frank J. and Feldman, Charles L. and Pfister, Hanspeter},
doi = {10.1109/TVCG.2011.192},
file = {:Users/nsawada/Google Drive/Papers/Evaluation of Artery Visualizations for Heart Disease Diagnosis.pdf:pdf},
isbn = {1941-0506 (Electronic)$\backslash$r1077-2626 (Linking)},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Quantitative evaluation,biomedical and medical visualization,qualitative evaluation},
number = {12},
pages = {2479--2488},
pmid = {22034369},
publisher = {IEEE},
title = {{Evaluation of artery visualizations for heart disease diagnosis}},
volume = {17},
year = {2011}
}
@article{Borkin2013,
abstract = {Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56{\%}) compared to men (70{\%}) with Orbiter.},
author = {Borkin, Michelle A. and Yeh, Chelsea S. and Boyd, Madelaine and MacKo, Peter and Gajos, Krzysztof Z. and Seltzer, Margo and Pfister, Hanspeter},
doi = {10.1109/TVCG.2013.155},
file = {:Users/nsawada/Google Drive/Papers/Evaluation of Filesystem Provenance Visualization Tools.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Provenance data,gender differences,graph/network data,hierarchy data,quantitative evaluation},
number = {12},
pages = {2476--2485},
pmid = {24051814},
publisher = {IEEE},
title = {{Evaluation of filesystem provenance visualization tools}},
volume = {19},
year = {2013}
}
@article{B.Viegas2007,
abstract = {We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.},
annote = {Contributions: Enabling end-user creation of visualizations and fostering large-scale collaborative usage at the Internet Scale},
author = {{B. Viegas}, Fernanda and Wattenberg, Martin and {Van Ham}, Frank and Kriss, Jesse and McKeon, Matt},
doi = {10.1109/TVCG.2007.70577},
file = {:Users/nsawada/Google Drive/Papers/Many Eyes A Site for Visualization at Internet Scale.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {6},
pages = {1121--1128},
title = {{Many Eyes: A site for visualization at internet scale}},
url = {https://ieeexplore.ieee.org/document/4376131},
volume = {13},
year = {2007}
}
@article{Haehn2014,
abstract = {Fig. 1: Proofreading with Dojo. We present a web-based application for interactive proofreading of automatic segmentations of connectome data acquired via electron microscopy. Split, merge and adjust functionality enables multiple users to correct the labeling of neurons in a collaborative fashion. Color-coded structures can be explored in 2D and 3D. Abstract-Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron mi-croscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multiuser web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.},
author = {Haehn, Daniel and Knowles-Barley, Seymour and Roberts, Mike and Beyer, Johanna and Kasthuri, Narayanan and Lichtman, Jeff W and Pfister, Hanspeter},
doi = {10.1109/TVCG.2014.2346371},
file = {:Users/nsawada/Google Drive/Papers/Haehn et al. - Unknown - Design and Evaluation of Interactive Proofreading Tools for Connectomics.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Connectomics,Index Terms-Proofreading,Quantitative Evaluation,Segmentation},
number = {12},
pages = {2466--2475},
title = {{Design and evaluation of interactive proofreading tools for Connectomics}},
url = {http://www.rhoana.org.},
volume = {20},
year = {2014}
}
@inproceedings{Pfister2000,
abstract = {Surface elements (surfels) are a powerful paradigm to efficiently render complex geometric objects at interactive frame rates. Unlike classical surface discretizations, i.e., triangles or quadrilateral meshes, surfels are point primitives without explicit connectivity. Surfel attributes comprise depth, texture color, normal, and others. As a pre-process, an octree-based surfel representation of a geometric object is computed. During sampling, surfel positions and normals are optionally perturbed, and different levels of texture colors are prefiltered and stored per surfel. During rendering, a hierarchical forward warping algorithm projects surfels to a z-buffer. A novel method called visibility splatting determines visible surfels and holes in the z-buffer. Visible surfels are shaded using texture filtering, Phong illumination, and environment mapping using per-surfel normals. Several methods of image reconstruction, including supersampling, offer flexible speed-quality tradeoffs. Due to the simplicity of the operations, the surfel rendering pipeline is amenable for hardware implementation. Surfel objects offer complex shape, low rendering cost and high image quality, which makes them specifically suited for low-cost, real-time graphics, such as games.},
address = {New York, New York, USA},
author = {Pfister, Hanspeter and Zwicker, Matthias and van Baar, Jeroen and Gross, Markus},
booktitle = {Proceedings of the 27th annual conference on Computer graphics and interactive techniques  - SIGGRAPH '00},
doi = {10.1145/344779.344936},
file = {:Users/nsawada/Google Drive/Papers/Pfister et al. - 2000 - Surfels Surface elements as rendering primitives.pdf:pdf},
isbn = {1581132085},
pages = {335--342},
publisher = {ACM Press},
title = {{Surfels: Surface elements as rendering primitives}},
url = {http://portal.acm.org/citation.cfm?doid=344779.344936},
year = {2000}
}
@article{Marscher2008,
abstract = {Blazars are the most extreme active galactic nuclei. They possess oppositely directed plasma jets emanating at near light speeds from accreting supermassive black holes. According to theoretical models, such jets are propelled by magnetic fields twisted by differential rotation of the black hole's accretion disk or inertial-frame-dragging ergosphere. The flow velocity increases outward along the jet in an acceleration and collimation zone containing a coiled magnetic field. Detailed observations of outbursts of electromagnetic radiation, for which blazars are famous, can potentially probe the zone. It has hitherto not been possible to either specify the location of the outbursts or verify the general picture of jet formation. Here we report sequences of high-resolution radio images and optical polarization measurements of the blazar BL Lacertae. The data reveal a bright feature in the jet that causes a double flare of radiation from optical frequencies to TeV gamma-ray energies, as well as a delayed outburst at radio wavelengths. We conclude that the event starts in a region with a helical magnetic field that we identify with the acceleration and collimation zone predicted by the theories. The feature brightens again when it crosses a standing shock wave corresponding to the bright 'core' seen on the images.},
archivePrefix = {arXiv},
arxivId = {Figures, S., 2010. Supplementary information. Nature, 1(c), pp.1â7. Available at: http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3006164{\&}tool=pmcentrez{\&}rendertype=abstract.},
author = {Marscher, Alan P. and Jorstad, Svetlana G. and D'Arcangelo, Francesca D. and Smith, Paul S. and Williams, G. Grant and Larionov, Valeri M. and Oh, Haruki and Olmstead, Alice R. and Aller, Margo F. and Aller, Hugh D. and McHardy, Ian M. and L{\"{a}}hteenm{\"{a}}ki, Anne and Tornikoski, Merja and Valtaoja, Esko and Hagen-Thorn, Vladimir A. and Kopatskaya, Eugenia N. and Gear, Walter K. and Tosti, Gino and Kurtanidze, Omar and Nikolashvili, Maria and Sigua, Lorand and Miller, H. Richard and Ryle, Wesley T.},
doi = {10.1038/nature06895},
eprint = {/www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3006164{\&}tool=pmcentrez{\&}rendertype=abstract.},
file = {:Users/nsawada/Google Drive/Papers/nature06895.pdf:pdf},
isbn = {4936551015},
issn = {14764687},
journal = {Nature},
number = {7190},
pages = {966--969},
pmid = {18432239},
primaryClass = {Figures, S., 2010. Supplementary information. Nature, 1(c), pp.1â7. Available at: http:},
title = {{The inner jet of an active galactic nucleus as revealed by a radio-to-$\gamma$-ray outburst}},
volume = {452},
year = {2008}
}
@article{Liu2017,
abstract = {Eurographics Conference on Visualization (EuroVis) - STARs},
author = {Liu, Shusen and Maljovec, Dan and Wang, Bei and Bremer, Peer Timo and Pascucci, Valerio},
doi = {10.1109/TVCG.2016.2640960},
file = {:Users/nsawada/Google Drive/Papers/Visualizing High-Dimensional Data Advances in the Past Decade.pdf:pdf},
isbn = {-},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Taxonomy,computational modeling,data models,high-dimensional data,multidimensional data,visualization},
number = {3},
pages = {1249--1268},
pmid = {28113321},
title = {{Visualizing high-dimensional data: Advances in the past decade}},
volume = {23},
year = {2017}
}
@article{Kruiger2017,
abstract = {Understanding large multidimensional datasets is one of the most challenging problems in visual data exploration. One key challenge that increases the size of the exploration space is the number of views that one can generate from a single dataset, based on the use of multiple parameter values and exploration paths. Often, no such single view contains all needed insights. The question thus arises of how we can efficiently combine insights from multiple views of a dataset. We propose a set of techniques that considerably reduce the exploration effort for such situations, based on the explicit depiction of the view space, using a small multiple metaphor. We leverage this view space by offering interactive techniques that enable users to explicitly create, visualize, and follow their exploration path. This way, partial insights obtained from each view can be efficiently and effectively combined. We demonstrate our approach by applications using real-world datasets from air traffic control, software maintenance, and machine learning.},
author = {Kruiger, Johannes and Hassoumi, Almoctar and Schulz, Hans-J{\"{o}}rg and Telea, AlexandruC and Hurter, Christophe},
doi = {10.3390/informatics4030026},
file = {:Users/nsawada/Google Drive/Papers/Multidimensional Data Exploration by Explicitly Controlled Animation.pdf:pdf},
issn = {2227-9709},
journal = {Informatics},
keywords = {animation,big data,information visualization,small multiple},
number = {3},
pages = {26},
title = {{Multidimensional data exploration by explicitly controlled animation}},
url = {http://www.mdpi.com/2227-9709/4/3/26},
volume = {4},
year = {2017}
}
@article{Elmqvist2008,
abstract = {Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.},
annote = {Like the structure! Interesting! Related!
https://www.youtube.com/watch?v=E1birsp9iYk},
author = {Elmqvist, Niklas and Dragicevic, Pierre and Fekete, Jean Daniel},
doi = {10.1109/TVCG.2008.153},
file = {:Users/nsawada/Google Drive/Papers/Rolling the Dice Multidimensional Visual Exploration using Scatterplot Matrix Navigation.pdf:pdf},
isbn = {1077-2626 VO - 14},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Interaction,Multivariate data,Navigation,Visual analytics,Visual exploration,Visual queries},
number = {6},
pages = {1141--1148},
title = {{Rolling the Dice: Multidimensional visual exploration using scatterplot matrix navigation}},
volume = {14},
year = {2008}
}
@article{Wilkinson2006,
abstract = {We introduce a method for organizing multivariate displays and for guiding interactive exploration through high-dimensional data. The method is based on nine characterizations of the 2D distributions of orthogonal pairwise projections on a set of points in multidimensional Euclidean space. These characterizations include such measures as density, skewness, shape, outliers, and texture. Statistical analysis of these measures leads to ways for 1) organizing 2D scatterplots of points for coherent viewing, 2) locating unusual (outlying) marginal 2D distributions of points for anomaly detection, and 3) sorting multivariate displays based on high-dimensional data, such as trees, parallel coordinates, and glyphs.},
archivePrefix = {arXiv},
arxivId = {1077-2626},
author = {Wilkinson, Leland and Anand, Anushka and Grossman, Robert},
doi = {10.1109/TVCG.2006.94},
eprint = {1077-2626},
file = {:Users/nsawada/Google Drive/Papers/High-Dimensional Visual Analytics Interactive Exploration Guided by Pairwise Views of Point Distributions.pdf:pdf},
isbn = {1077-2626 (Print)$\backslash$r1077-2626 (Linking)},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Statistical graphics,Visualization},
number = {6},
pages = {1363--1372},
pmid = {17073361},
title = {{High-dimensional visual analytics: Interactive exploration guided by pairwise views of point distributions}},
volume = {12},
year = {2006}
}
@article{Viau2010,
abstract = {A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.},
author = {Viau, Christophe and McGuffin, Michael J. and Chiricota, Yves and Jurisica, Igor},
doi = {10.1109/TVCG.2010.205},
file = {:Users/nsawada/Google Drive/Papers/The FlowVizMenu and Parallel Scatterplot Matrix Hybrid Multidimensional Visualizations for Network Exploration.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {attribute-driven layout,interactive graph drawing,network layout,parallel coordinates,radial menu,scatterplot matrix},
number = {6},
pages = {1100--1108},
pmid = {20975148},
title = {{The FlowVizMenu and parallel scatterplot matrix: Hybrid multidimensional visualizations for network exploration}},
volume = {16},
year = {2010}
}
@article{Bikakis2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1601.08059v1},
author = {Bikakis, Nikos and Athens, N T U},
eprint = {arXiv:1601.08059v1},
file = {:Users/nsawada/Google Drive/Papers/Exploration and Visualization in the Web of Big Linked Data A Survey of the State of the Art.pdf:pdf},
issn = {16130073},
journal = {6th International Workshop on Linked Web Data Management},
keywords = {big data,big data challenges,data exploration,exploration,large databases,scalability,semantic web,stat,survey,visual analytics,visual exploration,visualization,visualization tools},
title = {{Exploration and visualization in the web of big linked data: A survey of the state of the art}},
url = {https://www.semanticscholar.org/paper/Exploration-and-Visualization-in-the-Web-of-Big-Bikakis-Sellis/a979fec7e4803af4068cd83f75eb15bb09d79989},
volume = {abs/1601.0},
year = {2016}
}
@article{Roweis2000,
abstract = {Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.},
annote = {we take a different approach, called locally linear embedding (LLE),that eliminates the need to estimate pairwise distances between widely separated data points.
LLE: ï½åã®Neighborã¨ã®è·é¢ãæå°ã«ãªãããã«è»¸ãæ±ºãã},
archivePrefix = {arXiv},
arxivId = {1011.1669v3},
author = {Roweis, Sam T. and Saul, Lawrence K.},
doi = {10.1126/science.290.5500.2323},
eprint = {1011.1669v3},
file = {:Users/nsawada/Google Drive/Papers/Nonlinear Dimensionality Reduction by Locally Linear Embedding.pdf:pdf},
isbn = {00368075},
issn = {0036-8075},
journal = {Science},
number = {5500},
pages = {2323--2326},
pmid = {11125150},
title = {{Nonlinear dimensionality reduction by locally linear embedding}},
volume = {290},
year = {2000}
}
@article{Tenenbaum2000,
abstract = {Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.},
annote = {an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set
our approach is capable of discovering the nonlinear degrees of freedom that underlie com- plex natural observations
âââââââââââââââ
Our goal is to discover, given only the unordered high-dimensional inputs, low-dimensional representations such as Fig. 1A with coordi- nates that capture the intrinsic degrees of freedom of a data set.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Tenenbaum, Joshua B. and de Silva, Vin and Langford, John C.},
doi = {10.1126/science.290.5500.2319},
eprint = {arXiv:1011.1669v3},
file = {:Users/nsawada/Google Drive/Papers/A Global Geometric Framework for Nonlinear Dimensionality Reduction.pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
keywords = {Algorithms,Artificial Intelligence,Face,Humans,Mathematics,Pattern Recognition,Visual,Visual Perception},
number = {5500},
pages = {2319--2323},
pmid = {11125149},
title = {{A global geometric framework for nonlinear dimensionality reduction}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11125149},
volume = {290},
year = {2000}
}
@article{Saul2001,
abstract = {Introduction of the concept of pseudo amino acid composition (PROTEINS: Structure, Function, and Genetics 43 (2001) 246; Erratum: ibid. 44 (2001) 60) has made it possible to incorporate a considerable amount of sequence-order effects by representing a protein sample in terms of a set of discrete numbers, and hence can significantly enhance the prediction quality of membrane protein type. As a continuous effort along such a line, the Supervised Locally Linear Embedding (SLLE) technique for nonlinear dimensionality reduction is introduced (Science 22 (2000) 2323). The advantage of using SLLE is that it can reduce the operational space by extracting the essential features from the high-dimensional pseudo amino acid composition space, and that the cluster-tolerant capacity can be increased accordingly. As a consequence by combining these two approaches, high success rates have been observed during the tests of self-consistency, jackknife and independent data set, respectively, by using the simplest nearest neighbour classifier. The current approach represents a new strategy to deal with the problems of protein attribute prediction, and hence may become a useful vehicle in the area of bioinformatics and proteomics. {\textcopyright} 2004 Elsevier Ltd. All rights reserved.},
annote = {we review the LLE algorithm in its most basic form and illustrate a potential application to audiovisual speech synthesis},
author = {Saul, Lawrence K. and Roweis, Sam T.},
doi = {10.1016/j.jtbi.2004.07.023},
file = {:Users/nsawada/Google Drive/Papers/An Introduction to Locally Linear Embedding.pdf:pdf},
isbn = {0022-5193},
issn = {00225193},
journal = {Journal of Machine Learning Research},
keywords = {Bioinformatics,Chou's invariance theorem,Covariant discriminant algorithm,Membrane protein types,Nonlinear dimensionality reduction,Pseudo amino acid composition,SLLE},
pages = {7--15},
pmid = {15498588},
title = {{An Introduction to Locally Linear Embedding}},
volume = {7},
year = {2001}
}
@inproceedings{Donoho2003,
abstract = {We describe a method for recovering the underlying parametrization of scattered data (m(i)) lying on a manifold M embedded in high-dimensional Euclidean space. The method, Hessian-based locally linear embedding, derives from a conceptual framework of local isometry in which the manifold M, viewed as a Riemannian submanifold of the ambient Euclidean Space R(n), is locally isometric to an open, connected subset $\Theta$ of Euclidean space R(d). Because $\Theta$ does not have to be convex, this framework is able to handle a significantly wider class of situations than the original ISOMAP algorithm. The theoretical framework revolves around a quadratic form H(f) = â«(M)||H(f)(m)||Â²(F)dm defined on functions f: M--{\textgreater} R. Here Hf denotes the Hessian of f, and H(f) averages the Frobenius norm of the Hessian over M. To define the Hessian, we use orthogonal coordinates on the tangent planes of M. The key observation is that, if M truly is locally isometric to an open, connected subset of R(d), then H(f) has a (d + 1)-dimensional null space consisting of the constant functions and a d-dimensional space of functions spanned by the original isometric coordinates. Hence, the isometric coordinates can be recovered up to a linear isometry. Our method may be viewed as a modification of locally linear embedding and our theoretical framework as a modification of the Laplacian eigenmaps framework, where we substitute a quadratic form based on the Hessian in place of one based on the Laplacian.},
annote = {In this article we describe a method that works to recover a parametrization for data lying on a manifold that is locally isometric to an open, connected subset â° of Euclidean space Rd.},
author = {Donoho, D. L. and Grimes, C.},
booktitle = {Proceedings of the National Academy of Sciences},
doi = {10.1073/pnas.1031596100},
file = {:Users/nsawada/Google Drive/Papers/Hessian eigenmaps Locally linear embedding techniques for high-dimensional data.pdf:pdf},
isbn = {1031596100},
issn = {0027-8424},
number = {10},
pages = {5591--5596},
pmid = {16576753},
title = {{Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1031596100},
volume = {100},
year = {2003}
}
@article{Gastal2012,
abstract = {We present a technique for performing high-dimensional filtering of images and videos in real time. Our approach produces high-quality results and accelerates filtering by computing the filter's response at a reduced set of sampling points, and using these for interpolation at all N input pixels. We show that for a proper choice of these sampling points, the total cost of the filtering operation is linear both in N and in the dimension d of the space in which the filter operates. As such, ours is the first high-dimensional filter with such a complexity. We present formal derivations for the equations that define our filter, as well as for an algorithm to compute the sam- pling points. This provides a sound theoretical justification for our method and for its properties. The resulting filter is quite flexible, being capable of producing responses that approximate either stan- dard Gaussian, bilateral, or non-local-means filters. Such flexibility also allows us to demonstrate the first hybrid Euclidean-geodesic filter that runs in a single pass. Our filter is faster and requires less memory than previous approaches, being able to process a 10- Megapixel full-color image at 50 fps on modern GPUs. We illus- trate the effectiveness of our approach by performing a variety of tasks ranging from edge-aware color filtering in 5-D, noise reduc- tion (using up to 147 dimensions), single-pass hybrid Euclidean- geodesic filtering, and detail enhancement, among others.},
annote = {ãªã¢ã«ã¿ã¤ã ã§ç»åããããªã®é«æ¬¡åãã£ã«ã¿ãªã³ã°ãå®è¡ããæè¡
æ¸ããããµã³ããªã³ã°ãã¤ã³ãã»ããã§ãã£ã«ã¿ã®ã¬ã¹ãã³ã¹ãè¨ç®ããããããNåãã¹ã¦ã®å¥åãã¯ã»ã«ã«å¯¾ããè£éã«ç¨ãããã¨ã§ãé«åè³ªã®çµæãä½ãåºãããã£ã«ã¿ãªã³ã°ï¼ã¼ããããããã£ããããããï¼ãé«éåããã},
author = {Gastal, Eduardo S. L. and Oliveira, Manuel M.},
doi = {10.1145/2185520.2185529},
file = {:Users/nsawada/Google Drive/Papers/Adaptive Manifolds for Real-Time High-Dimensional Filtering.pdf:pdf},
isbn = {0730-0301},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {bilateral,br,eslgastal,euclidean filters,filters,high-dimensional filters,hybrid euclidean-geodesic filters,inf,non-local-means filters,oliveira,ufrgs},
number = {4},
pages = {33:1--33:13},
title = {{Adaptive manifolds for real-time high-dimensional filtering}},
url = {http://dl.acm.org/citation.cfm?doid=2185520.2185529},
volume = {31},
year = {2012}
}
@inproceedings{Brand2003,
abstract = {We construct a nonlinear mapping from a high-dimensional sample space to a low-dimensional vector space, effectively recovering a Cartesian coordinate system for the manifold from which the data is sampled. The mapping preserves local geometric relations in the manifold and is pseudo-invertible. We show how to estimate the intrinsic dimensionality of the manifold from samples, decompose the sample data into locally linear low-dimensional patches, merge these patches into a single low-dimensional coordinate system, and compute forward and reverse mappings between the sample and coordinate spaces. The objective functions are convex and their solutions are given in closed form.},
annote = {Abstract
é«æ¬¡åã®ãµã³ãã«ç©ºéããä½æ¬¡åã®ãã¯ãã«ç©ºéã¸ã®éç·å½¢ãããã³ã°ãå¹æçã«ãã¼ã¿ããµã³ãã«ããããããã©ã¼ã«ãã®ãã«ã«ãåº§æ¨ç³»ããªã«ãã¼ã§ããã
è«æåã§ç¤ºãã¦ãããã¨
ã»ãµã³ãã«ãããããã©ã¼ã«ãã®åºæã®æ¬¡åãè¦ç©ãã
ã»ãã¼ã¿ãã­ã¼ã«ã«ã«ç·å½¢ãªä½æ¬¡åã®ãããã«decompose
ã»ãããã®ããããä¸ã¤ã®ä½æ¬¡ååº§æ¨ç³»ã«èå
ã»ãµã³ãã«ã¨è»¸ç©ºéã®éãè¨ç®ãããæ»ããã
âââââââââââââââ
ãã®è«æã®goalã¯ããµã³ãã«ç¹ã®å¯åº¦ã¨ç¸å¯¾çãªä½ç½®ã«é¢ããæå ±ã®ã­ã¹ãæå°ã«ãããããªãããã³ã°ãè¦ã¤ãããã¨

},
author = {Brand, Matthew},
booktitle = {Advances in Neural Information Processing Systems 15},
editor = {B., Becker and S., Thrun and K., Obermayer},
file = {:Users/nsawada/Google Drive/Papers/Charting a Manifold.pdf:pdf},
isbn = {0262025507},
issn = {10495258},
pages = {961--968},
publisher = {MIT Press},
title = {{Charting a manifold}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.6374{\&}rep=rep1{\&}type=pdf},
year = {2003}
}
@article{Zhang2012,
abstract = {Manifold learning algorithms seek to find a low-dimensional parameterization of high-dimensional data. They heavily rely on the notion of what can be considered as local, how accurately the manifold can be approximated locally, and, last but not least, how the local structures can be patched together to produce the global parameterization. In this paper, we develop algorithms that address two key issues in manifold learning: 1) the adaptive selection of the local neighborhood sizes when imposing a connectivity structure on the given set of high-dimensional data points and 2) the adaptive bias reduction in the local low-dimensional embedding by accounting for the variations in the curvature of the manifold as well as its interplay with the sampling density of the data set. We demonstrate the effectiveness of our methods for improving the performance of manifold learning algorithms using both synthetic and real-world data sets.},
annote = {ãã®è«æã§ã¯ãããã©ã¼ã«ãã©ã¼ãã³ã°ã«é¢ããäºã¤ã®éè¦ãªåé¡ã«åãçµãã§ãã
1. è¿é£ã®ãµã¤ãºï¼ã®é©å¿æ·æ±°
ï¼ã©ããã£ã¦ã­ã¼ã«ã«ãªæ¥ç¶æ§ãconstructããããã«ãk-nearest neighbor computationã«ããã¦è¿æ¥ãµã¤ãºãé©ç¨çã«é¸æããã
2. ãããã©ã¼ã«ãã®å±æ²ã®å¤åã¨ãã¼ã¿ã»ããã®ãµã³ããªã³ã°å¯åº¦ã¨ã®ç¸äºä½ç¨ãèæ®ããã­ã¼ã«ã«ãªå¹¾ä½å­¦æ§é ã¸ã®ãããããã£ããã£ã³ã°
ï¼ã©ã®ããã«ãããã©ã¼ã«ãã«ãããæ²æ§ã®å¤åã¨ãã¼ã¿ã®ãµã³ããªã³ã°å¯åº¦ã¨ã®ç¸é¢ãèæ®ããã
ââââââââââââ
ä¸è¨ã®äºã¤ã®åé¡ã«ãLocal tangent space alignmentï¼LTSAï¼ãLocally linear embedding(LLE)ã®ããªã¨ã¼ã·ã§ã³ã¨ã®é¢é£ã§è­°è«ãã¦ããã},
author = {Zhang, Zhenyue and Wang, Jing and Zha, Hongyuan},
doi = {10.1109/TPAMI.2011.115},
file = {:Users/nsawada/Google Drive/Papers/Adaptive Manifold Learning.pdf:pdf},
isbn = {9781424454099},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Manifold learning,bias reduction,classification,dimensionality reduction,neighborhood selection},
number = {2},
pages = {253--265},
pmid = {21670485},
title = {{Adaptive manifold learning}},
volume = {34},
year = {2012}
}
@article{Berger2011a,
author = {Berger, W. and Piringer, H. and Filzmoser, P. and Groller, M. E.},
doi = {10.1111/j.1467-8659.2011.01940.x},
isbn = {1467-8659},
issn = {01677055},
journal = {Computer Graphics Forum},
number = {3},
pages = {911--920},
title = {{Uncertainty-aware exploration of continnuous parameter spaces using multivariate prediction.}},
volume = {30(3)},
year = {2011}
}
@article{Honma2016a,
abstract = {{\textcopyright} Published under licence by IOP Publishing Ltd. We introduce a new imaging method for radio interferometry based on sparse- modeling. The direct observables in radio interferometry are visibilities, which are Fourier transformation of an astronomical image on the sky-plane, and incomplete sampling of visibilities in the spatial frequency domain results in an under-determined problem, which has been usually solved with 0 filling to un-sampled grids. In this paper we propose to directly solve this under-determined problem using sparse modeling without 0 filling, which realizes super resolution, i.e., resolution higher than the standard refraction limit. We show simulation results of sparse modeling for the Event Horizon Telescope (EHT) observations of super-massive black holes and demonstrate that our approach has significant merit in observations of black hole shadows expected to be realized in near future. We also present some results with the method applied to real data, and also discuss more advanced techniques for practical observations such as imaging with closure phase as well as treating the effect of interstellar scattering effect.},
author = {Honma, Mareki and Akiyama, Kazunori and Tazaki, Fumie and Kuramochi, Kazuki and Ikeda, Shiro and Hada, Kazuhiro and Uemura, Makoto},
doi = {10.1088/1742-6596/699/1/012006},
issn = {17426596},
journal = {Journal of Physics: Conference Series},
month = {mar},
number = {1},
pages = {012006:1--012006:9},
title = {{Imaging black holes with sparse modeling}},
url = {http://stacks.iop.org/1742-6596/699/i=1/a=012006?key=crossref.4c2d56fdca448d1397c14df8b6a00e4f},
volume = {699},
year = {2016}
}
@article{Ferdosiy2011,
abstract = {Abstract High-dimensional data visualization is receiving increasing interest because of the growing abundance of high-dimensional datasets. To understand such datasets, visualization of the structures present in the data, such as clusters, can be an invaluable tool. Structures may be present in the full high-dimensional space, as well as in its subspaces. Two widely used methods to visualize high-dimensional data are the scatter plot matrix (SPM) and the parallel coordinate plot (PCP). SPM allows a quick overview of the structures present in pairwise combinations of dimensions. On the other hand, PCP has the potential to visualize not only bi-dimensional structures but also higher dimensional ones. A problem with SPM is that it suffers from crowding and clutter which makes interpretation hard. Approaches to reduce clutter are available in the literature, based on changing the order of the dimensions. However, usually this reordering has a high computational complexity. For effective visualization of high-dimensional structures, also PCP requires a proper ordering of the dimensions. In this paper, we propose methods for reordering dimensions in PCP in such a way that high-dimensional structures (if present) become easier to perceive. We also present a method for dimension reordering in SPM which yields results that are comparable to those of existing approaches, but at a much lower computational cost. Our approach is based on finding relevant subspaces for clustering using a quality criterion and cluster information. The quality computation and cluster detection are done in image space, using connected morphological operators. We demonstrate the potential of our approach for synthetic and astronomical datasets, and show that our method compares favorably with a number of existing approaches. [PUBLICATION ABSTRACT]},
author = {Ferdosiy, Bilkis J. and Roerdinkz, Jos B T M and Ferdosi, Bilkis J},
doi = {10.1111/j.1467-8659.2011.01961.x},
file = {:Users/nsawada/Google Drive/Papers/Visualizing HighDimensional Structures by Dimension Ordering and Filtering using Subspace Analysis.pdf:pdf},
isbn = {01677055},
issn = {01677055},
journal = {Computer Graphics Forum},
number = {3},
pages = {1121--1130},
title = {{Visualizing high-dimensional structures by dimension ordering and filtering using subspace analysis}},
volume = {30},
year = {2011}
}
@article{Sedlmair2014,
abstract = {Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.},
author = {Sedlmair, Michael and Heinzl, Christoph and Bruckner, Stefan and Piringer, Harald and Moller, Torsten and M{\"{o}}ller, Torsten},
doi = {10.1109/tvcg.2014.2346321},
file = {:Users/nsawada/Google Drive/Papers/Visual Parameter Space Analysis A Conceptual Framework.pdf:pdf},
isbn = {1077-2626},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {dec},
number = {12},
pages = {2161--2170},
title = {{Visual parameter space analysis: A conceptual framework}},
url = {http://ieeexplore.ieee.org/document/6876043/},
volume = {20},
year = {2014}
}
@inproceedings{Weber2001,
abstract = {In this paper, we present a new approach for the visualiza- tion of time-series data based on spirals. Different to classi- cal bar charts and line graphs, the spiral is suited to visualize large data sets and supports much better the iden- tification of periodic structures in the data. Moreover, it sup- ports both the visualization of nominal and quantitative data based on a similar visualization metaphor. The extension of the spiral visualization to 3D gives access to concepts for zooming and focusing and linking in the data set. The spiral comes with additional tools to further enhance the identifi- cation of cycles},
author = {Weber, Marc and Alexa, Marc and Muller, W. and M{\"{u}}ller, Wolfgang},
booktitle = {Proceedings of IEEE Symposium on Information Visualization 2001},
doi = {10.1109/INFVIS.2001.963273},
isbn = {0-7695-7342-5},
issn = {1522-404X},
keywords = {Data Mining.,Graph Drawing,Information Visualization,Visualization of Time-Series Data,data mining,graph drawing,information visualization,sualization of time-series data,vi-},
pages = {7--14},
title = {{Visualizing time-series on spirals}},
url = {http://ieeexplore.ieee.org/document/963273/},
year = {2001}
}
@article{Navratil2007a,
abstract = {We describe our visualization process for a particle-based simulation of the formation of the first stars and their impact on cosmic history. The dataset consists of several hundred time-steps of point simulation data, with each time-step containing approximately two million point particles. For each time-step, we interpolate the point data onto a regular grid using a method taken from the radiance estimate of photon mapping [21]. We import the resulting regular grid representation into ParaView [24], with which we extract isosurfaces across multiple variables. Our images provide insights into the evolution of the early universe, tracing the cosmic transition from an initially homogeneous state to one of increasing complexity. Specifically, our visualizations capture the build-up of regions of ionized gas around the first stars, their evolution, and their complex interactions with the surrounding matter. These observations will guide the upcoming James Webb Space Telescope, the key astronomy mission of the next decade.},
annote = {From Duplicate 1 (Visualization of cosmological particle-based datasets - Navratil, Paul; Johnson, Jarrett; Bromm, Volker)

æ°ç¾ã®æéã¹ãããã®ã·ãã¥ã¬ã¼ã·ã§ã³ãã¼ã¿Hï¼SPHæ³ãç¨ãã¦æåã®æã®å¨ãã®ãã®ã®ã¤ã³ãã¯ããè¨ç®ã
åæéã¹ãããã¯2ç¾ä¸ã®ãã¼ãã£ã¯ã«ãããªã
åæã®å®å®ã®é²åã¨ããfirst starï¼å®å®ã§ä¸çªæåã®æï¼ã®ãªããã¡ã¨ããå¯è¦å},
archivePrefix = {arXiv},
arxivId = {0708.0961},
author = {Navr{\'{a}}til, Paul Arthur and Johnson, Jarrett L. and Bromm, Volker and Navratil, Paul and Johnson, Jarrett L. and Bromm, Volker},
doi = {10.1109/TVCG.2007.70526},
eprint = {0708.0961},
file = {:Users/nsawada/Google Drive/Papers/Visualization of Cosmological Particle-Based Datasets.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Astronomy,Cosmology,Interpolation,Isosurface},
month = {nov},
number = {6},
pages = {1712--1718},
pmid = {17968129},
title = {{Visualization of cosmological particle-based datasets}},
url = {http://ieeexplore.ieee.org/document/4376206/},
volume = {13},
year = {2007}
}
@article{Miao2018,
author = {Miao, H. and {De Llano}, E. and Isenberg, T. and Gr{\"{o}}ller, M. E. and Bari{\v{s}}i{\'{c}}, I. and Viola, I.},
doi = {10.1111/cgf.13429},
file = {:Users/nsawada/Google Drive/Papers/DimSUM Dimension and scale unifying map for visual abstraction of DNA origami structures.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {Applied computing â Computational biology,CCS Concepts,Human-centered computing â Scientific visualizatio,Visualization theory,concepts and paradigms},
number = {3},
pages = {403--413},
title = {{DimSUM: Dimension and scale unifying map for visual abstraction of DNA origami structures}},
volume = {37},
year = {2018}
}
@article{Mohammed2018,
abstract = {This paper presents Abstractocyte, a system for the visual analysis of astrocytes and their relation to neurons, in nanoscale volumes of brain tissue. Astrocytes are glial cells, i.e., non-neuronal cells that support neurons and the nervous system. The study of astrocytes has immense potential for understanding brain function. However, their complex and widely-branching structure requires high-resolution electron microscopy imaging and makes visualization and analysis challenging. Furthermore, the structure and function of astrocytes is very different from neurons, and therefore requires the development of new visualization and analysis tools. With Abstractocyte, biologists can explore the morphology of astrocytes using various visual abstraction levels, while simultaneously analyzing neighboring neurons and their connectivity. We define a novel, conceptual 2D abstraction space for jointly visualizing astrocytes and neurons. Neuroscientists can choose a specific joint visualization as a point in this space. Interactively moving this point allows them to smoothly transition between different abstraction levels in an intuitive manner. In contrast to simply switching between different visualizations, this preserves the visual context and correlations throughout the transition. Users can smoothly navigate from concrete, highly-detailed 3D views to simplified and abstracted 2D views. In addition to investigating astrocytes, neurons, and their relationships, we enable the interactive analysis of the distribution of glycogen, which is of high importance to neuroscientists. We describe the design of Abstractocyte, and present three case studies in which neuroscientists have successfully used our system to assess astrocytic coverage of synapses, glycogen distribution in relation to synapses, and astrocytic-mitochondria coverage.},
author = {Mohammed, Haneen and Al-Awami, Ali K. and Beyer, Johanna and Cali, Corrado and Magistretti, Pierre and Pfister, Hanspeter and Hadwiger, Markus},
doi = {10.1109/TVCG.2017.2744278},
file = {:Users/nsawada/Google Drive/Papers/abstractocyte a visual tool for exploring nanoscale astroglial cells.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Connectomics,Data Abstraction,Interactive 3D Visualization,Neuroscience},
number = {1},
pages = {853--861},
pmid = {28866534},
title = {{Abstractocyte: A visual tool for exploring nanoscale astroglial cells}},
volume = {24},
year = {2018}
}
@article{Pfister2001,
abstract = {Direct volume rendering is a key technology for visualizing large$\backslash$n3D data sets from scientific or medical applications. Transfer functions$\backslash$nare particularly important to the quality of direct volume-rendered$\backslash$nimages. A transfer function assigns optical properties, such as color$\backslash$nand opacity, to original values of the data set being visualized.$\backslash$nUnfortunately, finding good transfer functions proves difficult. It is$\backslash$none of the major problems in volume visualization. The article examines$\backslash$nfour of the currently most promising approaches to transfer function$\backslash$ndesign. The four approaches are: trial and error, with minimum computer$\backslash$naid; data-centric, with no underlying assumed model; data-centric, using$\backslash$nan underlying data model; and image-centric, using organized sampling$\backslash$n},
author = {Pfister, Hanspeter and Lorensen, Bill and Bajaj, Chandrajit and Kindlmann, Gordon and Schroeder, Will and Avila, Lisa Sobierajski and Martin, Ken and Machiraju, Raghu and Lee, Jinho},
doi = {10.1109/38.920623},
file = {:Users/nsawada/Google Drive/Papers/The Transfer Function Bake-Off.pdf:pdf},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {3},
pages = {16--22},
title = {{The transfer function bake-off}},
volume = {21},
year = {2001}
}
@article{Lipsa2012,
abstract = {Close collaboration with other scientific fields is an important goal for the visualization community. Yet engaging in a scientific collaboration can be challenging. The physical sciences, namely astronomy, chemistry, earth sci- ences and physics, exhibit an extensive range of research directions, providing exciting challenges for visualization scientists and creating ample possibilities for collaboration. We present the first survey of its kind that provides a comprehensive view of existing work on visualization for the physical sciences. We introduce novel classification schemes based on application area, data dimensionality and main challenge addressed, and apply these classifi- cations to each contribution from the literature. Our survey helps in understanding the status of current research and serves as a useful starting point for those interested in visualization for the physical sciences.},
author = {LipÅa, Dan R. and Laramee, Robert S. and Cox, Simon J. and Roberts, Jonathan C. and Walker, Rick and Borkin, Michelle A. and Pfister, Hanspeter},
doi = {10.1111/j.1467-8659.2012.03184.x},
file = {:Users/nsawada/Google Drive/Papers/Lip-a{\_}et{\_}al-2012-Computer{\_}Graphics{\_}Forum.pdf:pdf},
isbn = {01677055},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {scientific visualization,visualization},
number = {8},
pages = {2317--2347},
title = {{Visualization for the physical sciences}},
volume = {31},
year = {2012}
}
@article{Post2003,
abstract = {Flow visualisation is an attractive topic in data visualisation, offering great challenges for research. Very large data sets must be processed, consisting of multivariate data at large numbers of grid points, often arranged in many time steps. Recently, the steadily increasing performance of computers again has become a driving force for new advances in flow visualisation, especially in techniques based on texturing, feature extraction, vector field clustering, and topology extraction.

In this article we present the state of the art in featureâbased flow visualisation techniques. We will present numerous feature extraction techniques, categorised according to the type of feature. Next, feature tracking and event detection algorithms are discussed, for studying the evolution of features in timeâdependent data sets. Finally, various visualisation techniques are demonstrated.},
author = {Post, Frits H. and Vrolijk, Benjamin and Hauser, Helwig and Laramee, Robert S. and Doleisch, Helmut},
doi = {10.1111/j.1467-8659.2003.00723.x},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Post et al. - 2003 - The state of the art in flow visualisation Feature extraction and tracking.pdf:pdf},
journal = {Computer Graphics Forum},
month = {dec},
number = {4},
pages = {775--792},
publisher = {Wiley/Blackwell (10.1111)},
title = {{The state of the art in flow visualisation: Feature extraction and tracking}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2003.00723.x},
volume = {22},
year = {2003}
}
@article{Law2003,
author = {Law, Averill M and Law, Averill M and Box, P O},
file = {:Users/nsawada/Google Drive/Papers/Visualization methods for time-dependent data - an overview.pdf:pdf},
pages = {66--70},
title = {{Proceedings of the 2003 Winter Simulation Conference S. Chick, P. J. S{\'{a}}nchez, D. Ferrin, and D. J. Morrice, eds.}},
year = {2003}
}
@inproceedings{Djorgovski2005,
abstract = {We review the origins of the Virtual Observatory (VO) concept, and the current status of the efforts in this field. VO is the response of the astronomical community to the challenges posed by the modern massive and complex data sets. It is a framework in which information technology is harnessed to organize, maintain, and explore the rich information content of the exponentially growing data sets, and to enable a qualitatively new science to be done with them. VO will become a complete, open, distributed, web-based framework for astronomy of the early 21st century. A number of significant efforts worldwide are now striving to convert this vision into reality. The technological and methodological challenges posed by the information-rich astronomy are also common to many other fields. We see a fundamental change in the way all science is done, driven by the information technology revolution.},
archivePrefix = {arXiv},
arxivId = {astro-ph/0504006},
author = {Djorgovski, S. G. and Williams, R.},
booktitle = {Proceedings of Astronomical Society of the Pacific Conference Series},
eprint = {0504006},
file = {:Users/nsawada/Google Drive/Papers/Virtual Observatory From Concept to Implementation.pdf:pdf},
pages = {517--530},
primaryClass = {astro-ph},
title = {{Virtual Observatory: From concept to implementation}},
url = {http://arxiv.org/abs/astro-ph/0504006},
volume = {345},
year = {2005}
}
@article{Rang2008,
author = {Rang, Joachim},
file = {:Users/nsawada/Google Drive/Papers/Visualization of Multi-variate Scientific Data.pdf:pdf},
title = {{Visualization of scientific data}},
year = {2008}
}
@article{Xu2016,
author = {Xu, Longyin and Nakayama, Masanori and Wu, Hsiang-Yun and Watanabe, Kazuho and Takahashi, Shigeo and Uemura, Makoto and Fujishiro, Issei},
doi = {10.1109/NicoInt.2016.3},
file = {:Users/nsawada/Google Drive/Papers/TimeTubes.pdf:pdf},
journal = {Proceedings of NICOGRAPH International 2016},
keywords = {3d information visualization,blazar,data,multivariate data},
pages = {15--20},
title = {{TimeTubes: A visualization tool for time-dependent, multivariate datasets}},
year = {2016}
}
@article{Hopf2004a,
author = {Hopf, Matthias and Luttenberger, Michael},
file = {:Users/nsawada/Google Drive/Papers/Hierarchical splatting of scattered 4D data.pdf:pdf},
number = {August},
pages = {64--72},
title = {{Splatting of Scattered 4D Data positions is necessary to provide scientists visual clues}},
year = {2004}
}
@misc{,
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - JIEICE99-05.pdf(2).pdf:pdf},
title = {{IEICEå­¦ä¼èª99{\_}5.pdf}}
}
@article{Dykes2018,
author = {Dykes, T and Hassan, A and Gheller, C and Croton, D and Krokos, M},
doi = {10.1093/mnras/sty855},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Dykes et al. - 2018 - Interactive 3D visualization for theoretical virtual observatories.pdf:pdf},
issn = {0035-8711},
journal = {Monthly Notices of the Royal Astronomical Society},
month = {jun},
number = {2},
pages = {1495--1507},
publisher = {Oxford University Press},
title = {{Interactive 3D visualization for theoretical virtual observatories}},
url = {https://academic.oup.com/mnras/article/477/2/1495/4962400},
volume = {477},
year = {2018}
}
@article{Rubel2018,
abstract = {Mass spectrometry imaging (MSI) is a transtormative imaging method that supports the untargeted, quantitative measurement of the chemical composition and spatial heterogeneity of complex samples with broad applications in life sciences, bioenergy, and health. While MSI data can be routinely collected, its broad application is currently limited by the lack of easily accessible analysis methods that can process data of the size, volume, diversity, and complexity generated by MSI experiments. The development and application of cutting-edge analytical methods is a core driver in MSI research for new scientific discoveries, medical diagnostics, and commercial-innovation. However, the lack of means to share, apply, and reproduce analyses hinders the broad application, validation, and use of novel MSI analysis methods. To address this central challenge, we introduce the Berkeley Analysis and Storage Toolkit (BASTel), a novel framework for shareable and reproducible data analysis that supports standardized data and analysis interfaces, integrated data storage, data provenance, workflow management, and a broad set of integrated tools. Based on BASTet, we describe the extension of the OpenMSl mass spectrometry imaging science gateway to enable web-based sharing, reuse, analysis, and visualization of data analyses and derived data products. We demonstrate the application of BASTet and OpenMSl in practice to identify and compare characteristic substructures in the mouse brain based on their chemical composition measured via MSI.},
author = {Rubel, Oliver and Bowen, Benjamin P and R{\"{u}}bel, O and Bowen, Benjamin P},
doi = {10.1109/TVCG.2017.2744479},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Rubel et al. - 2018 - BASTet Shareable and reproducible analysis and visualization of mass spectrometry imaging data via OpenMSl.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Chemical analysis,Computer software,Data Sharing,Data handlin,Data provenance,Data visualization,Mass spectroscopy},
number = {1},
pages = {1025--1035},
title = {{BASTet: Shareable and reproducible analysis and visualization of mass spectrometry imaging data via OpenMSl}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028711599{\&}doi=10.1109{\%}2FTVCG.2017.2744479{\&}partnerID=40{\&}md5=ed08c67415ad9ee80b1a99e0116908fa},
volume = {24},
year = {2018}
}
@article{Pomarede2017,
abstract = {Cosmography, the study and making of maps of the universe or cosmos, is a field where visual representation benefits from modern three-dimensional visualization techniques and media. At the extragalactic distance scales, visualization is contributing in understanding the complex structure of the local universe, in terms of spatial distribution and flows of galaxies and dark matter. In this paper, we report advances in the field of extragalactic cosmography obtained using the SDvision visualization software in the context of the Cosmicflows Project. Here, multiple visualization techniques are applied to a variety of data products: catalogs of galaxy positions and galaxy peculiar velocities, reconstructed velocity field, density field, gravitational potential field, velocity shear tensor viewed in terms of its eigenvalues and eigenvectors, envelope surfaces enclosing basins of attraction. These visualizations, implemented as high-resolution images, videos, and interactive viewers, have contributed to a number of studies: the cosmography of the local part of the universe, the nature of the Great Attractor, the discovery of the boundaries of our home supercluster of galaxies Laniakea, the mapping of the cosmic web, the study of attractors and repellers.},
archivePrefix = {arXiv},
arxivId = {1702.01941},
author = {Pomar{\`{e}}de, Daniel and Courtois, H{\'{e}}l{\`{e}}ne M. and Hoffman, Yehuda and Tully, R. Brent},
doi = {10.1088/1538-3873/aa5b73},
eprint = {1702.01941},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Pomar{\`{e}}de et al. - 2017 - Cosmography and data visualization.pdf:pdf},
issn = {00046280},
journal = {Publications of the Astronomical Society of the Pacific},
keywords = {Large-scale structure of universe},
number = {975},
pages = {058002},
title = {{Cosmography and data visualization}},
volume = {129},
year = {2017}
}
@inproceedings{Wenskovitch2016,
address = {Macau},
author = {Wenskovitch, John E. and Lombardi, James C. and Hatfull, Roger W. M.},
booktitle = {SIGGRAPH ASIA 2016 Symposium on Visualization},
doi = {10.1145/3002151.3002154},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Wenskovitch, Lombardi, Hatfull - 2016 - FluxE Exploring flux in astrophysical simulations.pdf:pdf},
isbn = {9781450345477},
pages = {15:1--15:8},
publisher = {ACM Press},
title = {{FluxE: Exploring flux in astrophysical simulations}},
url = {http://dl.acm.org/citation.cfm?doid=3002151.3002154},
year = {2016}
}
@article{Steffen2017,
abstract = {We demonstrate the potential for research and outreach of mixed polygon and hydrodynamic modeling and multi-waveband rendering in the interactive 3-D astrophysical virtual laboratory Shape. In 3-D special effects and animation software for the mass media, computer graphics techniques that mix polygon and numerical hydrodynamics have become common place. In astrophysics, however, interactive modeling with polygon structures has only become available with the software Shape. Numerical hydrodynamic simulations and their visualization are usually separate, while in Shape it is integrated with the polygon modeling approach that requires no programming by the user. With two generic examples, we demonstrate that research and outreach modeling can be achieved with techniques similar to those used in the media industry with the added capability for physical rendering at any wavelength band, yielding more realistic radiation modeling. Furthermore, we show how the hydrodynamics and the polygon mesh modeling can be mixed to achieve results that are superior to those obtained using either one of these modeling techniques alone.},
author = {Steffen, W. and Koning, N.},
doi = {10.1016/J.ASCOM.2017.06.002},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Steffen, Koning - 2017 - Hybrid polygon and hydrodynamic nebula modeling with multi-waveband radiation transfer in astrophysics.pdf:pdf},
issn = {2213-1337},
journal = {Astronomy and Computing},
month = {jul},
pages = {87--96},
publisher = {Elsevier},
title = {{Hybrid polygon and hydrodynamic nebula modeling with multi-waveband radiation transfer in astrophysics}},
url = {https://www.sciencedirect.com/science/article/pii/S2213133717300525},
volume = {20},
year = {2017}
}
@inproceedings{AÃfalg2009,
author = {A{\ss}falg, Johannes and Kriegel, Hans-Peter and Kr{\"{o}}ger, Peer and Renz, Matthias},
booktitle = {Proceedings of the 21st International Conference on Scientific and Statistical Database Management},
doi = {10.1007/978-3-642-02279-1_31},
editor = {Winslett, Marianne},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/A{\ss}falg et al. - 2009 - Probabilistic similarity search for uncertain time series.pdf:pdf},
pages = {435--443},
publisher = {Springer, Berlin, Heidelberg},
title = {{Probabilistic similarity search for uncertain time series}},
url = {http://link.springer.com/10.1007/978-3-642-02279-1{\_}31},
year = {2009}
}
@inproceedings{Yeh2009,
address = {New York, New York, USA},
author = {Yeh, Mi-Yen and Wu, Kun-Lung and Yu, Philip S. and Chen, Ming-Syan},
booktitle = {Proceedings of the 12th International Conference on Extending Database Technology Advances in Database Technology},
doi = {10.1145/1516360.1516439},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Yeh et al. - 2009 - PROUD A probabilistic approach to processing similarity queries over uncertain data streams.pdf:pdf},
isbn = {9781605584225},
pages = {684--695},
publisher = {ACM Press},
title = {{PROUD: A probabilistic approach to processing similarity queries over uncertain data streams}},
url = {http://portal.acm.org/citation.cfm?doid=1516360.1516439},
year = {2009}
}
@inproceedings{Sarangi2010,
address = {New York, New York, USA},
author = {Sarangi, Smruti R. and Murthy, Karin},
booktitle = {Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining},
doi = {10.1145/1835804.1835854},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Sarangi, Murthy - 2010 - DUST A generalized notion of similarity between uncertain time series.pdf:pdf},
isbn = {9781450300551},
pages = {383--392},
publisher = {ACM Press},
title = {{DUST: A generalized notion of similarity between uncertain time series}},
url = {http://dl.acm.org/citation.cfm?doid=1835804.1835854},
year = {2010}
}
@article{Miller2006,
abstract = {We present GyVe, an interactive visualization tool for understanding structure in sparse three-dimensional (3D) point data. The scientific goal driving the tool's development is to determine the presence of filaments and voids as defined by inferred 3D galaxy positions within the Horologium-Reticulum supercluster (HRS). GyVe provides visualization techniques tailored to examine structures defined by the intercluster galaxies. Specific techniques include: interactive user control to move between a global overview and local viewpoints, labelled axes and curved drop lines to indicate positions in the astronomical RA-DEC-cz coordinate system, torsional rocking and stereo to enhance 3D perception, and geometrically distinct glyphs to show potential correlation between intercluster galaxies and known clusters. We discuss the rationale for each design decision and review the success of the techniques in accomplishing the scientific goals. In practice, GyVe has been useful for gaining intuition about structures that were difficult to perceive with 2D projection techniques alone. For example, during their initial session with GyVe, our collaborators quickly confirmed scientific conclusions regarding the large-scale structure of the HRS previously obtained over months of study with 2D projections and statistical techniques. Further use of GyVe revealed the spherical shape of voids and showed that a presumed filament was actually two disconnected structures.},
author = {Miller, Jameson and Quammen, Cory W. and Fleenor, Matthew C.},
doi = {10.1109/TVCG.2006.155},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Miller, Quammen, Fleenor - 2006 - Interactive visualization of intercluster galaxy structures in the horologium-reticulum supercluster.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Astronomy,Cosmology,Sparse point visualization},
number = {5},
pages = {1149--1155},
pmid = {17080846},
title = {{Interactive visualization of intercluster galaxy structures in the horologium-reticulum supercluster}},
volume = {12},
year = {2006}
}
@inproceedings{Yang2004,
address = {New York, New York, USA},
author = {Yang, Kiyoung and Shahabi, Cyrus},
booktitle = {Proceedings of the 2nd ACM international workshop on Multimedia databases  - MMDB '04},
doi = {10.1145/1032604.1032616},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Yang, Shahabi - 2004 - A PCA-based similarity measure for multivariate time series.pdf:pdf},
isbn = {1581139756},
pages = {65--74},
publisher = {ACM Press},
title = {{A PCA-based similarity measure for multivariate time series}},
url = {http://portal.acm.org/citation.cfm?doid=1032604.1032616},
year = {2004}
}
@article{Rafiei1997,
author = {Rafiei, Davood and Mendelzon, Alberto and Rafiei, Davood and Mendelzon, Alberto},
doi = {10.1145/253262.253264},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Rafiei et al. - 1997 - Similarity-based queries for time series data.pdf:pdf},
isbn = {0-89791-911-4},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = {jun},
number = {2},
pages = {13--25},
publisher = {ACM},
title = {{Similarity-based queries for time series data}},
url = {http://portal.acm.org/citation.cfm?doid=253262.253264},
volume = {26},
year = {1997}
}
@inproceedings{Popivanov2002,
author = {Popivanov, I. and Miller, R.J.},
booktitle = {Proceedings 18th International Conference on Data Engineering},
doi = {10.1109/ICDE.2002.994711},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Popivanov, Miller - 2002 - Similarity search over time-series data using wavelets.pdf:pdf},
isbn = {0-7695-1531-2},
pages = {212--221},
publisher = {IEEE Comput. Soc},
title = {{Similarity search over time-series data using wavelets}},
url = {http://ieeexplore.ieee.org/document/994711/},
year = {2002}
}
@inproceedings{Almryde2016,
annote = {dark matter halo merger treeã¨ããã®evolutionãæç©ºéæ¹åã«å¯è¦åãããå¯¾è©±çã«è§£æã§ããã¦ã§ããã¼ã«
ãããããªweb analysis operationsãã¤ãã¦ãï¼ãµãæ§é ãè¦ããã¨ãï¼},
author = {Almryde, Kyle R. and Forbes, Angus G.},
booktitle = {Proceedings of 2015 IEEE Scientific Visualization Conference},
doi = {10.1109/SciVis.2015.7429495},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Almryde, Forbes - 2016 - Halos in a dark sky Interactively exploring the structure of dark matter halo merger trees.pdf:pdf},
isbn = {9781467397858},
pages = {73--77},
title = {{Halos in a dark sky: Interactively exploring the structure of dark matter halo merger trees}},
year = {2016}
}
@article{Luciani2014,
abstract = {We introduce a web-based computing infrastructure to assist the visual integration, mining and interactive navigation of large-scale astronomy observations. Following an analysis of the application domain, we design a client-server architecture to fetch distributed image data and to partition local data into a spatial index structure that allows prefix-matching of spatial objects. In conjunction with hardware-accelerated pixel-based overlays and an online cross-registration pipeline, this approach allows the fetching, displaying, panning and zooming of gigabit panoramas of the sky in real time. To further facilitate the integration and mining of spatial and non-spatial data, we introduce interactive trend images{\&}{\#}x2014;compact visual representations for identifying outlier objects and for studying trends within large collections of spatial objects of a given class. In a demonstration, images from three sky surveys (SDSS, FIRST and simulated LSST results) are cross-registered and integrated as overlays, allowing cross-spectrum analysis of astronomy observations. Trend images are interactively generated from catalog data and used to visually mine astronomy observations of similar type. The front-end of the infrastructure uses the web technologies WebGL and HTML5 to enable cross-platform, webbased functionality. Our approach attains interactive rendering framerates; its power and flexibility enables it to serve the needs of the astronomy community. Evaluation on three case studies, as well as feedback from domain experts emphasize the benefits of this visual approach to the observational astronomy field; and its potential benefits to large scale geospatial visualization in general.},
annote = {æè¡ã®é²æ­©ã§ãè£å®çã«å¤§éã®ãã¼ã¿ãå¾ãããããã«ãªã£ããã©ãå¤©æå­¦èããããããã¼ã¿ãimageãæ±ãã¦è¤æ°ã®ãµã¼ãã¤ãèª¿ã¹ãããåä¸å¤©ä½ã«é¢ããè£å®ãããimageãcross-correlateãããããã¨ããã®ã¯ã²ãããã«ç¡é§ãå¤ãã¦éå±
ææ¡ææ³ï¼largescale, distributed, multi-layerãªå°çç©ºéçãªãã¼ã¿ã®å¯¾è©±çãªnavigationã¨miningã®ããã®ã¦ã§ããã¼ã¹ã®è¦è¦çãªã¤ã³ãã©ãææ¡},
author = {Luciani, Timothy Basil and Cherinka, Brian and Oliphant, Daniel and Myers, Sean and Wood-Vasey, W. Michael and Labrinidis, Alexandros and Marai, G. Elisabeta},
doi = {10.1109/TVCG.2014.2312008},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Luciani et al. - 2014 - Large-scale overlays and trends visually mining, panning and zooming the observable universe(2).pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data fusion and integration,geographic/geospatial visualization,scalability issues},
number = {7},
pages = {1048--1061},
title = {{Large-scale overlays and trends: visually mining, panning and zooming the observable universe}},
volume = {20},
year = {2014}
}
@article{VanHam2009,
abstract = {A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas' original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.},
author = {{Van Ham}, Frank and Perer, Adam},
doi = {10.1109/TVCG.2009.108},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Van Ham, Perer - 2009 - Search, show context, expand on demand Supporting large graph exploration with degree-of-interest.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Graph visualization,degree of interest,focus+context,legal citation networks,network visualization},
number = {6},
pages = {953--960},
pmid = {19834159},
title = {{"Search, show context, expand on demand": Supporting large graph exploration with degree-of-interest}},
volume = {15},
year = {2009}
}
@inproceedings{Hanula2016,
abstract = {We present the design and implementation of an immersive visual mining and analysis tool for cosmological data. The tool consists of an immersive linked multiview display which allows domain experts to interact with visual representations of spatial and nonspatial cosmology data. Nonspatial data is represented as time-aligned merger trees, and through a pixel-based heatmap. Spatial data is represented through GPU-accelerated point clouds and geometric primitives. The user can select a halo and visualize a 3D representation of the raw particles, as well as of the halos at the particular time stamp. We have demonstrated the tool to a senior staff member of the Adler Planetarium and report their feedback. The tool can assist researchers in the interaction navigation and mining of large scale cosmological simulation data.},
annote = {å¤©ä½ç¾è±¡ã®ã·ãã¥ã¬ã¼ã·ã§ã³ãã¼ã¿ã¯ãã®ãããè¦æ¨¡ãå¤§ãããã¨ãå¤ãã
ãã®ææ³ã¯ãdark matter particleã¨haloã®å¤§è¦æ¨¡ã§å¤å¤©ä½ã®ã·ãã¥ã¬ã¼ã·ã§ã³ã®å¯è¦åã«é¢ããæ°ããã¢ãã­ã¼ããè¤æ°ã®ãã£ã¹ãã¬ã¤ãç¹ãã¦ãæ²¡å¥çãªè§£æç°å¢ãå®ç¾},
author = {Hanula, Peter and Piekutowski, Kamil and Uribe, Carlos and Almryde, Kyle and Nishimoto, Arthur and Aguilera, Julieta and Marai, G. Elisabeta},
booktitle = {Proceedings of 2015 IEEE Scientific Visualization Conference},
doi = {10.1109/SciVis.2015.7429497},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Hanula et al. - 2016 - Cavern Halos Exploring spatial and nonspatial cosmological data in an immersive virtual environment.pdf:pdf},
isbn = {9781467397858},
pages = {87--99},
title = {{Cavern Halos: Exploring spatial and nonspatial cosmological data in an immersive virtual environment}},
year = {2016}
}
@article{Mirzargar2014,
abstract = {In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.},
author = {Mirzargar, Mahsa and Whitaker, Ross T. and Kirby, Robert M.},
doi = {10.1109/TVCG.2014.2346455},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Mirzargar, Whitaker, Kirby - 2014 - Curve Boxplot Generalization of boxplot for ensembles of curves.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {dec},
number = {12},
pages = {2654--2663},
title = {{Curve Boxplot: Generalization of boxplot for ensembles of curves}},
url = {http://ieeexplore.ieee.org/document/6875964/},
volume = {20},
year = {2014}
}
@article{Whitaker2013,
abstract = {Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.},
author = {Whitaker, Ross T and Member, Senior and Mirzargar, Mahsa and Kirby, Robert M},
doi = {10.1109/TVCG.2013.143},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Whitaker et al. - 2013 - Contour Boxplots A method for characterizing uncertainty in feature sets from simulation ensembles.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {12},
pages = {2713--2722},
title = {{Contour Boxplots: A method for characterizing uncertainty in feature sets from simulation ensembles}},
volume = {19},
year = {2013}
}
@article{Forbes2017,
abstract = {We introduce the Dynamic Influence Network (DIN), a novel visual analytics technique for representing and analyzing rule-based models of protein-protein interaction networks. Rule-based modeling has proved instrumental in developing biological models that are concise, comprehensible, easily extensible, and that mitigate the combinatorial complexity of multi-state and multi-component biological molecules. Our technique visualizes the dynamics of these rules as they evolve over time. Using the data produced by KaSim, an open source stochastic simulator of rule-based models written in the Kappa language, DINs provide a node-link diagram that represents the influence that each rule has on the other rules. That is, rather than representing individual biological components or types, we instead represent the rules about them (as nodes) and the current influence of these rules (as links). Using our interactive DIN-Viz software tool, researchers are able to query this dynamic network to find meaningful patterns about biological processes, and to identify salient aspects of complex rule-based models. To evaluate the effectiveness of our approach, we investigate a simulation of a circadian clock model that illustrates the oscillatory behavior of the KaiC protein phosphorylation cycle.},
author = {Forbes, Angus G. and Burks, Andrew and Lee, Kristine and Li, Xing and Boutillier, Pierre and Krivine, Jean and Fontana, Walter},
doi = {10.1109/TVCG.2017.2745280},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Forbes et al. - 2017 - Dynamic influence networks for rule-based models(2).pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {jan},
number = {1},
pages = {184--194},
title = {{Dynamic influence networks for rule-based models}},
url = {http://arxiv.org/abs/1711.00967 http://ieeexplore.ieee.org/document/8017593/},
volume = {24},
year = {2017}
}
@article{Kent2017a,
author = {Kent, Brian R.},
doi = {10.1088/1538-3873/aa5fa6},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Kent - 2017 - Editorial Techniques and methods for astrophysical data visualization.pdf:pdf},
journal = {Publications of the Astronomical Society of the Pacific},
month = {may},
number = {975},
pages = {058001:1},
publisher = {IOP Publishing},
title = {{Editorial: Techniques and methods for astrophysical data visualization}},
url = {http://stacks.iop.org/1538-3873/129/i=975/a=058001?key=crossref.8be11c9ad8a770af608c7ec6b25aa9e1},
volume = {129},
year = {2017}
}
@article{Goodman2012,
abstract = {Astronomical researchers often think of analysis and visualization as separate tasks. In the case of high-dimensional data sets, though, interactive exploratory data visualization can give far more insight than an approach where data processing and statistical analysis are followed, rather than accompanied, by visualization. This paper attempts to charts a course toward "linked view" systems, where multiple views of high-dimensional data sets update live as a researcher selects, highlights, or otherwise manipulates, one of several open views. For example, imagine a researcher looking at a 3D volume visualization of simulated or observed data, and simultaneously viewing statistical displays of the data set's properties (such as an x-y plot of temperature vs. velocity, or a histogram of vorticities). Then, imagine that when the researcher selects an interesting group of points in any one of these displays, that the same points become a highlighted subset in all other open displays. Selections can be graphical or algorithmic, and they can be combined, and saved. For tabular (ASCII) data, this kind of analysis has long been possible, even though it has been under-used in Astronomy. The bigger issue for Astronomy and several other "high-dimensional" fields is the need systems that allow full integration of images and data cubes within a linked-view environment. The paper concludes its history and analysis of the present situation with suggestions that look toward cooperatively-developed open-source modular software as a way to create an evolving, flexible, high-dimensional, linked-view visualization environment useful in astrophysical research.},
archivePrefix = {arXiv},
arxivId = {1205.4747},
author = {Goodman, Alyssa A.},
doi = {10.1002/asna.201211705},
eprint = {1205.4747},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Goodman - 2012 - Principles of High-Dimensional Data Visualization in Astronomy.pdf:pdf},
month = {may},
title = {{Principles of high-dimensional data visualization in astronomy}},
url = {http://arxiv.org/abs/1205.4747 http://dx.doi.org/10.1002/asna.201211705},
year = {2012}
}
@inproceedings{Zhou2015,
author = {Zhou, Pei-Yuan and Chan, Keith C. C.},
booktitle = {Proceedings of Pacific-Asia Conference on Knowledge Discovery and Data Mining},
doi = {10.1007/978-3-319-18032-8_32},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Zhou, Chan - 2015 - A feature extraction method for multivariate time series classification using temporal patterns.pdf:pdf},
pages = {409--421},
publisher = {Springer, Cham},
title = {{A feature extraction method for multivariate time series classification using temporal patterns}},
url = {http://link.springer.com/10.1007/978-3-319-18032-8{\_}32},
year = {2015}
}
@inproceedings{Agrawal1993,
author = {Agrawal, Rakesh and Faloutsos, Christos and Swami, Arun},
booktitle = {Proceedings of the 4th International Conference on Foundations of Data Organization and Algorithms},
doi = {10.1007/3-540-57301-1_5},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Agrawal, Faloutsos, Swami - 1993 - Efficient similarity search in sequence databases.pdf:pdf},
pages = {69--84},
publisher = {Springer, Berlin, Heidelberg},
title = {{Efficient similarity search in sequence databases}},
url = {http://link.springer.com/10.1007/3-540-57301-1{\_}5},
year = {1993}
}
@inproceedings{Faloutsos1994,
address = {New York, USA},
author = {Faloutsos, Christos and Ranganathan, M. and Manolopoulos, Yannis and Faloutsos, Christos and Ranganathan, M. and Manolopoulos, Yannis},
booktitle = {Proceedings of the 1994 ACM SIGMOD International Conference on Management of Data},
doi = {10.1145/191839.191925},
file = {:Users/nsawada/Google Drive/Papers/Fast subsequence matching in time-series databases.pdf:pdf},
isbn = {0897916395},
number = {2},
pages = {419--429},
publisher = {ACM Press},
title = {{Fast subsequence matching in time-series databases}},
url = {http://portal.acm.org/citation.cfm?doid=191839.191925},
volume = {23},
year = {1994}
}
@inproceedings{Rafiei1999,
author = {Rafiei, D.},
booktitle = {Proceedings of 15th International Conference on Data Engineering},
doi = {10.1109/ICDE.1999.754957},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Rafiei - 1999 - On similarity-based queries for time series data.pdf:pdf},
isbn = {0-7695-0071-4},
pages = {410--417},
publisher = {IEEE},
title = {{On similarity-based queries for time series data}},
url = {http://ieeexplore.ieee.org/document/754957/},
year = {1999}
}
@inproceedings{Goldin1995,
address = {Berlin, Heidelberg},
author = {Goldin, Dina Q. and Kanellakis, Paris C.},
booktitle = {Proceedings of International Conference on Principles and Practice of Constraint Programming},
doi = {10.1007/3-540-60299-2_9},
editor = {Montanari, Ugo and Rossi, Francesca},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Goldin, Kanellakis - 1995 - On similarity queries for time-series data Constraint specification and implementation.pdf:pdf},
pages = {137--153},
publisher = {Springer, Berlin, Heidelberg},
title = {{On similarity queries for time-series data: Constraint specification and implementation}},
url = {http://link.springer.com/10.1007/3-540-60299-2{\_}9},
year = {1995}
}
@inproceedings{Byoung-KeeYi1998,
author = {{Byoung-Kee Yi} and Jagadish, H.V. and Faloutsos, C.},
booktitle = {Proceedings 14th International Conference on Data Engineering},
doi = {10.1109/ICDE.1998.655778},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Byoung-Kee Yi, Jagadish, Faloutsos - 1998 - Efficient retrieval of similar time sequences under time warping.pdf:pdf},
isbn = {0-8186-8289-2},
pages = {201--208},
publisher = {IEEE Comput. Soc},
title = {{Efficient retrieval of similar time sequences under time warping}},
url = {http://ieeexplore.ieee.org/document/655778/},
year = {1998}
}
@article{Ravikumar2014,
abstract = {Classification is one of the most popular techniques in the data mining area. In supervised learning, a new pattern is assigned a class label based on a training set whose class labels are already known. This paper proposes a novel classification algorithm for time series data. In our algorithm, we use four parameters and based on their significance on different benchmark datasets, we have assigned the weights using simulated annealing process. We have taken the combination of these parameters as a performance metric to find the accuracy and time complexity. We have experimented with 6 benchmark datasets and results shows that our novel algorithm is computationally fast and accurate in several cases when compared with 1NN classifier.},
author = {Ravikumar, Penugonda and Devi, V. Susheela},
doi = {10.1109/CIDM.2014.7008671},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Ravikumar, Devi - 2014 - Weighted feature-based classification of time series data.pdf:pdf},
isbn = {978-1-4799-4518-4},
journal = {Proceedings of 2014 IEEE Symposium on Computational Intelligence and Data Mining},
keywords = {computational complexity,data analysis,data mining},
pages = {536--545},
title = {{Weighted feature-based classification of time series data}},
url = {http://ieeexplore.ieee.org/document/7008671/},
year = {2014}
}
@inproceedings{Seshadri1994,
address = {New York, USA},
author = {Seshadri, Praveen and Livny, Miron and Ramakrishnan, Raghu},
booktitle = {Proceedings of the 1994 ACM SIGMOD international conference on Management of data},
doi = {10.1145/191839.191926},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Seshadri, Livny, Ramakrishnan - 1994 - Sequence query processing.pdf:pdf},
isbn = {0897916395},
number = {2},
pages = {430--441},
publisher = {ACM Press},
title = {{Sequence query processing}},
url = {http://portal.acm.org/citation.cfm?doid=191839.191926},
volume = {23},
year = {1994}
}
@article{Sasada2012,
abstract = {In 2009 December, the bright blazar 3C 454.3 exhibited a strong outburst in the optical, X-ray, and gamma-ray regions. We performed photometric and polarimetric monitoring of this outburst in the optical and near-infrared bands with TRISPEC and HOWPol attached to the Kanata telescope. We also observed this outburst in the infrared band with AKARI, and the radio band with the 32-m radio telescope of Yamaguchi University. The object was in an active state from JD 2455055 to 2455159. It was 1.3 mag brighter than its quiescent state before JD 2455055 in the optical band. After the end of the active state in JD 2455159, a prominent outburst was observed in all wave-lengths. The outburst continued for two months. Our optical and near-infrared polarimetric observations revealed that the position angle of the polarization (PA) apparently rotated clockwise by 240 Ä± within 11 d in the active state (JD 2455063â2455074); after this rotation, PA remained almost constant during our monitoring. In the outburst state, PA smoothly rotated counterclockwise by 350 Ä± within 35 d (JD 2455157â2455192). Thus, we detected two distinct rotation events of polarization vectors in opposite directions. We discuss these two events compared with the past rotation events observed in 2005, 2007, and 2008.},
author = {Sasada, Mahito and Uemura, Makoto and Fukazawa, Yasushi and Kawabata, Koji S and Itoh, Ryosuke and Sakon, Itsuki and Fujisawa, Kenta and Kadota, Akiko and Ohsugi, Takashi and Yoshida, Michitoshi and Yasuda, Hajimu and Yamanaka, Masayuki and Sato, Shuji and Kino, Masaru},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Sasada et al. - 2012 - Multi-wavelength photometric and polarimetric observations of the outburst of 3C 454.3 in 2009 December.pdf:pdf},
journal = { Publications of the Astronomical Society of Japan},
number = {3},
pages = {58:1--58:8},
title = {{Multi-wavelength photometric and polarimetric observations of the outburst of 3C 454.3 in 2009 December}},
volume = {64},
year = {2012}
}
@article{Rosner1983,
abstract = {A generalized (extreme Studentized deviate) ESD many-outlier procedure is given for detecting from 1 to k outliers in a data set. This procedure has an advantage over the original ESD many-outlier procedure (Rosner 1975) in that it controls the type I error both under the hypothesis of no outliers and under the alternative hypotheses of 1, 2,..., k-1 outliers. A method is given for approximating percentiles for this procedure based on the t distribution. This method is shown to be adequately accurate using Monte Carlo simulation, for detecting up to 10 outliers in samples as small as 25. Tables are given for implementing this method for n = 25(1)50(10)100(50)500; k = 10, $\alpha$ = .05, .01, .005.},
author = {Rosner, Bernard},
doi = {10.2307/1268549},
journal = {Technometrics},
month = {may},
number = {2},
pages = {165--172},
publisher = {Taylor {\&} Francis, Ltd.American Statistical AssociationAmerican Society for Quality},
title = {{Percentage points for a generalized ESD many-outlier procedure}},
url = {http://www.jstor.org/stable/1268549?origin=crossref},
volume = {25},
year = {1983}
}
@article{Xing2010,
author = {Xing, Zhengzheng and Pei, Jian and Keogh, Eamonn},
doi = {10.1145/1882471.1882478},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Xing, Pei, Keogh - 2010 - A brief survey on sequence classification.pdf:pdf},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
month = {nov},
number = {1},
pages = {40},
publisher = {ACM},
title = {{A brief survey on sequence classification}},
url = {http://portal.acm.org/citation.cfm?doid=1882471.1882478},
volume = {12},
year = {2010}
}
@inproceedings{Ye2009,
address = {New York, New York, USA},
author = {Ye, Lexiang and Keogh, Eamonn},
booktitle = {Proceedings of the 15th International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/1557019.1557122},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Ye, Keogh - 2009 - Time series shapelets A new primitive for data mining.pdf:pdf},
isbn = {9781605584959},
pages = {947--956},
publisher = {ACM Press},
title = {{Time series shapelets: A new primitive for data mining}},
url = {http://portal.acm.org/citation.cfm?doid=1557019.1557122},
year = {2009}
}
@inproceedings{Li1999,
author = {Li, Cen and Biswas, Gautam},
booktitle = {Advances in Intelligent Data Analysis},
doi = {10.1007/3-540-48412-4_21},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Li, Biswas - 1999 - Temporal pattern generation using hidden Markov model based unsupervised classification.pdf:pdf},
pages = {245--256},
publisher = {Springer, Berlin, Heidelberg},
title = {{Temporal pattern generation using hidden Markov model based unsupervised classification}},
url = {http://link.springer.com/10.1007/3-540-48412-4{\_}21},
year = {1999}
}
@article{Laxman2006,
author = {Laxman, Srivatsan and Sastry, P. S.},
doi = {10.1007/BF02719780},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Laxman, Sastry - 2006 - A survey of temporal data mining.pdf:pdf},
journal = {Sadhana},
month = {apr},
number = {2},
pages = {173--198},
publisher = {Springer India},
title = {{A survey of temporal data mining}},
url = {http://link.springer.com/10.1007/BF02719780},
volume = {31},
year = {2006}
}
@article{Socas-Navarro2005,
abstract = {This paper introduces a novel feature extraction technique for the analysis of spectral line Stokes profiles. The procedure is based on the use of an auto-associative artificial neural network containing non-linear hidden layers. The neural network extracts a small subset of parameters from the profiles (features), from which it is then able to reconstruct the original profile. This new approach is compared to two other procedures that have been proposed in previous works, namely principal component analysis and Hermitian function expansions. Depending on the target application, each one of these three techniques has some advantages and disadvantages, which are discussed here.},
archivePrefix = {arXiv},
arxivId = {astro-ph/0410565},
author = {Socas-Navarro, H.},
doi = {10.1086/426811},
eprint = {0410565},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Socas-Navarro - 2005 - Feature extraction techniques for the analysis of spectral polarization profiles.pdf:pdf},
journal = {The Astrophysical Journal},
number = {1},
pages = {517--522},
primaryClass = {astro-ph},
title = {{Feature extraction techniques for the analysis of spectral polarization profiles}},
url = {http://arxiv.org/abs/astro-ph/0410565},
volume = {620},
year = {2005}
}
@inproceedings{Li2010,
author = {Li, Xiaojie and Li, Xiang and Tang, Daimin and Xu, Xianrui},
booktitle = {Proceedings of 2010 18th International Conference on Geoinformatics},
doi = {10.1109/GEOINFORMATICS.2010.5567483},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2010 - Deriving features of traffic flow around an intersection from trajectories of vehicles.pdf:pdf},
isbn = {2161-024X},
pages = {1--5},
publisher = {IEEE},
title = {{Deriving features of traffic flow around an intersection from trajectories of vehicles}},
url = {http://ieeexplore.ieee.org/document/5567483/},
year = {2010}
}
@inproceedings{VanGoethem2016,
abstract = {We present algorithms and data structures that support the interactive analysis of the grouping structure of one-, two-, or higher-dimensional time-varying data while varying all defining parameters. Grouping structures characterise important patterns in the temporal evaluation of sets of time-varying data. We follow Buchin et al. [JoCG 2015] who define groups using three parameters: group-size, group-duration, and inter-entity distance. We give upper and lower bounds on the number of maximal groups over all parameter values, and show how to compute them efficiently. Furthermore, we describe data structures that can report changes in the set of maximal groups in an output-sensitive manner. Our results hold in {\$}\backslashmathbb{\{}R{\}}{\^{}}d{\$} for fixed {\$}d{\$}.},
archivePrefix = {arXiv},
arxivId = {1603.06252},
author = {van Goethem, Arthur and van Kreveld, Marc and L{\"{o}}ffler, Maarten and Speckmann, Bettina and Staals, Frank},
booktitle = {Proceedings of 32nd International Symposium on Computational Geometry},
doi = {10.4230/LIPIcs.SoCG.2016.61},
eprint = {1603.06252},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/van Goethem et al. - 2016 - Grouping time-varying data for interactive exploration(2).pdf:pdf},
isbn = {9783959770095},
issn = {18688969},
number = {61},
pages = {1--16},
title = {{Grouping time-varying data for interactive exploration}},
url = {http://arxiv.org/abs/1603.06252},
year = {2016}
}
@incollection{Nanopoulos2001,
address = {Commack, NY, USA},
annote = {multi-layer perception (MLP) neural networkãä½¿ã£ã¦åé¡
ã¯ã©ã¹ã¿ãªã³ã°ï¼ãã¼ã¿ãåé¡ããã¿ã¤ããç¹å®
classificationï¼æ¢ç¥ã®ã¿ã¤ãã«ãã¼ã¿ãããã

éè¦ãªãã¿ã¼ã³ï¼é¡ä¼¼åº¦ãå¾åãå¨ææ§},
author = {Nanopoulos, Alex and Alcock, Rob and Manolopoulos, Yannis},
booktitle = {Information Processing and Technology},
chapter = {Feature-ba},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Nanopoulos, Alcock, Manolopoulos - 2001 - Feature-based classifcation of time-series data.pdf:pdf},
isbn = {1-59033-116-8},
pages = {49--61},
publisher = {Nova Science Publishers, Inc.},
title = {{Feature-based classifcation of time-series data}},
url = {http://dl.acm.org/citation.cfm?id=766914.766918},
year = {2001}
}
@article{Steffen2011,
abstract = {We present a flexible interactive 3D morpho-kinematical modeling application for astrophysics. Compared to other systems, our application reduces the restrictions on the physical assumptions, data type, and amount that is required for a reconstruction of an object's morphology. It is one of the first publicly available tools to apply interactive graphics to astrophysical modeling. The tool allows astrophysicists to provide a priori knowledge about the object by interactively defining 3D structural elements. By direct comparison of model prediction with observational data, model parameters can then be automatically optimized to fit the observation. The tool has already been successfully used in a number of astrophysical research projects.},
annote = {From Duplicate 2 (Shape: A 3D modeling tool for astrophysics - Steffen, Wolfgang; Koning, Nicholas; Wenger, Stephan; Morisset, Christophe; Magnor, Marcus)

a novel 3D application for the modeling and reconstruction of astrophysical objects that incorporates interactive modeling tools},
archivePrefix = {arXiv},
arxivId = {1003.2012},
author = {Steffen, Wolfgang and Koning, Nicholas and Wenger, Stephan and Morisset, Christophe and Magnor, Marcus},
doi = {10.1109/TVCG.2010.62},
eprint = {1003.2012},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Steffen et al. - 2011 - Shape A 3D modeling tool for astrophysics.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Modeling packages,astronomy,physics,scene analysis},
month = {apr},
number = {4},
pages = {454--465},
pmid = {20421682},
title = {{Shape: A 3D modeling tool for astrophysics}},
url = {http://ieeexplore.ieee.org/document/5453364/},
volume = {17},
year = {2011}
}
@article{WarrenLiao2005,
abstract = {Time series clustering has been shown effective in providing useful information in various domains. There seems to be an increased interest in time series clustering as part of the effort in temporal data mining research. To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of time series data in various application domains. The basics of time series clustering are presented, including general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time series being compared, either in the forms of raw data, extracted features, or some model parameters. The past researchs are organized into three groups depending upon whether they work directly with the raw data either in the time or frequency domain, indirectly with features extracted from the raw data, or indirectly with models built from the raw data. The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified. Moreover, the areas that time series clustering have been applied to are also summarized, including the sources of data used. It is hoped that this review will serve as the steppingstone for those interested in advancing this area of research. {\textcopyright} 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {{Warren Liao}, T.},
doi = {10.1016/j.patcog.2005.01.025},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Warren Liao - 2005 - Clustering of time series data-a survey.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Clustering,Data mining,Distance measure,Time series data},
number = {11},
pages = {1857--1874},
pmid = {18557655},
title = {{Clustering of time series data-a survey}},
volume = {38},
year = {2005}
}
@phdthesis{Olszewski2001,
abstract = {Pattern recognition encompasses two fundamental tasks: description and classification. Given an object to analyze, a pattern recognition system first generates a description of it (i.e., the pattern) and then classifies the object based on that description (i.e., the recognition). Two general approaches for implementing pattern recognition systems, statistical and structural, employ different techniques for description and classification. Statistical approaches to pattern recognition use decision-theoretic concepts to discriminate among objects belonging to different groups based upon their quantitative features. Structural approaches to pattern recognition use syntactic grammars to discriminate among objects belonging to different groups based upon the arrangement of their morphological features. Hybrid approaches to pattern recognition combine aspects of both statistical and structural pattern recognition. Structural pattern recognition systems are difficult to apply to new domains because implementation of both the description and classification tasks requires domain knowledge. Knowledge acquisition techniques necessary to obtain domain knowledge from experts are tedious and often fail to produce a complete and accurate knowledge base. Consequently, applications of structural pattern recognition have been primarily restricted to domains in which the set of useful morphological features has been established in the literature and the syntactic grammars can be composed by hand (e.g., electrocardiogram diagnosis). To overcome this limitation, a domain-independent approach to structural pattern recognition is needed that is capable of extracting morphological features and performing classification without relying on domain knowledge. This thesis presents a suite of structure detectors that effectively performs generalized feature extraction for structural pattern recognition in time-series data.},
author = {Olszewski, Robert Thomas},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Olszewski - 2001 - Generalized feature extraction for structural pattern recognition in time-series data.pdf:pdf},
school = {Carnegie Mellon University},
title = {{Generalized feature extraction for structural pattern recognition in time-series data}},
url = {http://www.dtic.mil/docs/citations/ADA457624},
year = {2001}
}
@inproceedings{Cedilnik2000,
author = {Cedilnik, Andrej and Rheingans, Penny},
booktitle = {Proceedings Visualization 2000},
pages = {77--84},
title = {{Procedural annotation of uncertain information}},
year = {2000}
}
@inproceedings{Hullman2016,
abstract = {Evaluating a visualization that depicts uncertainty is fraught with challenges due to the complex psychology of uncer-tainty. However, relatively little attention is paid to se-lecting and motivating a chosen interpretation or elicitation method for subjective probabilities in the uncertainty visual-ization literature. I survey existing evaluation work in uncer-tainty visualization, and examine how research in judgment and decision-making that focuses on subjective uncertainty elicitation sheds light on common approaches in visualiza-tion. I propose suggestions for practice aimed at reducing errors and noise related to how ground truth is defined for subjective probability estimates, the choice of an elicitation method, and the strategies used by subjects making judg-ments with an uncertainty visualization.},
author = {Hullman, Jessica},
booktitle = {Proceedings of the Beyond Time and Errors on Novel Evaluation Methods for Visualization},
doi = {10.1145/2993901.2993919},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Hullman - 2016 - Why evaluating uncertainty visualization is error prone.pdf:pdf},
isbn = {9781450348188},
keywords = {subjective probability distribution,uncertainty visualization},
pages = {143--151},
title = {{Why evaluating uncertainty visualization is error prone}},
url = {http://dl.acm.org/citation.cfm?doid=2993901.2993919},
year = {2016}
}
@article{Yeates2013,
abstract = {We propose a phenomenological technique for modelling the emergence of active regions within a three-dimensional, kinematic dynamo framework. By imposing localised velocity perturbations, we create emergent flux-tubes out of toroidal magnetic field at the base of the convection zone, leading to the eruption of active regions at the solar surface. The velocity perturbations are calibrated to reproduce observed active region properties (including the size and flux of active regions, and the distribution of tilt angle with latitude), resulting in a more consistent treatment of flux-tube emergence in kinematic dynamo models than artificial flux deposition. We demonstrate how this technique can be used to assimilate observations and drive a kinematic 3D model, and use it to study the characteristics of active region emergence and decay as a source of poloidal field. We find that the poloidal components are strongest not at the solar surface, but in the middle convection zone, in contrast with the common assumption that the poloidal source is located near the solar surface. We also find that, while most of the energy is contained in the lower convection zone, there is a good correlation between the evolution of the surface and interior magnetic fields.},
archivePrefix = {arXiv},
arxivId = {1309.6342},
author = {Yeates, A. R. and Mu{\~{n}}oz-Jaramillo, A.},
doi = {10.1093/mnras/stt1818},
eprint = {1309.6342},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Yeates, Mu{\~{n}}oz-Jaramillo - 2013 - Kinematic active region formation in a three-dimensional solar dynamo model.pdf:pdf},
issn = {00358711},
journal = {Monthly Notices of the Royal Astronomical Society},
keywords = {Sun:Photosphere,Sun:interior,Sun:magnetic fields,Sunspots},
number = {4},
pages = {3366--3379},
title = {{Kinematic active region formation in a three-dimensional solar dynamo model}},
volume = {436},
year = {2013}
}
@incollection{Deitrick2006,
author = {Deitrick, Stephanie and Edsall, Robert},
booktitle = {Progress in Spatial Data Handling},
doi = {10.1007/3-540-35589-8_45},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Deitrick, Edsall - 2006 - The influence of uncertainty visualization on decision making An empirical evaluation.pdf:pdf},
pages = {719--738},
publisher = {Springer Berlin Heidelberg},
title = {{The influence of uncertainty visualization on decision making: An empirical evaluation}},
url = {http://link.springer.com/10.1007/3-540-35589-8{\_}45},
year = {2006}
}
@inproceedings{Zuk2006,
author = {Zuk, Torre and Carpendale, Sheelagh},
booktitle = {Proceedings of SPIE},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Zuk, Carpendale - 2006 - Theoretical analysis of uncertainty visualizations.pdf:pdf},
keywords = {evaluation,framework,information visualization,perception,uncertainty,visualization},
pages = {66--79},
title = {{Theoretical analysis of uncertainty visualizations}},
year = {2006}
}
@article{Lodha1996,
abstract = {Integrated presentation of data with uncertainty is a worthy goal in scientific visualization. It allows researchers to make informed decisions based on imperfect data. It also allows users to visually compare and contrast different algorithms for performing the same task or different models for representing the same physical phe- nomenon. This work presents LISTEN â a data sonification system â that has been incorporated into two visualization systems: a sys- tem for visualizing geometric uncertainty of surface interpolants and a system for visualizing uncertainty in fluid flow. LISTEN is written in C++ for the SGI platform. It works with the SGI internal audio chip or aMIDI device or both. LISTEN is an object-oriented systemthat ismodular, flexible, adaptable, portable, interactive and extensible. We demonstrate that sonification is very effective as an additional tool in visualizing geometric and fluid flowuncertainty},
author = {Lodha, Suresh K. and Wilson, C.M. and Sheehan, R.E.},
doi = {10.1109/VISUAL.1996.568105},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Lodha, Wilson, Sheehan - 1996 - LISTEN Sounding uncertainty visualization.pdf:pdf},
isbn = {0-89791-864-9},
journal = {Proceedings of Seventh Annual IEEE Visualization '96},
keywords = {and phrases,flow,geometry,interactive,interpola-,midi,modular,portable,sonification,tion,uncertainty,visualiza-},
pages = {189--195},
title = {{LISTEN: Sounding uncertainty visualization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=568105},
year = {1996}
}
@article{Rousseeuw1999,
abstract = {Abstract We propose the bagplot, a bivariate generalization of the$\backslash$nunivariate boxplot. The key notion is the half space location depth$\backslash$nof a point relative to a bivariate dataset, which extends the univariate$\backslash$nconcept of rank. The depth median is the deepest location, and it$\backslash$nis surrounded by a bag containing the n/2 observations with largest$\backslash$ndepth. Magnifying the bag by a factor 3 yields the fence (which is$\backslash$nnot plotted). Observations between the bag and the fence are marked$\backslash$nby a light gray loop, whereas observations outside the fence are$\backslash$nflagged as outliers. The bagplot visualizes the location, spread,$\backslash$ncorrelation, skewness, and tails of the data. It is equivariant for$\backslash$nlinear transformations, and not limited to elliptical distributions.$\backslash$nSoftware for drawing the bagplot is made available for the S-Plus$\backslash$nand MATLAB environments. The bagplot is illustrated on several datasets$\backslash$nfor example, in a scatterplot matrix of multivariate data.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rousseeuw, Peter J. and Ruts, Ida and Tukey, John W.},
doi = {10.1080/00031305.1999.10474494},
eprint = {arXiv:1011.1669v3},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Rousseeuw, Ruts, Tukey - 1999 - The Bagplot A bivariate boxplot.pdf:pdf},
isbn = {00031305},
issn = {15372731},
journal = {American Statistician},
keywords = {Algorithms,Depth contours,Graphical display,Location depth,Ranks},
number = {4},
pages = {382--387},
pmid = {248},
title = {{The Bagplot: A bivariate boxplot}},
volume = {53},
year = {1999}
}
@inproceedings{Lodha1996a,
author = {Lodha, S K and Sheehan, R E and Pang, A T and Wittenbrink, C M},
booktitle = {Proceedings of the Conference on Graphics Interface '96},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Lodha et al. - 1996 - Visualizing geometric uncertainty of surface interpolants.pdf:pdf},
isbn = {0-9695338-5-3},
issn = {0713-5424},
keywords = {central to the work,comparison,engineers and,geometry,glyphs,interac-,interpolation,of scientists,probes,surfaces,tainty,texture,tive,uncer-,visualization},
pages = {238--245},
title = {{Visualizing geometric uncertainty of surface interpolants}},
year = {1996}
}
@article{Lundstrom2007,
abstract = {Direct Volume Rendering has proved to be an effective visualization method for medical data sets and has reached wide-spread clinical use. The diagnostic exploration, in essence, corresponds to a tissue classification task, which is often complex and time-consuming. Moreover, a major problem is the lack of information on the uncertainty of the classification, which can have dramatic consequences for the diagnosis. In this paper this problem is addressed by proposing animation methods to convey uncertainty in the rendering. The foundation is a probabilistic Transfer Function model which allows for direct user interaction with the classification. The rendering is animated by sampling the probability domain over time, which results in varying appearance for uncertain regions. A particularly promising application of this technique is a "sensitivity lens" applied to focus regions in the data set. The methods have been evaluated by radiologists in a study simulating the clinical task of stenosis assessment, in which the animation technique is shown to outperform traditional rendering in terms of assessment accuracy.},
author = {Lundstr{\"{o}}m, Claes and Ljung, Patric and Persson, Anders and Ynnerman, Anders},
doi = {10.1109/TVCG.2007.70518},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Lundstr{\"{o}}m et al. - 2007 - Uncertainty visualization in medical volume rendering using probabilistic animation.pdf:pdf},
isbn = {1077-2626 (Print)},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Medical visualization,Probability,Transfer function,Uncertainty,Volume rendering},
number = {6},
pages = {1648--1655},
pmid = {17968121},
title = {{Uncertainty visualization in medical volume rendering using probabilistic animation}},
volume = {13},
year = {2007}
}
@inproceedings{Lodha1996b,
author = {Lodha, Suresh K. and Pang, Alex and Sheehan, Bob and Wittenbrink, Craig M.},
booktitle = {Proceedings of Visualization 1996},
doi = {10.1109/VISUAL.1996.568116},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Lodha et al. - 1996 - UFLOW Visualizing uncertainty in fluid flow.pdf:pdf},
keywords = {an-,and phrases,certainty glyphs,ow envelopes,ow visualization,rakes,streamlines,un-},
pages = {249--254},
title = {{UFLOW: Visualizing uncertainty in fluid flow}},
year = {1996}
}
@article{Pang1997,
abstract = {Visualized data often have dubious origins and quality. Different forms of uncertainty and errors are also introduced as the data are derived, transformed, interpolated, and finally rendered. This paper surveys uncertainty visualization techniques that present data so that users are made aware of the locations and degree of uncertainties in their data. The techniques include adding glyphs, adding geometry, modifying geometry, modifying attributes, animation, sonification, and psychovisual approaches. We present our results in uncertainty visualization for environmental visualization, surface interpolation, global illumination with radiosity, flow visualization, and figure animation. We also present a classification of the possibilities in uncertainty visualization and locate our contributions within this classification.},
author = {Pang, Alex T. and Wittenbrink, Craig M. and Lodha, Suresh K.},
doi = {10.1007/s003710050111},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Pang, Wittenbrink, Lodha - 1997 - Approaches to uncertainty visualization.pdf:pdf},
isbn = {0178-2789},
issn = {01782789},
journal = {The Visual Computer},
keywords = {classi cation,comparative visualization,data quality,di erences,verity},
number = {8},
pages = {370--390},
title = {{Approaches to uncertainty visualization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.4128{\&}rep=rep1{\&}type=pdf},
volume = {13},
year = {1997}
}
@inproceedings{Osorio2008,
abstract = {Composite structure incorporating steel beams and precast hollowcore slabs is a recently developed composite floor system for building structures. This form of composite construction is so far limited to simple beam-column connections. Although the concept of semi-rigid composite joints has been widely research in the past, most of the researches have been carried out on composite joints with metal deck flooring and solid concrete slabs. Research on composite joints with precast hollowcore slabs is rather limited. As the construction industry demands for rapid construction with reduction in cost and environmental impacts, this form of composite floor system, which does not require major onsite concreting, has become very popular among the designers and engineers in the UK. In this paper, full-scale tests of beam-to-column semi-rigid composite joints with steel beam and precast hollowcore slabs are reported. Based on the tests data; the structural behaviour of these semi-rigid composite joints is discussed together with numerical and finite element modelling. Through parametric studies, an analytical model for the semirigid composite joints is proposed and is verified by both the experimental data and finite element model; and good agreement is obtained.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0412138v1},
author = {Osorio, R. S. Allendes and Brodlie, K. W.},
booktitle = {Proceedings of Theory and Practice of Computer Graphics},
doi = {10.1186/1742-7622-5-2},
eprint = {0412138v1},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Osorio, Brodlie - 2008 - Contouring with uncertainty.pdf:pdf},
isbn = {9783540793960},
issn = {01676296},
keywords = {energy from waste,hypothetical compound,monte carlo analysis,municipal solid waste management},
pages = {1--7},
pmid = {18179835},
primaryClass = {cond-mat},
title = {{Contouring with uncertainty}},
year = {2008}
}
@article{Robertson2008,
abstract = {Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.},
annote = {Contribution: propose two visualizations for trend analysis (showing traces of all trends in one display and a small multiple display)
we will focus only on informal trends that can be perceived visually without statistical trend estimation},
author = {Robertson, George and Fernandez, Roland and Fisher, Danyel and Lee, Bongshin and Stasko, John},
doi = {10.1109/TVCG.2008.125},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Robertson et al. - 2008 - Effectiveness of animation in trend visualization.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Animation,Design,Experiment,Information visualization,Trends},
number = {6},
pages = {1325--1332},
pmid = {18988980},
title = {{Effectiveness of animation in trend visualization}},
volume = {14},
year = {2008}
}
@article{Grigoryan2004,
abstract = {Efficient and informative visualization of surfaces with uncertainties is an important topic with many applications in science and engineering. In these applications, the correct course of action may depend not only on the location of a boundary, but on the precision with which that location is known. Examples include environmental pollution borderline detection, oil basin edge characterization, or discrimination between cancerous and healthy tissue in medicine. This paper presents a method for producing visualizations of surfaces with uncertainties using points as display primitives. Our approach is to render the surface as a collection of points and to displace each point from its original location along the surface normal by an amount proportional to the uncertainty at that point. This approaoh can be used in combination with other techniques such as pseudocoloring to produce efficient and revealing visualizations. The basic approach is sufficiently flexible to allow natural extensions; we show incorporation of expressive modulation of opacity, change of the stroke primitive, and addition of an underlying polygonal model. The method is used to visualize real and simulated tumor formations with uncertainty of tumor boundaries. The point-based technique is compared to pseudocoloring for a position estimation task in a preliminary user study.},
author = {Grigoryan, Gevorg and Rheingans, Penny},
doi = {10.1109/TVCG.2004.30},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Grigoryan, Rheingans - 2004 - Point-based probabilistic surfaces to show surface uncertainty.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Point-based graphics,Uncertainty,Visualizing surface uncertainty},
number = {5},
pages = {564--573},
pmid = {15794138},
title = {{Point-based probabilistic surfaces to show surface uncertainty}},
volume = {10},
year = {2004}
}
@inproceedings{Collberg2003,
abstract = {We describe GEVOL, a system that visualizes the evolution of software using a novel graph drawing technique for visualization of large graphs with a temporal component. GEVOL extracts information about a Java program stored within a CVS version control system and displays it using a temporal graph visualizer. This information can be used by programmers to understand the evolution of a legacy program: Why is the program structured the way it is? Which programmers were responsible for which parts of the program during which time periods? Which parts of the program appear unstable over long periods of time and may need to be rewritten? This type of information will complement that produced by more static tools such as source code browsers, slicers, and static analyzers.},
annote = {è²ã§æéãè¡¨ç¾ãã¦ããï¼ã¯ãï¼ï¼

è²ã¯ã©ããããã³ã¼ããå¤æ´ããã¦ããªãããè¡¨ç¾ãã¹ã¦ã®ãã¼ãã¯èµ¤ããå§ã¾ã£ã¦ãã ãã ãç½ã£ã½ããªã£ã¦ãããæçµçã«ã¯éç½ã«ãªã},
author = {Collberg, Christian and Kobourov, Stephen and Nagra, Jasvir and Pitts, Jacob and Wampler, Kevin},
booktitle = {Proceedings of the 2003 ACM Symposium on Software Visualization},
doi = {10.1145/774833.774844},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Collberg et al. - 2003 - A system for graph-based visualization of the evolution of software.pdf:pdf},
isbn = {1581136420},
pages = {77--ff},
title = {{A system for graph-based visualization of the evolution of software}},
url = {http://portal.acm.org/citation.cfm?doid=774833.774844},
year = {2003}
}
@article{Madura2017,
annote = {ããããã¤åº§ã¤ã¼ã¿æãï¼Dããªã³ã¿ã§è²ä»ãã®ç«ä½ãä½ã£ã¦ãæ§é ãæããã«ããã},
archivePrefix = {arXiv},
arxivId = {1611.09994},
author = {Madura, Thomas I.},
doi = {10.1088/1538-3873/129/975/058011},
eprint = {1611.09994},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Madura - 2017 - A case study in astronomical 3D printing The mysterious $\eta$ carinae.pdf:pdf},
issn = {0004-6280},
journal = {Publications of the Astronomical Society of the Pacific},
keywords = {data analysis,hydrodynamics,individual,methods,miscellaneous,stars,$\eta$ carinae},
number = {975},
pages = {058011},
title = {{A case study in astronomical 3D printing: The mysterious $\eta$ carinae}},
url = {http://stacks.iop.org/1538-3873/129/i=975/a=058011?key=crossref.77f0fec7c181816490e8cde6a5e92fe6},
volume = {129},
year = {2017}
}
@article{Kehrer2013,
abstract = {Visualization and visual analysis play important roles in exploring, analyzing, and presenting scientific data. In many disciplines, data and model scenarios are becoming multifaceted: data are often spatiotemporal and multivariate; they stem from different data sources (multimodal data), from multiple simulation runs (multirun/ensemble data), or from multiphysics simulations of interacting phenomena (multimodel data resulting from coupled simulation models). Also, data can be of different dimensionality or structured on various types of grids that need to be related or fused in the visualization. This heterogeneity of data characteristics presents new opportunities as well as technical challenges for visualization research. Visualization and interaction techniques are thus often combined with computational analysis. In this survey, we study existing methods for visualization and interactive visual analysis of multifaceted scientific data. Based on a thorough literature review, a categorization of approaches is proposed. We cover a wide range of fields and discuss to which degree the different challenges are matched with existing solutions for visualization and visual analysis. This leads to conclusions with respect to promising research directions, for instance, to pursue new solutions for multirun and multimodel data as well as techniques that support a multitude of facets.},
author = {Kehrer, Johannes and Hauser, Helwig},
doi = {10.1109/TVCG.2012.110},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Kehrer, Hauser - 2013 - Visualization and visual analysis of multifaceted scientific data A survey.pdf:pdf},
isbn = {1077-2626 VO - 19},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Visualization,interactive visual analysis,multimodal,multimodel,multirun,multivariate,spatiotemporal data},
number = {3},
pages = {495--513},
pmid = {22508905},
title = {{Visualization and visual analysis of multifaceted scientific data: A survey}},
volume = {19},
year = {2013}
}
@article{Silva2000,
abstract = {During the last few years, databases have been growing in size, varieties of data, numbers of users and diversity of applications. Many such applications deal with data characterized by the temporal dimension (e.g. medical records, biographical data, financial data, etc.). Typically, end-users of these data are competent in the field of the application but are not computer experts. They need easy-to-use systems that are able to support them in the task of accessing and manipulating the data contained in the databases. It is well-known that visual techniques are suitable in supporting users interacting with large data sets. However, not much research has been carried on specifically on the relationship between visual techniques and time-dependent data. This paper aims at filling this gap by presenting an overview of the main visual techniques for interactive exploration of time-oriented (historical) information.},
author = {Silva, S. F. and Catarci, T.},
doi = {10.1109/WISE.2000.882407},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Silva, Catarci - 2000 - Visualization of linear time-oriented data A survey.pdf:pdf},
isbn = {0769505775},
journal = {Proceedings of the 1st International Conference on Web Information Systems Engineering, WISE 2000},
number = {March},
pages = {310--319},
title = {{Visualization of linear time-oriented data: A survey}},
volume = {1},
year = {2000}
}
@inproceedings{McDonald2012,
abstract = {NASA's latest space mission on the Lunar Reconnaissance Orbiter (LRO) has produced some of the largest publicly accessible Laser Altimeter data products available to date. The spatial density of these new data products are up to four times greater than laser altimeter data produced from previous space missions. However, partially due to the size, volume and density of the new altimeter data, current software tools provide only limited or no support for real-time cartographical projects, slope analysis, distance measurements or other analyses method critical to physiographic study of planetary systems. We discuss a novel software tool called mVTK, which facilitates the physiographic analysis of the Lunar surface using the newly acquired high resolution altimeter data products. Some of the features provided by m VTK include realtime cartographic projects, slope analysis, distance measurement and visual data discovery.},
annote = {Laser Altimeter dataã®å¯è¦å
ææ°ã®è¦å¯æ©ããã®ãã¼ã¿ã¯ã¨ã£ã¦ãå¤§ããã®ã§ãªã¢ã«ã¿ã¤ã ã§å¾æã¨ãè·é¢ã¨ããæ¸¬ã£ããããã®ãå°é£
ææ¡ææ³ï¼mVTKï¼ã¯ãã®é«è§£ååº¦ã®é«åº¦ãã¼ã¿ã®ãç¨ããæé¢ã®è§£æãå®¹æã«ãããã¼ã«},
author = {McDonald, J and Montgomery, J},
booktitle = {Proceedings of 2012 International Conference on Computer Vision in Remote Sensing},
doi = {10.1109/CVRS.2012.6421285},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/McDonald, Montgomery - 2012 - Terrain visualization and data discovery using lunar high-resolution laser altimeter data sets.pdf:pdf},
isbn = {9781467312745},
keywords = {Extraterrestrial measurements,Laser Altimeter,Lasers,Lunar,Moon,altimeters,astronomical image processing,cartographical project,data discovery,data visualisation,distance measurement,distance measurements,high resolution altimeter data,lunar high-resolution laser altimeter data sets,lunar reconnaissance orbiter,lunar surface,mVTK software tool,measurement by laser beam,physiographic analysis,real-time cartographical projections,slope analysis,spatial density,terrain mapping,terrain visualization},
pages = {335--339},
title = {{Terrain visualization and data discovery using lunar high-resolution laser altimeter data sets}},
url = {http://ieeexplore.ieee.org/ielx5/6410226/6421218/06421285.pdf?tp={\&}arnumber=6421285{\&}isnumber=6421218},
year = {2012}
}
@inproceedings{Pomar2011,
author = {Pomar, Daniel and Hernandez, Edgar Fajardo and Thooris, Bruno and De, Institut and Fondamentales, Lois and Univers, De and Saclay, C E A and Cedex, Gif-sur-yvette},
booktitle = {Proceedings of 2011 Eighth International Conference Computer Graphics, Imaging and Visualization},
doi = {10.1109/CGIV.2011.25},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Pomar et al. - 2011 - Exploratory visualization of Saturn, its rings and moons with SDvision.pdf:pdf},
isbn = {9780769544847},
pages = {170--176},
title = {{Exploratory visualization of Saturn, its rings and moons with SDvision}},
year = {2011}
}
@inproceedings{Chen2017,
author = {Chen, Wei and Chen, Lifang},
booktitle = {Proceedings of 2017 IEEE/ACIS 16th International Conference on Computer and Information Science},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Chen, Chen - 2017 - Lunar craters visualization based on orthogonal spline basis.pdf:pdf},
isbn = {9781509055074},
keywords = {lunar craters,scattered data fitting,visualization},
pages = {391--394},
title = {{Lunar craters visualization based on orthogonal spline basis}},
year = {2017}
}
@inproceedings{Powell2005,
abstract = {We present an account of the scientific visualization techniques that were used to support science planning for NASA's 2003 Mars Exploration Rover Mission. The great sophistication of the rover's Athena Science Payload required a wide variety of visualization modalities to make the large amounts of scientific data accessible and readily understood by the science planners under the tight time constraints of the tactical planning schedule. A number of techniques were also newly developed to support science operations, including on-the-fly mosaic stitching and rendering, image cube visualization, and data fusion. Many other well-established visualization techniques were applied to science operations also, such as anaglyph stereo, high performance 3D visualization, and optimized I/O and memory management techniques for the loading, processing, and visualization of very large data sets. We discuss each of these topics and demonstrate their application in the MER mission with examples.},
author = {Powell, Mark W. and Norris, Jeffrey S. and Vona, Marsette A. and Backes, Paul G. and Wick, Justin V.},
booktitle = {Proceedings of the 2005 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2005.1570780},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Powell et al. - 2005 - Scientific visualization for the mars exploration rovers.pdf:pdf},
isbn = {078038914X},
issn = {10504729},
keywords = {Coregistration,Image processing,Science planning,Telerobotics,Visualization},
pages = {4290--4296},
title = {{Scientific visualization for the mars exploration rovers}},
year = {2005}
}
@inproceedings{Hartman2005,
abstract = {The Rover Sequencing and Visualization Program is a suite of tools for the commanding of planetary rovers which are subject to significant light time delay and thus are unsuitable for tele-operation. The two main components of the program are the Rover Sequence Editor and HyperDrive. This paper focuses on HyperDrive, the immersive visualization component of the system. HyperDrive fuses multiple data types returned from the vehicle in order to facilitate an operator understanding of the current environment and past rover performance, so that safe effective command sequences for successful future rover activities may be generated on a tight tactical timeline. Multiple display and task specific interaction modalities are provided to most efficiently present relevant spatial and time series data to the sequence builder},
author = {Hartman, F R and Cooper, B and Leger, C and Maxwell, S and Wright, J and Yen, J},
booktitle = {Proceedings of 2005 IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2005.1571339},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Hartman et al. - 2005 - Data visualization for effective rover sequencing.pdf:pdf},
isbn = {0-7803-9298-1},
issn = {1062922X},
keywords = {astronomy computing,augmented reality,data visuali},
pages = {1378--1383},
title = {{Data visualization for effective rover sequencing}},
volume = {2},
year = {2005}
}
@inproceedings{Risch1997,
abstract = {STARLIGHT is an example of a new class of information system expressly designed around visualization-oriented user-interface. Incorporating more traditional information storage and retrieval technologies into its design, the STARLIGHT system also enables the integrated use of multiple, concurrent visualization techniques to support comparison of content and interrelationship information levels of abstraction simultaneously. This powerful new form of information analysis eases cognitive workloads by providing a visual context for the information under study. Originally developed for intelligence analysis applications, the STARLIGHT software is intended to support the rapid, concurrent analysis of complex multimedia information, including structured and unstructured text, geographic information, and digital imagery. The system uses novel 3-D visualization techniques that interactively generate easily understandable representations of explicit and implicit relationships contained in information collections of various types. This paper describes the general theory behind our approach, and the design and features of a Windows NT-based operational system},
author = {Risch, J.S. and Rex, D.B. and Dowson, S.T. and Walters, T.B. and May, R.a. and Moon, B.D.},
booktitle = {Proceedings of 1997 IEEE Conference on Information Visualization (Cat. No.97TB100165)},
doi = {10.1109/IV.1997.626486},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Risch et al. - 1997 - The STARLIGHT information visualization system.pdf:pdf},
isbn = {0-8186-8076-8},
keywords = {data visualisation,graphical user interfaces,information analysis,information systems},
pages = {42--49},
title = {{The STARLIGHT information visualization system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=626486},
year = {1997}
}
@article{Fluke2017,
abstract = {In this data-rich era of astronomy; there is a growing reliance on automated techniques to discover new knowledge. The role of the astronomer may change from being a discoverer to being a confirmer. But what do astronomers actually look at when they distinguish between âsourcesâ and ânoise?â What are the differences between novice and expert astronomers when it comes to visual-based discovery? Can we identify elite talent or coach astronomers to maximize their potential for discovery? By looking to the field of sports performance analysis; we consider an established; domain-wide approach; where the expertise of the viewer (i.e. a member of the coaching team) plays a crucial role in identifying and determining the subtle features of gameplay that provide a winning advantage. As an initial case study; we investigate whether the SportsCode performance analysis software can be used to understand and document how an experienced Hi astronomer makes discoveries in spectral data cubes. We find that the process of timeline-based coding can be applied to spectral cube data by mapping spectral channels to frames within a movie. SportsCode provides a range of easy to use methods for annotation; including feature-based codes and labels; text annotations associated with codes; and image-based drawing. The outputs; including instance movies that are uniquely associated with coded events; provide the basis for a training program or team-based analysis that could be used in unison with discipline specific analysis software. In this coordinated approach to visualization and analysis; SportsCode can act as a visual notebook; recording the insight and decisions in partnership with established analysis methods. Alternatively; in situ annotation and coding of features would be a valuable addition to existing and future visualization and analysis packages.},
archivePrefix = {arXiv},
arxivId = {arXiv:1702.04829v1},
author = {Fluke, C J and Parrington, L and Hegarty, S and Macmahon, C and Morgan, S and Hassan, A H and Kilborn, V A},
doi = {10.1088/1538-3873/aa5385},
eprint = {arXiv:1702.04829v1},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Fluke et al. - 2017 - Sports stars Analyzing the performance of astronomers at visualization-based discovery.pdf:pdf},
issn = {0004-6280},
journal = {Publications of the Astronomical Society of the Pacific},
keywords = {catalogs,data analysis,methods,surveys,techniques},
number = {975},
pages = {05009},
title = {{Sports stars: Analyzing the performance of astronomers at visualization-based discovery}},
volume = {129},
year = {2017}
}
@article{Wang2011,
abstract = {In recent years, there is an emerging direction that leverages information theory to solve many challenging problems in scientific data analysis and visualization. In this article, we review the key concepts in information theory, discuss how the principles of information theory can be useful for visualization, and provide specific examples to draw connections between data communication and data visualization in terms of how information can be measured quantitatively. As the amount of digital data available to us increases at an astounding speed, the goal of this article is to introduce the interested readers to this new direction of data analysis research, and to inspire them to identify new applications and seek solutions using information theory.},
author = {Wang, Chaoli and Shen, Han-Wei},
doi = {10.3390/e13010254},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Shen - 2011 - Information theory in scientific visualization.pdf:pdf},
issn = {1099-4300},
journal = {Entropy},
keywords = {information theory,scientific visualization,visual communication channel},
number = {1},
pages = {254--273},
title = {{Information theory in scientific visualization}},
url = {http://www.mdpi.com/1099-4300/13/1/254/},
volume = {13},
year = {2011}
}
@article{Hassan2011,
abstract = {Astronomy is entering a new era of discovery, coincident with the establishment of new facilities for observation and simulation that will routinely generate petabytes of data. While an increasing reliance on automated data analysis is anticipated, a critical role will remain for visualization-based knowledge discovery. We have investigated scientific visualization applications in astronomy through an examination of the literature published during the last two decades. We identify the two most active fields for progress - visualization of large-N particle data and spectral data cubes - discuss open areas of research, and introduce a mapping between astronomical sources of data and data representations used in general purpose visualization tools. We discuss contributions using high performance computing architectures (e.g: distributed processing and GPUs), collaborative astronomy visualization, the use of workflow systems to store metadata about visualization parameters, and the use of advanced interaction devices. We examine a number of issues that may be limiting the spread of scientific visualization research in astronomy and identify six grand challenges for scientific visualization research in the Petascale Astronomy Era.},
archivePrefix = {arXiv},
arxivId = {1102.5123},
author = {Hassan, Amr and Fluke, Christopher J.},
doi = {10.1071/AS10031},
eprint = {1102.5123},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Hassan, Fluke - 2011 - Scientific visualization in astronomy Towards the petascale astronomy era.pdf:pdf},
isbn = {1323-3580},
issn = {13233580},
journal = {Publications of the Astronomical Society of Australia},
keywords = {methods: data analysis,techniques: miscellaneous},
number = {2},
pages = {150--170},
publisher = {Keio University},
title = {{Scientific visualization in astronomy: Towards the petascale astronomy era}},
volume = {28},
year = {2011}
}
@article{Kent2017,
abstract = {Data immersion has advantages in astrophysical visualization. Complex multi-dimensional data and phase spaces can be explored in a seamless and interactive viewing environment. Putting the user in the data is a first step toward immersive data analysis. We present a technique for creating 360 degree spherical panoramas with astrophysical data. The three-dimensional software package Blender and the Google Spatial Media module are used together to immerse users in data exploration. Several examples employing these methods exhibit how the technique works using different types of astronomical data.},
archivePrefix = {arXiv},
arxivId = {1701.08807},
author = {Kent, Brian R.},
doi = {10.1088/1538-3873/aa5543},
eprint = {1701.08807},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Kent - 2017 - Spherical panoramas for astrophysical data visualization.pdf:pdf},
issn = {0004-6280},
journal = {Publications of the Astronomical Society of the Pacific},
keywords = {color fi gures,data analysis,data visualization,methods,methods: data analysis,mobile devices,online material,visualization},
number = {975},
pages = {58001},
publisher = {IOP Publishing},
title = {{Spherical panoramas for astrophysical data visualization}},
volume = {129},
year = {2017}
}
@article{Abbott2004,
abstract = {Partiview is an advanced, real-time visualization tool for multi-dimensional datasets. Developed at NCSA, Partiview has cross-platform compatibility that allows its use in environments ranging from laptops to the 21-meter-diameter Hayden Planetarium dome, on scales varying from the solar neighborhood to large-scale structure. Current applications of Partiview include the simultaneous, fully interactive visualization of multiple datasets, including both observed and simulated data. The software is available at no cost from www.haydenplanetarium.org along with our Digital Universe data archive. A major priority of the ongoing development of Partiview is its integration as an analysis and visualization component of an International Virtual Observatory.},
annote = {ãã«ããã©ãããã©ã¼ã ã§ãªã¢ã«ã¿ã¤ã ã§åãå¤æ¬¡åãã¼ã¿ã®å¯è¦åãã¼ã«ã},
author = {Abbott, Brian P and Emmart, Carter B and Levy, Stuart and Liu, Charles T},
doi = {10.1007/10857598_8},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Abbott et al. - 2004 - Visualizing and analyzing massive astronomical datasets with Partiview.pdf:pdf},
isbn = {978-3-540-39908-7},
journal = {Toward an International Virtual Observatory: Proceedings of the ESO/ESA/NASA/NSF Conference Held at Garching, Germany, 10-14 June 2002},
pages = {57--61},
publisher = {Springer Berlin Heidelberg},
title = {{Visualizing and analyzing massive astronomical datasets with Partiview}},
year = {2004}
}
@article{Naiman2016,
abstract = {The rapid growth in scale and complexity of both computational and observational astrophysics over the past decade necessitates efficient and intuitive methods for examining and visualizing large datasets. Here, I present AstroBlend, an open-source Python library for use within the three dimensional modeling software, Blender. While Blender has been a popular open-source software among animators and visual effects artists, in recent years it has also become a tool for visualizing astrophysical datasets. AstroBlend combines the three dimensional capabilities of Blender with the analysis tools of the widely used astrophysical toolset, yt, to afford both computational and observational astrophysicists the ability to simultaneously analyze their data and create informative and appealing visualizations. The introduction of this package includes a description of features, work flow, and various example visualizations. A website - www.astroblend.com - has been developed which includes tutorials, and a gallery of example images and movies, along with links to downloadable data, three dimensional artistic models, and various other resources.},
annote = {Python library},
archivePrefix = {arXiv},
arxivId = {1602.03178},
author = {Naiman, J. P.},
doi = {10.1016/j.ascom.2016.02.002},
eprint = {1602.03178},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Naiman - 2016 - AstroBlend An astrophysical visualization package for Blender.pdf:pdf},
issn = {22131337},
journal = {Astronomy and Computing},
keywords = {Methods: numerical,Miscellaneous},
pages = {50--60},
title = {{AstroBlend: An astrophysical visualization package for Blender}},
volume = {15},
year = {2016}
}
@article{Taylor2017,
abstract = {Astronomical data does not always use Cartesian coordinates. Both all-sky observational data and simulations of rotationally symmetric systems, such as accretion and protoplanetary discs, may use spherical polar or other coordinate systems. Standard displays rely on Cartesian coordinates, but converting non-Cartesian data into Cartesian format causes distortion of the data and loss of detail. I here demonstrate a method using standard techniques from computer graphics that avoids these problems with 3D data in arbitrary coordinate systems. The method adds minimum computational cost to the display process and is suitable for both realtime, interactive content and producing fixed rendered images and videos. Proof-of-concept code is provided which works for data in spherical polar coordinates.},
archivePrefix = {arXiv},
arxivId = {1611.02517},
author = {Taylor, Rhys},
doi = {10.1088/1538-3873/129/972/028002},
eprint = {1611.02517},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Taylor - 2017 - Visualising three-dimensional volumetric data with an arbitrary coordinate system.pdf:pdf},
issn = {00046280},
journal = {Publications of the Astronomical Society of Pacific},
keywords = {galaxies,kinematics and dynamics,radio lines,scientific visualization,surveys,visual analytics},
number = {2},
pages = {028002},
title = {{Visualising three-dimensional volumetric data with an arbitrary coordinate system}},
url = {http://arxiv.org/abs/1611.02517{\%}5Cnhttp://adsabs.harvard.edu/abs/2017PASP..129b8002T},
volume = {129},
year = {2017}
}
@article{Baines2017,
abstract = {ESASky is a science-driven discovery portal to explore the multi-wavelength sky and visualise and access multiple astronomical archive holdings. The tool is a web application that requires no prior knowledge of any of the missions involved and gives users world-wide simplified access to the highest-level science data products from multiple astronomical space-based astronomy missions plus a number of ESA source catalogues. The first public release of ESASky features interfaces for the visualisation of the sky in multiple wavelengths, the visualisation of query results summaries, and the visualisation of observations and catalogue sources for single and multiple targets. This paper describes these features within ESASky, developed to address use cases from the scientific community. The decisions regarding the visualisation of large amounts of data and the technologies used were made in order to maximise the responsiveness of the application and to keep the tool as useful and intuitive as possible.},
archivePrefix = {arXiv},
arxivId = {1701.02533},
author = {Baines, Deborah and Giordano, Fabrizio and Racero, Elena and Salgado, Jes{\'{u}}s and Mart{\'{i}}, Bel{\'{e}}n L{\'{o}}pez and Mer{\'{i}}n, Bruno and Sarmiento, Mar{\'{i}}a-Henar and Guti{\'{e}}rrez, Ra{\'{u}}l and de Landaluce, I{\~{n}}aki Ortiz and Le{\'{o}}n, Ignacio and de Teodoro, Pilar and Gonz{\'{a}}lez, Juan and Nieto, Sara and Segovia, Juan Carlos and Pollock, Andy and Rosa, Michael and Arviset, Christophe and Lennon, Daniel and O'Mullane, William and de Marchi, Guido},
doi = {10.1088/1538-3873/129/972/028001},
eprint = {1701.02533},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Baines et al. - 2017 - Visualization of multi-mission astronomical data with ESASky.pdf:pdf},
issn = {0004-6280},
journal = {Publications of the Astronomical Society of the Pacific},
keywords = {astronomical databases,catalogs,miscellaneous,telescopes},
number = {972},
pages = {028001},
title = {{Visualization of multi-mission astronomical data with ESASky}},
volume = {129},
year = {2017}
}
@article{Hanson2007,
abstract = {Modern astronomical instruments produce enormous amounts of three-dimensional data describing the physical Universe. The currently available data sets range from the solar system to nearby stars and portions of the Milky Way Galaxy, including the interstellar medium and some extrasolar planets, and extend out to include galaxies billions of light years away. Because of its gigantic scale and the fact that it is dominated by empty space, modeling and rendering the Universe is very different from modeling and rendering ordinary three-dimensional virtual worlds at human scales. Our purpose is to introduce a comprehensive approach to an architecture solving this visualization problem that encompasses the entire Universe while seeking to be as scale-neutral as possible. One key element is the representation of model-rendering procedures using power scaled coordinates (PSC), along with various PSC-based techniques that we have devised to generalize and optimize the conventional graphics framework to the scale domains of astronomical visualization. Employing this architecture, we have developed an assortment of scale-independent modeling and rendering methods for a large variety of astronomical models, and have demonstrated scale-insensitive interactive visualizations of the physical Universe covering scales ranging from human scale to the Earth, to the solar system, to the Milky Way Galaxy, and to the entire observable Universe.},
author = {Hanson, Andrew J.},
doi = {10.1109/TVCG.2007.2},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Hanson - 2007 - A transparently scalable visualization architecture for exploring the universe.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Visualization techniques and methodologies,astronomy,virtual reality,visualization systems and software},
number = {1},
pages = {108--121},
pmid = {17093340},
title = {{A transparently scalable visualization architecture for exploring the universe}},
volume = {13},
year = {2007}
}
@inproceedings{Magnor2004,
author = {Magnor, M. and Kindlmann, G. and Duric, N. and Hansen, C.},
booktitle = {IEEE Visualization 2004},
doi = {10.1109/VISUAL.2004.18},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Magnor et al. - 2004 - Constrained inverse volume rendering for planetary nebulae.pdf:pdf},
isbn = {0-7803-8788-0},
keywords = {inverse rendering,planetary nebulae,volume reconstruction,volume rendering,volumetric modeling},
pages = {83--90},
publisher = {IEEE Comput. Soc},
title = {{Constrained inverse volume rendering for planetary nebulae}},
url = {http://ieeexplore.ieee.org/document/1372183/},
year = {2004}
}
@article{Li2006,
annote = {å®å®ç©ºéãWIMçã«
å¨ä½ãè¦éããããã«
ã·ãã¥ã¬ã¼ã·ã§ã³},
author = {Li, Yinggang and Fu, Chi-wing and Hanson, Andrew},
doi = {10.1109/TVCG.2006.176},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Li, Fu, Hanson - 2006 - Scalable WIM Effective exploration in large-scale astrophysical environments.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {sep},
number = {5},
pages = {1005--1012},
title = {{Scalable WIM: Effective exploration in large-scale astrophysical environments}},
url = {http://ieeexplore.ieee.org/document/4015458/},
volume = {12},
year = {2006}
}
@inproceedings{Magnor2005,
annote = {reflection neb ulaeã£ã¦ãã®ã®å¯è¦å
ã¤ã³ã¿ã©ã¯ãã£ãã«åã£ã¦ããæã®å¨ãã®dust distributionãå¯è¦åãããã¼ã«
ã·ãã¥ã¬ã¼ã·ã§ã³},
author = {Magnor, Marcus A. and Hildebrand, Kristian and Lintu, Andrei and Hanson, Andrew J.},
booktitle = {Proceedings of IEEE Visualization 2005},
doi = {10.1109/VISUAL.2005.1532803},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Magnor et al. - 2005 - Reflection nebula visualization.pdf:pdf},
isbn = {0780394623},
pages = {255--262},
publisher = {IEEE},
title = {{Reflection nebula visualization}},
url = {http://ieeexplore.ieee.org/document/1532803/},
year = {2005}
}
@article{Hopf2004,
annote = {å¯è¦åã®è«æã§ã¯ãªãã¦ãé«éåã®è«æ

æç³»åã®scattered point dataã®å¯è¦å
ã·ãã¥ã¬ã¼ã·ã§ã³

åç¹ãposition xiï¼ãã¯ãã«ï¼, diameter si, and intensity ci at various wavelengthsã®ãã¼ã¿ãæã£ã¦ã
ãã®ã¾ã¾ã ã¨ã¨ã¦ãã¤ã³ã¿ã©ã¯ãã£ãã«å¯è¦åã§ããªãã®ã§ãç ç©¶èã¯low-pass filterãããã¦ãªãµã³ããªã³ã°ããããããããã¨fine detailsãå¤±ããã¦ãã¾ããã®ã§ããªãµã³ããªã³ã°ããªãã§ãé«è§£ååº¦ã®ãã¼ã¿ãç§å­¦èã«è¦ããã

we can visualize time-dependent data sets with millions of points inter- actively with subpixel screen space error on current PC graphics hardware employing advanced vertex shader functionality},
author = {Hopf, M. and Luttenberger, M. and Ertl, T.},
doi = {10.1109/MCG.2004.7},
file = {:Users/nsawada/Google Drive/Papers/Hierarchical splatting of scattered 4D data.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
month = {jul},
number = {4},
pages = {64--72},
title = {{Hierarchical splatting of scattered 4D data}},
url = {http://ieeexplore.ieee.org/document/1310213/},
volume = {24},
year = {2004}
}
@inproceedings{Baranoski,
annote = {ãªã¼ã­ã©ã®ã·ãã¥ã¬ã¼ã·ã§ã³çµæã®å¯è¦å},
author = {Baranoski, G.V.G. and Rokne, J.G. and Shirley, P. and Trondsen, T. and Bastos, R.},
booktitle = {Proceedings the Eighth Pacific Conference on Computer Graphics and Applications},
doi = {10.1109/PCCGA.2000.883852},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Baranoski et al. - Unknown - Simulating the aurora borealis.pdf:pdf},
isbn = {0-7695-0868-5},
pages = {2--432},
publisher = {IEEE Comput. Soc},
title = {{Simulating the aurora borealis}},
url = {http://ieeexplore.ieee.org/document/883852/}
}
@inproceedings{Jensen2001,
address = {New York, New York, USA},
annote = {å¤ç©ºã®ã·ãã¥ã¬ã¼ã·ã§ã³å¯è¦å},
author = {Jensen, Henrik Wann and Durand, Fr{\'{e}}do and Dorsey, Julie and Stark, Michael M. and Shirley, Peter and Premo{\v{z}}e, Simon},
booktitle = {Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques},
doi = {10.1145/383259.383306},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Jensen et al. - 2001 - A physically-based night sky model.pdf:pdf},
isbn = {158113374X},
pages = {399--408},
publisher = {ACM Press},
title = {{A physically-based night sky model}},
url = {http://portal.acm.org/citation.cfm?doid=383259.383306},
year = {2001}
}
@article{Nadeau2000,
annote = {ããªã¥ã¼ã ã¬ã³ããªã³ã°
ã·ãã¥ã¬ã¼ã·ã§ã³},
author = {Nadeau, David R. and Nadeau, David R. and Genetti, Jon D. and Napear, Steve and Pailthorpe, Bernard and Emmart, Carter and Wesselak, Erik and Davidson, Dennis},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Nadeau et al. - 2000 - Visualizing stars and emission nebulae.pdf:pdf},
journal = {Computer Graphics Forum},
number = {1},
pages = {27--33},
title = {{Visualizing stars and emission nebulae}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.9807},
volume = {20},
year = {2000}
}
@article{Genetti2002,
annote = {æé²ã®é«è§£ååº¦ã®ã·ãã¥ã¬ã¼ã·ã§ã³},
author = {Genetti, Jon},
doi = {10.1145/581571.581574},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Genetti - 2002 - Volume-rendered galactic animations.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = {nov},
number = {11},
pages = {62--66},
publisher = {ACM},
title = {{Volume-rendered galactic animations}},
url = {http://portal.acm.org/citation.cfm?doid=581571.581574},
volume = {45},
year = {2002}
}
@inproceedings{Riveiro2007,
author = {Riveiro, Maria},
booktitle = {Proceedings of 2007 10th International Conference on Information Fusion},
doi = {10.1109/ICIF.2007.4408049},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Riveiro - 2007 - Evaluation of uncertainty visualization techniques for information fusion.pdf:pdf},
isbn = {978-0-662-45804-3},
month = {jul},
pages = {1--8},
publisher = {IEEE},
title = {{Evaluation of uncertainty visualization techniques for information fusion}},
url = {http://ieeexplore.ieee.org/document/4408049/},
year = {2007}
}
@article{Ge2009,
abstract = {The existence of uncertainty in classified remotely sensed data necessitates the application of enhanced techniques for identifying and visualizing the various degrees of uncertainty. This paper, therefore, applies the multidimensional graphical data analysis technique of parallel coordinate plots (PCP) to visualize the uncertainty in Landsat Thematic Mapper (TM) data classified by the Maximum Likelihood Classifier (MLC) and Fuzzy C-Means (FCM). The Landsat TM data are from the Yellow River Delta, Shandong Province, China. Image classification with MLC and FCM provides the probability vector and fuzzy membership vector of each pixel. Based on these vectors, the Shannon's entropy (S.E.) of each pixel is calculated. PCPs are then produced for each classification output. The PCP axes denote the posterior probability vector and fuzzy membership vector and two additional axes represent S.E. and the associated degree of uncertainty. The PCPs highlight the distribution of probability values of different land cover types for each pixel, and also reflect the status of pixels with different degrees of uncertainty. Brushing functionality is then added to PCP visualization in order to highlight selected pixels of interest. This not only reduces the visualization uncertainty, but also provides invaluable information on the positional and spectral characteristics of targeted pixels. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Ge, Yong and Li, Sanping and Lakhan, V. Chris and Lucieer, Arko},
doi = {10.1016/j.jag.2009.08.004},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Ge et al. - 2009 - Exploring uncertainty in remotely sensed data with parallel coordinate plots.pdf:pdf},
isbn = {0303-2434},
issn = {15698432},
journal = {International Journal of Applied Earth Observation and Geoinformation},
keywords = {Brushing,Interactive visualization,Parallel coordinate plots (PCP),Remotely sensed data,Shannon's entropy,Uncertainty},
month = {dec},
number = {6},
pages = {413--422},
publisher = {Elsevier},
title = {{Exploring uncertainty in remotely sensed data with parallel coordinate plots}},
url = {http://www.sciencedirect.com/science/article/pii/S0303243409000701},
volume = {11},
year = {2009}
}
@article{Wittenbrink1996,
abstract = {Environmental data have inherent uncertainty which is often ignored in visualization. Meteorological stations and doppler radars, including their time series averages, have a wealth of uncertainty information that traditional vector visualization methods such as meteorological wind barbs and arrow glyphs simply ignore. We have developed a new vector glyph to visualize uncertainty in winds and ocean currents. Our approach is to include uncertainty in direction and magnitude, as well as the mean direction and length, in vector glyph plots. Our glyph shows the variation in uncertainty, and provides fair comparisons of data from instruments, models, and time averages of varying certainty. We also define visualizations that incorporate uncertainty in an unambiguous manner as verify visualization. We use both quantitative and qualitative methods to compare our glyphs to traditional ones. Subjective comparison tests with experts are provided, as well as objective tests, where the information density of our new glyphs and traditional glyphs are compared. The design of the glyph and numerous examples using environmental data are given. We show enhanced visualization, data together with their uncertainty information, that may improve understanding of environmental vector field data quality.},
annote = {ãã¯ãã«å ´ã«ä¸ç¢ºå®æ§ãè¡¨ç¾to improve understanding
é«æ¬¡åã«ãªãã¨box plotã§ã¯å¯¾å¿ããããªã

æ­£ç¢ºãªdepixtionã®ããã«ãã¼ã¿ãã¾ã¨ãã¦ãã¤ãä¸ç¢ºå®æ§ããã¯ãã«å ´ã«è¡¨ç¾ããã®ãæ°ããè©¦ã¿ãããã«ãããå®éçã«ãå®æ§çã«ãè©ä¾¡},
author = {Wittenbrink, Craig M. and Pang, Alex T. and Lodha, Suresh K.},
doi = {10.1109/2945.537309},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Wittenbrink, Pang, Lodha - 1996 - Glyphs for visualizing uncertainty in vector fields.pdf:pdf},
isbn = {10772626 (ISSN)},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Doppler radar,Icons,Verity visualization,Wind barbs,Wind profilers},
number = {3},
pages = {266--279},
title = {{Glyphs for visualizing uncertainty in vector fields}},
volume = {2},
year = {1996}
}
@article{Prassni2010,
author = {Prassni, Jorg-Stefan and Ropinski, Timo and Hinrichs, Klaus},
doi = {10.1109/TVCG.2010.208},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Prassni, Ropinski, Hinrichs - 2010 - Uncertainty-aware guided volume segmentation.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {nov},
number = {6},
pages = {1358--1365},
title = {{Uncertainty-aware guided volume segmentation}},
url = {http://ieeexplore.ieee.org/document/5613476/},
volume = {16},
year = {2010}
}
@inproceedings{Pagendarm1994,
abstract = {Today most of the work reported in the field of visualization addresses methods to transform given data into an image. Comparison, if at all, is done by placing images side by side and let the eye and brain perform the task. This paper tries to illustrate the benefits of employing scientific vis- ualization in an deliberately comparative manner. A range of opportunities for comparison on the data level as well as on the image level and with respect to visualization methods is illustrated. Additionally, examples from fluid dynamics applications are used to demonstrate various comparative strategies.},
author = {Pagendarm, Hans-Georg and Post, Frits H},
booktitle = {5th EurographicsWorkshop on Visualization in Scientific Computing},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Pagendarm, Post - 1994 - Comparative visualization - approaches and examples.pdf:pdf},
title = {{Comparative visualization - approaches and examples}},
year = {1994}
}
@inproceedings{Lodha2002,
abstract = {This paper addresses the computation and visualization of the un- certainty associated with the positions of moving particles, using temporal projections based on uncertain knowledge of previous particle position and velocity. First, we present an algorithm for computing the probability distribution describing the position of a particle moving in 2D or 3D space, given the probability distribu- tions that separately characterize the initial position, speed, and di- rection of the particle. The initial distributions are arbitrary, but the special case of Gaussian distributions is considered in greater detail. We also discuss the algorithmic complexity of the algorithm, and ways to improve its performance. Three visualization techniques (galaxy, transparency, and pseudo-color) are developed to represent the resulting probability distribution associated with the particle at a later time. An appropriate time-dependent sampling approach is adopted to make the visualizations more comprehensible to the human viewer. Experiments with different distributions indicate that the resulting visualizations often take the form of recognizable real-world shapes, assisting the user in understanding the nature of a particle's movement.},
annote = {particleã®ä½ç½®ã«ãããä¸ç¢ºå®æ§ããåã®particleã®ä½ç½®ã¨éåº¦ããã¨ã«å¯è¦å},
author = {Lodha, Suresh K and Faaland, Nikolai M and Charaniya, Amin P and Varshney, Pramod K and Mehrotra, Kishan and Mohan, Chilukuri},
booktitle = {Proceedings of the Computer Graphics and Imaging Conference},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Lodha et al. - 2002 - Visualization of uncertain particle movement.pdf:pdf},
pages = {226--232},
title = {{Visualization of uncertain particle movement}},
url = {ftp://classes.soe.ucsc.edu/.zfs/snapshot/2014-01-01/pub/lodha/papers/cgim2002.pdf},
year = {2002}
}
@article{Djurcilov2002,
annote = {è²ãå¤ãéæåº¦ãä¸ç¢ºå®æ§},
author = {Djurcilov, Suzana and Kim, Kwansik and Lermusiaux, Pierre and Panga, Alex},
doi = {10.1016/S0097-8493(02)00055-9},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Djurcilov et al. - 2002 - Visualizing scalar volumetric data with uncertainty.pdf:pdf},
issn = {0097-8493},
journal = {Computers {\&} Graphics},
month = {apr},
number = {2},
pages = {239--248},
publisher = {Pergamon},
title = {{Visualizing scalar volumetric data with uncertainty}},
url = {http://www.sciencedirect.com/science/article/pii/S0097849302000559},
volume = {26},
year = {2002}
}
@inproceedings{Chlan,
author = {Chlan, E.B. and Rheingans, P.},
booktitle = {IEEE Symposium on Information Visualization, 2005. INFOVIS 2005.},
doi = {10.1109/INFVIS.2005.1532140},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Chlan, Rheingans - Unknown - Multivariate glyphs for multi-object clusters.pdf:pdf},
isbn = {0-7803-9464-X},
pages = {141--148},
publisher = {IEEE},
title = {{Multivariate glyphs for multi-object clusters}},
url = {http://ieeexplore.ieee.org/document/1532140/}
}
@article{Gosink2013,
author = {Gosink, Luke and Bensema, Kevin and Pulsipher, Trenton and Obermaier, Harald and Henry, Michael and Childs, Hank and Joy, Kenneth I.},
doi = {10.1109/TVCG.2013.138},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Gosink et al. - 2013 - Characterizing and visualizing predictive uncertainty in numerical ensembles through bayesian model averaging.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {dec},
number = {12},
pages = {2703--2712},
title = {{Characterizing and visualizing predictive uncertainty in numerical ensembles through bayesian model averaging}},
url = {http://ieeexplore.ieee.org/document/6634123/},
volume = {19},
year = {2013}
}
@article{Wang2017,
author = {Wang, He and Ondrej, Jan and O'Sullivan, Carol},
doi = {10.1109/TVCG.2016.2642963},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Ondrej, O'Sullivan - 2017 - Trending Paths A new semantic-level metric for comparing simulated and real crowd data.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {may},
number = {5},
pages = {1454--1464},
title = {{Trending Paths: A new semantic-level metric for comparing simulated and real crowd data}},
url = {http://ieeexplore.ieee.org/document/7797248/},
volume = {23},
year = {2017}
}
@article{Keim2002,
author = {Keim, Daniel},
doi = {10.1109/2945.981847},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Keim - 2002 - Information visualization and visual data mining.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {1--8},
title = {{Information visualization and visual data mining}},
url = {http://ieeexplore.ieee.org/document/981847/},
volume = {8},
year = {2002}
}
@article{Micallef2017,
abstract = {âDesigning a good scatterplot can be difficult for non-experts in visualization, because they need to decide on many parameters, such as marker size and opacity, aspect ratio, color, and rendering order. This paper contributes to research exploring the use of perceptual models and quality metrics to set such parameters automatically for enhanced visual quality of a scatterplot. A key consideration in this paper is the construction of a cost function to capture several relevant aspects of the human visual system, examining a scatterplot design for some data analysis task. We show how the cost function can be used in an optimizer to search for the optimal visual design for a user's dataset and task objectives (e.g., " reliable linear correlation estimation is more important than class separation "). The approach is extensible to different analysis tasks. To test its performance in a realistic setting, we pre-calibrated it for correlation estimation, class separation, and outlier detection. The optimizer was able to produce designs that achieved a level of speed and success comparable to that of those using human-designed presets (e.g., in R or MATLAB). Case studies demonstrate that the approach can adapt a design to the data, to reveal patterns without user intervention.},
author = {Micallef, Luana and Palmas, Gregorio and Oulasvirta, Antti and Weinkauf, Tino},
doi = {10.1109/TVCG.2017.2674978},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Micallef et al. - 2017 - Towards perceptual optimization of the visual design of scatterplots.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Scatterplot,crowdsourcing,optimization,perception},
number = {6},
pages = {1588--1599},
title = {{Towards perceptual optimization of the visual design of scatterplots}},
volume = {23},
year = {2017}
}
@article{Keim2008,
abstract = {We are living in a world which faces a rapidly increasing amount of data to be dealt with on a daily basis. In the last decade, the steady improvement of data storage devices and means to create and collect data along the way influenced our way of dealing with information: Most of the time, data is stored without filtering and refinement for later use. Virtually every branch of industry or business, and any political or personal activity nowadays generate vast amounts of data. Making matters worse, the possibilities to collect and store data increase at a faster rate than our ability to use it for making decisions. However, in most applications, raw data has no value in itself; instead we want to extract the information contained in it.},
address = {Berlin, Heidelberg},
author = {Keim, Daniel and Andrienko, Gennady and Fekete, Jean-Daniel and G{\"{o}}rg, Carsten and Kohlhammer, J{\"{o}}rn and Melan{\c{c}}on, Guy},
doi = {10.1007/978-3-540-70956-5_7},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Keim et al. - 2008 - Visual analytics Definition, process, and challenges.pdf:pdf},
journal = {Information Visualization},
pages = {154--175},
publisher = {Springer Berlin Heidelberg},
title = {{Visual analytics: Definition, process, and challenges}},
url = {http://link.springer.com/10.1007/978-3-540-70956-5{\_}7},
year = {2008}
}
@article{Aldrich2017,
author = {Aldrich, Garrett and Hyman, Jeffrey D. and Karra, Satish and Gable, Carl W. and Makedonska, Nataliia and Viswanathan, Hari and Woodring, Jonathan and Hamann, Bernd},
doi = {10.1109/TVCG.2016.2582174},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Aldrich et al. - 2017 - Analysis and visualization of discrete fracture networks using a flow topology graph.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {8},
pages = {1896--1909},
title = {{Analysis and visualization of discrete fracture networks using a flow topology graph}},
url = {http://ieeexplore.ieee.org/document/7494624/},
volume = {23},
year = {2017}
}
@article{Turkay2017,
abstract = {Good paper as example for multivariate tool. Emphasizes the importance of algorithms with combination of human interaction aid.},
author = {Turkay, Cagatay and Kaya, Erdem and Balcisoy, Selim and Hauser, Helwig},
doi = {10.1109/TVCG.2016.2598470},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Turkay et al. - 2017 - Designing progressive and interactive analytics processes for high-dimensional data analysis.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Progressive analytics,high dimensional data,iterative refinement,visual analytics},
number = {1},
pages = {131--140},
title = {{Designing progressive and interactive analytics processes for high-dimensional data analysis}},
volume = {23},
year = {2017}
}
@article{Wu2017,
abstract = {{\textcopyright} 2016 IEEE.Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies.},
author = {Wu, Yanhong and Cao, Nan and Archambault, Daniel and Shen, Qiaomu and Qu, Huamin and Cui, Weiwei},
doi = {10.1109/TVCG.2016.2598867},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Wu et al. - 2017 - Evaluation of graph sampling A visualization perspective.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Graph visualization,empirical evaluation,graph sampling},
number = {1},
pages = {401--410},
title = {{Evaluation of graph sampling: A visualization perspective}},
volume = {23},
year = {2017}
}
@article{Yao2017,
abstract = {Manga are a popular artistic form around the world, and artists use simple line drawing and screentone to create all kinds of interesting productions. Vectorization is helpful to digitally reproduce these elements for proper content and intention delivery on electronic devices. Therefore, this study aims at transforming scanned Manga to a vector representation for interactive manipulation and real-time rendering with arbitrary resolution. Our system first decomposes the patch into rough Manga elements including possible borders and shading regions using adaptive binarization and screentone detector. We classify detected screentone into simple and complex patterns: our system extracts simple screentone properties for refining screentone borders, estimating lighting, compensating missing strokes inside screentone regions, and later resolution independently rendering with our procedural shaders. Our system treats the others as complex screentone areas and vectorizes them with our proposed line tracer which aims at locating boundaries of all shading regions and polishing all shading borders with the curve-based Gaussian refiner. A user can lay down simple scribbles to cluster Manga elements intuitively for the formation of semantic components, and our system vectorizes these components into shading meshes along with embedded BÂ´ ezier curves as a unified foundation for consistent manipulation including pattern manipulation, deformation, and lighting addition. Our system can real-time and resolution independently render the shading regions with our procedural shaders and drawing borders with the curve-based shader. For Manga manipulation, the proposed vector representation can be not only magnified without artifacts but also deformed easily to generate interesting results.},
author = {Yao, Chih Yuan and Hung, Shih Hsuan and Li, Guo Wei and Chen, I. Yu and Adhitya, Reza and Lai, Yu Chi},
doi = {10.1109/TVCG.2016.2525774},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Yao et al. - 2017 - Manga vectorization and manipulation with procedural simple screentone.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Manga,procedural shaders,screentone,semantic components,vectorization},
number = {2},
pages = {1070--1084},
title = {{Manga vectorization and manipulation with procedural simple screentone}},
volume = {23},
year = {2017}
}
@inproceedings{Sawada2017,
address = {Yokohama, Japan},
author = {Sawada, Naoko and Nakayama, Masanori and Wu, Hsiang-Yun and Uemura, Makoto and Fujishiro, Issei},
booktitle = {Proceedings of the Computer Graphics International Conference},
doi = {10.1145/3095140.3095154},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Sawada et al. - 2017 - TimeTubes Visual fusion and validation for ameliorating uncertainties of blazar datasets from different observato.pdf:pdf},
isbn = {9781450352284},
keywords = {Visualization,Visualization design and evaluation methods,Visualization toolkits,acm reference format,astrophysics,blazar,time-varying multivariate visualization,uncertainty visualization,â¢Human-centered computing  Information visualizati},
pages = {14:1--14:6},
title = {{TimeTubes: Visual fusion and validation for ameliorating uncertainties of blazar datasets from different observatories}},
year = {2017}
}
@article{Byrne2016,
abstract = {While information visualization frameworks and heuristics have traditionally been reluctant to include acquired codes of meaning, designers are making use of them in a wide variety of ways. Acquired codes leverage a user's experience to understand the meaning of a visualization. They range from figurative visualizations which rely on the reader's recognition of shapes, to conventional arrangements of graphic elements which represent particular subjects. In this study, we used content analysis to codify acquired meaning in visualization. We applied the content analysis to a set of infographics and data visualizations which are exemplars of innovative and effective design. 88{\%} of the infographics and 71{\%} of data visualizations in the sample contain at least one use of figurative visualization. Conventions on the arrangement of graphics are also widespread in the sample. In particular, a comparison of representations of time and other quantitative data showed that conventions can be specific to a subject. These results suggest that there is a need for information visualization research to expand its scope beyond perceptual channels, to include social and culturally constructed meaning. Our paper demonstrates a viable method for identifying figurative techniques and graphic conventions and integrating them into heuristics for visualization design.},
author = {Byrne, Lydia and Angus, Daniel and Wiles, Janet},
doi = {10.1109/TVCG.2015.2467321},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Byrne, Angus, Wiles - 2016 - Acquired codes of meaning in data visualization and infographics Beyond perceptual primitives.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Context,Data visualization,Encoding,Image color analysis,Shape,Visualization},
number = {1},
pages = {509--518},
pmid = {26529716},
title = {{Acquired codes of meaning in data visualization and infographics: Beyond perceptual primitives}},
volume = {22},
year = {2016}
}
@article{Glueck2017,
abstract = {Cross-sectional phenotype studies are used by genetics researchers to better understand how phenotypes vary across patients with genetic diseases, both within and between cohorts. Analyses within cohorts identify patterns between phenotypes and patients (e.g., co-occurrence) and isolate special cases (e.g., potential outliers). Comparing the variation of phenotypes between two cohorts can help distinguish how different factors affect disease manifestation (e.g., causal genes, age of onset, etc.). PhenoStacks is a novel visual analytics tool that supports the exploration of phenotype variation within and between cross-sectional patient cohorts. By leveraging the semantic hierarchy of the Human Phenotype Ontology, phenotypes are presented in context, can be grouped and clustered, and are summarized via overviews to support the exploration of phenotype distributions. The design of PhenoStacks was motivated by formative interviews with genetics researchers: we distil high-level tasks, present an algorithm for simplifying ontology topologies for visualization, and report the results of a deployment evaluation with four expert genetics researchers. The results suggest that PhenoStacks can help identify phenotype patterns, investigate data quality issues, and inform data collection design.},
author = {Glueck, Michael and Gvozdik, Alina and Chevalier, Fanny and Khan, Azam and Brudno, Michael and Wigdor, Daniel},
doi = {10.1109/TVCG.2016.2598469},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Glueck et al. - 2017 - PhenoStacks Cross-sectional cohort phenotype comparison visualizations.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Cross-sectional cohort analysis,Human Phenotype Ontology (HPO),Phenotypes},
number = {1},
pages = {191--200},
pmid = {27514055},
title = {{PhenoStacks: Cross-sectional cohort phenotype comparison visualizations}},
volume = {23},
year = {2017}
}
@article{Fulda2016,
abstract = {We present TimeLineCurator, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With TimeLineCurator, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. TimeLineCurator provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate TimeLineCurator through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment.},
author = {Fulda, Johanna and Brehmel, Matthew and Munzner, Tamara},
doi = {10.1109/TVCG.2015.2467531},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Fulda, Brehmel, Munzner - 2016 - TimeLineCurator Interactive authoring of visual timelines from unstructured text.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Context,Data mining,Data visualization,Manuals,Natural language processing,Pipelines,Visualization},
number = {1},
pages = {300--309},
pmid = {26529709},
title = {{TimeLineCurator: Interactive authoring of visual timelines from unstructured text}},
volume = {22},
year = {2016}
}
@article{Glueck2016,
abstract = {The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting.},
author = {Glueck, Michael and Hamilton, Peter and Chevalier, Fanny and Breslav, Simon and Khan, Azam and Wigdor, Daniel and Brudno, Michael},
doi = {10.1109/TVCG.2015.2467733},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Glueck et al. - 2016 - PhenoBlocks Phenotype comparison visualizations.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Bioinformatics,Data visualization,Diseases,Medical diagnostic imaging,Ontologies,Semantics},
number = {1},
pages = {101--110},
pmid = {26529691},
title = {{PhenoBlocks: Phenotype comparison visualizations}},
volume = {22},
year = {2016}
}
@article{Quinan2016,
abstract = {Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data.},
author = {Quinan, P. Samuel and Meyer, Miriah},
doi = {10.1109/TVCG.2015.2467754},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Quinan, Meyer - 2016 - Visually comparing weather features in forecasts.pdf:pdf},
isbn = {1077-2626 VO - 22},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Color,Data visualization,Encoding,Image color analysis,Predictive models,Weather forecasting},
number = {1},
pages = {389--398},
title = {{Visually comparing weather features in forecasts}},
volume = {22},
year = {2016}
}
@article{Wu2016,
abstract = {Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.},
author = {Wu, Wenchao and Xu, Jiayi and Zeng, Haipeng and Zheng, Yixian and Qu, Huamin and Ni, Bing and Yuan, Mingxuan and Ni, Lionel M.},
doi = {10.1109/TVCG.2015.2467194},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Wu et al. - 2016 - TelCoVis Visual exploration of co-occurrence in urban human mobility based on telco data.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Correlation,Data mining,Data visualization,Mobile handsets,Sociology,Visual analytics},
number = {1},
pages = {935--944},
pmid = {26469282},
title = {{TelCoVis: Visual exploration of co-occurrence in urban human mobility based on telco data}},
volume = {22},
year = {2016}
}
@article{Alexander2016,
abstract = {Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model's performance on the analyst's intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity.},
author = {Alexander, Eric and Gleicher, Michael},
doi = {10.1109/TVCG.2015.2467618},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Alexander, Gleicher - 2016 - Task-driven comparison of topic models.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Analytical models,Color,Computational modeling,Encoding,Measurement,Numerical models,Visualization},
number = {1},
pages = {320--329},
pmid = {26340780},
title = {{Task-driven comparison of topic models}},
volume = {22},
year = {2016}
}
@article{Gu2016,
abstract = {A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach.},
author = {Gu, Yi and Wang, Chaoli and Peterka, Tom and Jacob, Robert and Kim, Seung Hyun},
doi = {10.1109/TVCG.2015.2468031},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Gu et al. - 2016 - Mining graphs for understanding time-varying volumetric data.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Connectors,Data mining,Data visualization,Fans,Feature extraction,Layout,Visualization},
number = {1},
pages = {965--974},
pmid = {26529740},
title = {{Mining graphs for understanding time-varying volumetric data}},
volume = {22},
year = {2016}
}
@article{Neuroth2016,
author = {Neuroth, Tyson and Sauer, Franz and Wang, Weixing and Ethier, Stephane and Chang, Choong-Seock and Ma, Kwan-Liu},
doi = {10.1109/TVCG.2016.2642103},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Neuroth et al. - 2016 - Scalable visualization of time-varying multi-parameter distributions using spatially organized histograms.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {8},
pages = {1--1},
title = {{Scalable visualization of time-varying multi-parameter distributions using spatially organized histograms}},
url = {http://ieeexplore.ieee.org/document/7792155/},
volume = {14},
year = {2016}
}
@article{Zhou2008,
author = {Zhou, Hong and Yuan, Xiaoru and Qu, Huamin and Cui, Weiwei and Chen, Baoquan},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Zhou et al. - 2008 - Visual clustering in parallel coordinates.pdf:pdf},
keywords = {clutter reduction,multi-,parallel coordinates,variate data visualization,visual clustering},
number = {3},
title = {{Visual clustering in parallel coordinates}},
volume = {27},
year = {2008}
}
@article{Correll,
author = {Correll, Michael and Heer, Jeffrey},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Correll, Heer - Unknown - Surprise ! Bayesian weighting for de-biasing thematic maps.pdf:pdf},
title = {{Surprise ! Bayesian weighting for de-biasing thematic maps}}
}
@article{Gramazio2017,
author = {Gramazio, Connor C and Member, Student and Laidlaw, David H and Schloss, Karen B},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Gramazio et al. - 2017 - Colorgorical Creating discriminable and preferable color palettes for information visualization.pdf:pdf},
number = {1},
pages = {521--530},
title = {{Colorgorical : Creating discriminable and preferable color palettes for information visualization}},
volume = {23},
year = {2017}
}
@article{Fang2017,
author = {Fang, H and Walton, S and Delahaye, E and Harris, J and Storchak, D A and Chen, M},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Fang et al. - 2017 - Categorical colormap optimization with visualization case studies.pdf:pdf},
number = {1},
pages = {871--880},
title = {{Categorical colormap optimization with visualization case studies}},
volume = {23},
year = {2017}
}
@article{Mcdonnell2008,
author = {Mcdonnell, K T and Mueller, K},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Mcdonnell, Mueller - 2008 - Illustrative parallel coordinates.pdf:pdf},
number = {3},
title = {{Illustrative parallel coordinates}},
volume = {27},
year = {2008}
}
@article{Palmas2014,
author = {Palmas, Gregorio},
doi = {10.1109/PacificVis.2014.40},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Palmas - 2014 - An edge-bundling layout for interactive parallel coordinates.pdf:pdf},
isbn = {9781479928736},
pages = {57--64},
title = {{An edge-bundling layout for interactive parallel coordinates}},
year = {2014}
}
@misc{,
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - JIEICE99-05.pdf(2).pdf:pdf},
title = {{JIEICE99-05.pdf}}
}
@article{Gerber2010,
abstract = {An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.},
author = {Gerber, Samuel and Bremer, Peer Timo and Pascucci, Valerio and Whitaker, Ross},
doi = {10.1109/TVCG.2010.213},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Gerber et al. - 2010 - Visual exploration of high dimensional scalar functions.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {High-dimensional visualization,Morse theory,Morse-Smale complex},
number = {6},
pages = {1271--1280},
pmid = {20975167},
title = {{Visual exploration of high dimensional scalar functions}},
volume = {16},
year = {2010}
}
@article{Ferstl2017,
author = {Ferstl, Florian and Kanzler, Mathias and Rautenhaus, Marc and Westermann, Rudiger},
doi = {10.1109/TVCG.2016.2598868},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Ferstl et al. - 2017 - Time-hierarchical clustering and visualization of weather forecast ensembles.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {jan},
number = {1},
pages = {831--840},
title = {{Time-hierarchical clustering and visualization of weather forecast ensembles}},
url = {http://ieeexplore.ieee.org/document/7539342/},
volume = {23},
year = {2017}
}
@article{Yi2007,
author = {Yi, Ji Soo and ah Kang, Youn and Stasko, John},
doi = {10.1109/TVCG.2007.70515},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Yi, Kang, Stasko - 2007 - Toward a deeper understanding of the role of interaction in information visualization.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {nov},
number = {6},
pages = {1224--1231},
title = {{Toward a deeper understanding of the role of interaction in information visualization}},
url = {http://ieeexplore.ieee.org/document/4376144/},
volume = {13},
year = {2007}
}
@article{Miller2007,
author = {Miller, James R.},
doi = {10.1109/MCG.2007.54},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Miller - 2007 - Attribute blocks Visualizing multiple continuously defined attributes.pdf:pdf},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
month = {may},
number = {3},
pages = {57--69},
title = {{Attribute blocks: Visualizing multiple continuously defined attributes}},
url = {http://ieeexplore.ieee.org/document/4178161/},
volume = {27},
year = {2007}
}
@incollection{Roberts2005,
abstract = {This chapter provides an overview of current multiple linked view tools, methodologies, and models, discusses related challenges and ideas, and provides some rudiments for coordination within a geovisualization context. Such multiple linked views (MLVs) enable the user to quickly view a scenario, compare it with previous realizations, examine properties such as dependencies and sizes, and put this view to one side and try out another scenario. There are many good principles that can be learned from examining the way other systems achieve this MLV exploration. In geovisualization, the explorer often generates many spatial or abstract representations. With such exploratory environments, the user is able (even encouraged) to take a hands-on approach to gain a deeper understanding of the underlying information and can also change various parameter values of a visualization system that in turn alters the appearance of the visual result. In addition, the user may generate additional windows that contain the visual result of the new parameters so they can compare different ideas side-by-side. Commonly these windows are linked together to allow further investigation and discovery, such as selection by brushing or combined navigation.},
annote = {three-way taxonomy of comparison},
author = {Roberts, Jonathan C.},
booktitle = {Exploring Geovisualization},
chapter = {8},
doi = {10.1016/B978-008044531-1/50426-7},
editor = {Dykes, Jason and MacEachren, Alan M. and Kraak, Menno-Jan},
isbn = {9780080445311},
pages = {159--180},
publisher = {Elsevier},
title = {{Exploratory visualization with multiple linked views}},
url = {http://www.sciencedirect.com/science/article/pii/B9780080445311504267},
year = {2005}
}
@article{VivekVerma2004,
annote = {three-way taxonomy of comparison},
author = {{Vivek Verma} and Pang, A.},
doi = {10.1109/TVCG.2004.39},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Vivek Verma, Pang - 2004 - Comparative flow visualization.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {nov},
number = {6},
pages = {609--624},
title = {{Comparative flow visualization}},
url = {http://ieeexplore.ieee.org/document/1333660/},
volume = {10},
year = {2004}
}
@inproceedings{Shen1998,
annote = {three-way taxonomy of comparison},
author = {Shen, Qin and Pang, Alex and Uselton, Sam},
booktitle = {Proceedings of the conference on Visualization '98},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Shen, Pang, Uselton - 1998 - Data level comparison of wind tunnel and computational fluid dynamics data.pdf:pdf},
isbn = {1581131062},
pages = {415--418},
publisher = {IEEE Computer Society Press},
title = {{Data level comparison of wind tunnel and computational fluid dynamics data}},
url = {http://dl.acm.org/citation.cfm?id=288333{\&}CFID=889420413{\&}CFTOKEN=59982815},
year = {1998}
}
@inproceedings{Amenta,
author = {Amenta, N. and Klingner, J.},
booktitle = {IEEE Symposium on Information Visualization, 2002. INFOVIS 2002.},
doi = {10.1109/INFVIS.2002.1173150},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Amenta, Klingner - Unknown - Case study Visualizing sets of evolutionary trees.pdf:pdf},
isbn = {0-7695-1751-X},
pages = {71--74},
publisher = {IEEE Comput. Soc},
title = {{Case study: Visualizing sets of evolutionary trees}},
url = {http://ieeexplore.ieee.org/document/1173150/}
}
@inproceedings{Jerding,
author = {Jerding, D.F. and Stasko, J.T.},
booktitle = {Proceedings of Visualization 1995 Conference},
doi = {10.1109/INFVIS.1995.528685},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Jerding, Stasko - Unknown - The information mural a technique for displaying and navigating large information spaces.pdf:pdf},
isbn = {0-8186-7201-3},
pages = {43--50,},
publisher = {IEEE Comput. Soc. Press},
title = {{The information mural: a technique for displaying and navigating large information spaces}},
url = {http://ieeexplore.ieee.org/document/528685/}
}
@article{Mansmann2007,
author = {Mansmann, Florian and Keim, Daniel A. and North, Stephen C. and Rexroad, Brian and Sheleheda, Daniel},
doi = {10.1109/TVCG.2007.70522},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Mansmann et al. - 2007 - Visual analysis of network traffic for resource planning, interactive monitoring, and interpretation of securit.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {nov},
number = {6},
pages = {1105--1112},
title = {{Visual analysis of network traffic for resource planning, interactive monitoring, and interpretation of security threats}},
url = {http://ieeexplore.ieee.org/document/4376129/},
volume = {13},
year = {2007}
}
@article{Huerta-Cepas2010,
abstract = {Many bioinformatics analyses, ranging from gene clustering to phylogenetics, produce hierarchical trees as their main result. These are used to represent the relationships among different biological entities, thus facilitating their analysis and interpretation. A number of standalone programs are available that focus on tree visualization or that perform specific analyses on them. However, such applications are rarely suitable for large-scale surveys, in which a higher level of automation is required. Currently, many genome-wide analyses rely on tree-like data representation and hence there is a growing need for scalable tools to handle tree structures at large scale.},
author = {Huerta-Cepas, Jaime and Dopazo, Joaqu{\'{i}}n and Gabald{\'{o}}n, Toni},
doi = {10.1186/1471-2105-11-24},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Huerta-Cepas, Dopazo, Gabald{\'{o}}n - 2010 - ETE a python environment for tree exploration.pdf:pdf},
journal = {BMC Bioinformatics},
number = {1},
pages = {24},
publisher = {BioMed Central},
title = {{ETE: a python environment for tree exploration}},
url = {http://dx.doi.org/10.1186/1471-2105-11-24},
volume = {11},
year = {2010}
}
@inproceedings{Bendix,
author = {Bendix, F. and Kosara, R. and Hauser, H.},
booktitle = {IEEE Symposium on Information Visualization, 2005. INFOVIS 2005.},
doi = {10.1109/INFVIS.2005.1532139},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Bendix, Kosara, Hauser - Unknown - Parallel sets Visual analysis of categorical data.pdf:pdf},
isbn = {0-7803-9464-X},
pages = {133--140},
publisher = {IEEE},
title = {{Parallel sets: Visual analysis of categorical data}},
url = {http://ieeexplore.ieee.org/document/1532139/}
}
@article{White2004,
author = {White, Daniel R. and Joy, Mike S.},
doi = {10.1145/1086339.1086341},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/White, Joy - 2004 - Sentence-based natural language plagiarism detection.pdf:pdf},
issn = {15314278},
journal = {Journal on Educational Resources in Computing},
keywords = {Natural language,plagiarism detection},
month = {dec},
number = {4},
pages = {1--20},
publisher = {ACM},
title = {{Sentence-based natural language plagiarism detection}},
url = {http://portal.acm.org/citation.cfm?doid=1086339.1086341},
volume = {4},
year = {2004}
}
@article{Engels2006,
author = {Engels, R. and Yu, T. and Burge, C. and Mesirov, J. P. and DeCaprio, D. and Galagan, J. E.},
doi = {10.1093/bioinformatics/btl193},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Engels et al. - 2006 - Combo a whole genome comparative browser.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jul},
number = {14},
pages = {1782--1783},
publisher = {Oxford University Press},
title = {{Combo: a whole genome comparative browser}},
url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btl193},
volume = {22},
year = {2006}
}
@inproceedings{Andrews2009,
author = {Andrews, Keith and Wohlfahrt, Martin and Wurzinger, Gerhard},
booktitle = {2009 13th International Conference Information Visualisation},
doi = {10.1109/IV.2009.108},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Andrews, Wohlfahrt, Wurzinger - 2009 - Visual graph comparison.pdf:pdf},
month = {jul},
pages = {62--67},
publisher = {IEEE},
title = {{Visual graph comparison}},
url = {http://ieeexplore.ieee.org/document/5190876/},
year = {2009}
}
@article{Meyer2009,
author = {Meyer, M. and Munzner, T. and Pfister, H.},
doi = {10.1109/TVCG.2009.167},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Meyer, Munzner, Pfister - 2009 - MizBee A multiscale synteny browser.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {nov},
number = {6},
pages = {897--904},
title = {{MizBee: A multiscale synteny browser}},
url = {http://ieeexplore.ieee.org/document/5290692/},
volume = {15},
year = {2009}
}
@inproceedings{Freire2008,
abstract = {Programming assignments are easy to plagiarize in such a way as to foil casual reading by graders. Graders can resort to automatic plagiarism detection systems, which can gen-erate a " distance " matrix that covers all possible pairings. Most plagiarism detection programs then present this infor-mation as a simple ranked list, losing valuable information in the process. The Ac system uses the whole distance matrix to pro-vide graders with multiple linked visualizations. The graph representation can be used to explore clusters of highly re-lated submissions at different filtering levels. The histogram representation presents compact " individual " histograms for each submission, complementing the graph representation in aiding graders during analysis. Although Ac's visualizations were developed with plagia-rism detection in mind, they should also prove effective to visualize distance matrices from other domains, as demon-strated by preliminary experiments.},
author = {Freire, Manuel},
booktitle = {Proceedings of the Working Conference on Advanced Visual Interfaces},
doi = {10.1145/1385569.1385644},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Freire - 2008 - Visualizing program similarity in the AC plagiarism detection system.pdf:pdf},
keywords = {Design Keywords Software plagiarism,G22 [Graph Theory],K32 [Computer and Information Science Education],Visualization,[Com-puter science education],[GUI,[Graph algorithms] General Terms Algorithms,interaction styles]},
pages = {404--407},
publisher = {ACM},
title = {{Visualizing program similarity in the AC plagiarism detection system}},
url = {http://delivery.acm.org/10.1145/1390000/1385644/p404-freire.pdf?ip=131.113.67.5{\&}id=1385644{\&}acc=ACTIVE SERVICE{\&}key=D2341B890AD12BFE.3544E7C56679C917.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}CFID=929581369{\&}CFTOKEN=60622888{\&}{\_}{\_}acm{\_}{\_}=1493348482{\_}952c77f4ca9205c1f506bf},
year = {2008}
}
@article{Procter2010,
abstract = {Tree and sequence alignment visualizations have a long history. Evolutionary tree diagrams can be found in even the earliest descriptions of evolution, and their visualization still plays a key role in modern phyloge-netics. However, although trees visualize an organism's evolutionary history, it is the biological data used in their construction that contains the information that distinguishes each organism. Sequence alignments are the most common data used in phylogenetic analysis, and their visualization assists in understanding the molecular mechanisms that differentiate each species, down to the level of the individual nucleotide bases and amino acids. Many tools for tree and sequence alignment visualiza-tion have been developed in the last 20 years, and a com-prehensive analysis is beyond the scope of this review. Instead, we describe the main visualization approaches found in a selection of applications that are available at present (Tables 1 and 2), and that we consider either to be widely used or to represent a significant contribution to each field. We also highlight important capabilities and drawbacks for each tool, but since many are under active development, we urge the user to explore a tool's capabilities for themselves. Several functions can be found among the tree and alignment visualization tools we consider here: 'ren-derers' generate static figures, 'viewers' allow interac-tive display and analysis, and 'workbenches' provide a complete environment for creation, visualization, editing, annotation and analysis. Some tools are more specialized and provide functions essential for edit-ing and analyzing alignments or working with RNA (Table 1) or allow the user to map other kinds of bio-logical data ('Annotators', Table 2). Sequence databaSe SearcheS Many sequence analysis exercises begin by using a search tool such as BLAST 1 . These tools use fast alignment methods to compare a query sequence against a library of potential sequence or sequence-family matches. The result is a ranked list of queryâhit alignments, each with an associated alignment score and estimate of the signifi-cance of the match. The user is then tasked with examin-ing this list, to identify the alignments relevant to their investigation for use in the next stage of the analysis. Probably the most widely used visualization tool for sequence database search results is the BLAST viewer 2 at the US National Center for Biotechnology Information (NCBI) website. This web-based system has its roots in the textual report generated by BLAST search tools. However, the main advantage of this viewer is that it pro-vides a summary diagram that gives a bird's-eye view of the aligned positions of each hit on the query sequence. Each hit is colored by the bit score for its match to the query to indicate alignment quality, and a hyperlink takes the viewer to the pairwise alignment, enabling},
annote = {éºä¼éå},
author = {Procter, James B and Thompson, Julie and Letunic, Ivica and Creevey, Chris and Jossinet, Fabrice and Barton, Geoffrey J},
doi = {10.1038/NmETH.1434},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Procter et al. - 2010 - Visualization of multiple alignments, phylogenies and gene family evolution.pdf:pdf},
journal = {Nature Publishing Group},
title = {{Visualization of multiple alignments, phylogenies and gene family evolution}},
url = {https://mipt.ru/dbmp/upload/f1f/Procter-arphlf4516u.pdf},
volume = {7},
year = {2010}
}
@article{Holten2008,
annote = {éå±¤çãªãã¼ã¿ã®æ¯è¼},
author = {Holten, Danny and van Wijk, Jarke J.},
doi = {10.1111/j.1467-8659.2008.01205.x},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Holten, van Wijk - 2008 - Visual comparison of hierarchically organized data.pdf:pdf},
issn = {01677055},
journal = {Computer Graphics Forum},
keywords = {I.3.3 [Computer Graphics]: Viewing Algorithms I.3},
month = {may},
number = {3},
pages = {759--766},
publisher = {Blackwell Publishing Ltd},
title = {{Visual comparison of hierarchically organized data}},
url = {http://doi.wiley.com/10.1111/j.1467-8659.2008.01205.x},
volume = {27},
year = {2008}
}
@article{Munzner2003,
abstract = {Structural comparison of large trees is a difficult task that is only partially supported by current visualization techniques, which are mainly designed for browsing. We present TreeJuxtaposer, a sys-tem designed to support the comparison task for large trees of sev-eral hundred thousand nodes. We introduce the idea of " guaran-teed visibility " , where highlighted areas are treated as landmarks that must remain visually apparent at all times. We propose a new methodology for detailed structural comparison between two trees and provide a new nearly-linear algorithm for computing the best corresponding node from one tree to another. In addition, we present a new rectilinear Focus+Context technique for navigation that is well suited to the dynamic linking of side-by-side views while guaranteeing landmark visibility and constant frame rates. These three contributions result in a system delivering a fluid ex-ploration experience that scales both in the size of the dataset and the number of pixels in the display. We have based the design deci-sions for our system on the needs of a target audience of biologists who must understand the structural details of many phylogenetic, or evolutionary, trees. Our tool is also useful in many other ap-plication domains where tree comparison is needed, ranging from network management to call graph optimization to genealogy.},
annote = {å¤éºä¼å­æ¨ã®æ¯è¼},
author = {Munzner, Tamara and Ere, Fran{\c{c}}oisGuimbret{\`{i}} and Tasiran, Serdar and Zhang, Li and Zhou, Yunhong},
doi = {10.1145/882262.882291},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Munzner et al. - 2003 - TreeJuxtaposer Scalable tree comparison using focuscontext with guaranteed visibility.pdf:pdf},
journal = {ACM Transactions on Graphics},
keywords = {CR Categories,Focus+Context,I36 [Computer Graphics],information visualization,phylogenetic tree,realtime rendering,tree drawing},
number = {3},
pages = {453--462},
title = {{TreeJuxtaposer: Scalable tree comparison using focus+context with guaranteed visibility}},
url = {http://delivery.acm.org/10.1145/890000/882291/p453-munzner.pdf?ip=131.113.67.5{\&}id=882291{\&}acc=ACTIVE SERVICE{\&}key=D2341B890AD12BFE.3544E7C56679C917.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}CFID=929581369{\&}CFTOKEN=60622888{\&}{\_}{\_}acm{\_}{\_}=1493345818{\_}d183e9004115583427bf86da},
volume = {22},
year = {2003}
}
@article{Gleicher2011,
annote = {è¦è¦çãªæ¯è¼ã«é¢ããè«æ
juxtaposition, superposition, explicit encoding(explicit representation of the relationshipsãé¢ä¿ãè¡¨ç¾)ã®ä¸ã¤ã«å¤§åããã
juxtaposition: ã¦ã¼ã¶ã®è¨æ¶ã«ãã£ã¦ãé¢é£ãç¢ºããããé¢é£ã¯å¯è¦åããã¦ããªã
superposition: è¦è¦ã·ã¹ãã ã«ãã£ã¦é¢é£ãè¦èªå¯è½ãå¯è¦åçµæãè¿æ¥ãããã¨ã§é¢é£ãã¨ã³ã³ã¼ã
explicit encoding: è¨ç®ã«ãã£ã¦é¢é£æ§ãæ±ºå®ãè¦è¦çã¨ã³ã³ã¼ãã£ã³ã°
Juxtaposition+explicit encoding: ä¸è´ããé¨åããã¤ã©ã¤ãããããããããå¼·èª¿ããããã«é¢é£ãæ¸ã
Superposition+explicit encoding: clutterå¯¾ç­ã«æå¹ãã°ã©ãã®éããæç¤ºã§ãã},
author = {Gleicher, Michael and Albers, Danielle and Walker, Rick and Jusufi, Ilir and Hansen, Charles D and Roberts, Jonathan C},
doi = {10.1177/1473871611416549},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Gleicher et al. - 2011 - Visual comparison for information visualization.pdf:pdf},
isbn = {1473-8716},
journal = {Information Visualization},
keywords = {comparison,survey,taxonomy},
number = {4},
pages = {289--309},
title = {{Visual comparison for information visualization}},
volume = {10},
year = {2011}
}
@article{Potter2006,
abstract = {The display of statistical information is ubiquitous in all fields of visual- ization. Whether aided by graphs, tables, plots, or integrated into the visualizations themselves, understanding the best way to convey statistical information is important. Highlighting the box plot, a survey of traditional methods for expressing specific sta- tistical characteristics of data is presented. Reviewing techniques for the expression of statistical measures will be increasingly important as data quality, confidence and uncertainty are becoming influential characteristics to integrate into visualizations.},
author = {Potter, Kristin},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Potter - 2006 - Methods for presenting statistical information The box plot.pdf:pdf},
journal = {Visualization of Large and Unstructured Data Sets},
pages = {97--106},
title = {{Methods for presenting statistical information: The box plot}},
volume = {S-4},
year = {2006}
}
@article{Schulz2017,
abstract = {We present a novel uncertain network visualization technique based on node-link diagrams. Nodes expand spatially in our probabilistic graph layout, depending on the underlying probability distributions of edges. The visualization is created by computing a two-dimensional graph embedding that combines samples from the probabilistic graph. A Monte Carlo process is used to decompose a probabilistic graph into its possible instances and to continue with our graph layout technique. Splatting and edge bundling are used to visualize point clouds and network topology. The results provide insights into probability distributions for the entire networkânot only for individual nodes and edges. We validate our approach using three data sets that represent a wide range of network types: synthetic data, proteinâprotein interactions from the STRING database, and travel times extracted from Google Maps. Our approach reveals general limitations of the force-directed layout and allows the user to recognize that some nodes of the graph are at a specific position just by chance.},
author = {Schulz, Christoph and Nocaj, Arlind and Goertler, Jochen and Deussen, Oliver and Brandes, Ulrik and Weiskopf, Daniel},
doi = {10.1109/TVCG.2016.2598919},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Schulz et al. - 2017 - Probabilistic graph layout for uncertain network visualization.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Monte Carlo method,Uncertainty visualization,edge bundling,graph layout,graph visualization},
number = {1},
pages = {531--540},
title = {{Probabilistic graph layout for uncertain network visualization}},
volume = {23},
year = {2017}
}
@article{Gr2010,
abstract = {In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrates simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represents simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employs linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provides in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making. Index},
author = {Gr, M Eduard},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Gr - 2010 - World Lines.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {6},
pages = {1458--1467},
title = {{World Lines}},
volume = {16},
year = {2010}
}
@article{Feng2010,
abstract = {Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets.},
author = {Feng, David and Kwock, Lester and Lee, Yueh and Taylor, Russell},
doi = {10.1109/TVCG.2010.176},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Feng et al. - 2010 - Matching visual saliency to confidence in plots of uncertain data.pdf:pdf},
isbn = {1077-2626 (Print)$\backslash$n1077-2626 (Linking)},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Uncertainty visualization,brushing,multivariate data,parallel coordinates,scatter plots},
number = {6},
pages = {980--989},
pmid = {20975135},
title = {{Matching visual saliency to confidence in plots of uncertain data}},
volume = {16},
year = {2010}
}
@article{Blumenstein2016,
author = {Blumenstein, Kerstin and Niederer, Christina and Wagner, Markus and Schmiedl, Grischa and Rind, Alexander and Aigner, Wolfgang},
doi = {10.1145/2993901.2993906},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Blumenstein et al. - 2016 - Evaluating Information Visualization on Mobile Devices.pdf:pdf},
isbn = {9781450348188},
journal = {Proceedings of the Beyond Time and Errors on Novel Evaluation Methods for Visualization - BELIV '16},
keywords = {evaluation,information visualization,mobile},
pages = {125--132},
title = {{Evaluating Information Visualization on Mobile Devices}},
url = {http://dl.acm.org/citation.cfm?doid=2993901.2993906},
year = {2016}
}
@inproceedings{Haroz2008,
abstract = {Though the mediums for visualization are limited, the potential dimensions of a dataset are not. In many areas of scientific study, understanding the correlations between those dimensions and their uncertainties is pivotal to mining useful information from a dataset. Obtaining this insight can necessitate visualizing the many relationships among temporal, spatial, and other dimensionalities of data and its uncertainties. We utilize multiple views for interactive dataset exploration and selection of important features, and we apply those techniques to the unique challenges of cosmological particle datasets. We show how interactivity and incorporation of multiple visualization techniques help overcome the problem of limited visualization dimensions and allow many types of uncertainty to be seen in correlation with other variables.},
author = {Haroz, Steve and Kwan-Liu, Ma and Heitmann, Katrin},
booktitle = {Proceedings of IEEE Pacific Visualisation Symposium},
doi = {10.1109/PACIFICVIS.2008.4475478},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Haroz, Kwan-Liu, Heitmann - 2008 - Multiple uncertainties in time-variant cosmological particle data.pdf:pdf},
isbn = {9781424419661},
keywords = {Cosmology,Parallel coordinates,Uncertainty visualization,Visualization applications},
pages = {207--214},
title = {{Multiple uncertainties in time-variant cosmological particle data}},
year = {2008}
}
@article{Burger2009,
author = {B{\"{u}}rger, Raphael and Hauser, Helwig},
doi = {10.1111/j.1467-8659.2009.01429.x},
file = {:Users/nsawada/Google Drive/Papers/Visualization of Multi-variate Scientific Data.pdf:pdf},
journal = {Computer Graphics Forum},
keywords = {tutorial},
number = {6},
pages = {1670--1690},
title = {{Visualization of multi-variate scientific data}},
volume = {28},
year = {2009}
}
@inproceedings{Havre2000,
abstract = {ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The ``river'' flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored ``currents'' flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events},
author = {Havre, Susan and Hetzler, Beth and Nowell, Lucy},
booktitle = {Proceedings of IEEE Symposium on Information Visualization},
doi = {10.1109/INFVIS.2000.885098},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Havre, Hetzler, Nowell - 2000 - ThemeRiver Visualizing theme changes over time.pdf:pdf},
isbn = {0-7695-0804-9},
issn = {1522-404X},
keywords = {Bars,Data visualization,Histograms,Prototypes,Rivers,Testing,ThemeRiver,USA Councils,Usability,data visualisation,document collection,document handling,prototype system,temporally associated documents,textual presentation,thematic variations,theme change visualization,timeline},
pages = {115--123},
title = {{ThemeRiver: Visualizing theme changes over time}},
year = {2000}
}
@article{Liu2013,
abstract = {Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.},
author = {Liu, Shixia and Wu, Yingcai and Wei, Enxun and Liu, Mengchen and Liu, Yang},
doi = {10.1109/TVCG.2013.196},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Liu et al. - 2013 - StoryFlow Tracking the evolution of stories.pdf:pdf},
isbn = {1077-2626 VO - 19},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Storylines,level-of-detail,optimization,story-telling visualization,user interactions},
number = {12},
pages = {2436--2445},
pmid = {24051810},
title = {{StoryFlow: Tracking the evolution of stories}},
volume = {19},
year = {2013}
}
@inproceedings{Rose2009,
abstract = {Sources of streaming information, such as news syndicates, publish information continuously. Information portals and news aggregators list the latest information from around the world enabling information consumers to easily identify events in the past 24 hours. The volume and velocity of these streams causes information from prior days to quickly vanish despite its utility in providing an informative context for interpreting new information. Few capabilities exist to support an individual attempting to identify or understand trends and changes from streaming information over time. The burden of retaining prior information and integrating with the new is left to the skills, determination, and discipline of each individual. In this paper we present a visual analytics system for linking essential content from information streams over time into dynamic stories that develop and change over multiple days. We describe particular challenges to the analysis of streaming information and present a fundamental visual representation for showing story change and evolution over time.},
author = {Rose, Stuart and Butner, Scott and Cowley, Wendy and Gregory, Michelle and Walker, Julia},
booktitle = {Proceedings of IEEE Symposium on Visual Analytics Science and Technology},
doi = {10.1109/VAST.2009.5333437},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Rose et al. - 2009 - Describing story evolution from dynamic information streams.pdf:pdf},
isbn = {9781424452835},
keywords = {H.3.1 [content analysis and indexing]: abstracting,H.3.3 [information search and retrieval]: informat,H.3.7 [digital libraries]: user issues,I.3.3 [computer graphics]: picture/image generatio},
pages = {99--106},
title = {{Describing story evolution from dynamic information streams}},
year = {2009}
}
@article{Johnson2003,
abstract = {The development of formal theoretical frameworks and the creation of new visual representations of error and uncertainty will be fundamental to a better understanding of 3D experimental and simulation data. Such improved understanding will validate new theoretical models, enable better understanding of data, and facilitate better decision making. We urge the scientific visualization research community to take the next step and make visually representing errors and uncertainties the norm rather than the exception.},
author = {Johnson, Chris R. and Sanderson, Allen R.},
doi = {10.1109/MCG.2003.1231171},
file = {:Users/nsawada/Google Drive/Papers/A Next Step Visualizing Errors and Uncertainty.pdf:pdf},
isbn = {0272-1716 VO - 23},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {5},
pages = {6--10},
pmid = {877907237988686168},
title = {{A next step: Visualizing errors and uncertainty}},
volume = {23},
year = {2003}
}
@inproceedings{Sanyal2009,
abstract = {Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4x4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization design. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.},
author = {Sanyal, Jibonananda and Zhang, Song and Bhattacharya, Gargi and Amburn, Phil and Moorhead, Robert J.},
booktitle = {IEEE Transactions on Visualization and Computer Graphics},
doi = {10.1109/TVCG.2009.114},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Sanyal et al. - 2009 - A user study to compare four uncertainty visualization methods for 1D and 2D datasets.pdf:pdf},
isbn = {1523040054738},
issn = {10772626},
keywords = {User study,uncertainty visualization},
month = {nov},
number = {6},
pages = {1209--1218},
pmid = {19834191},
title = {{A user study to compare four uncertainty visualization methods for 1D and 2D datasets}},
volume = {15},
year = {2009}
}
@article{Putten2002,
abstract = {In data mining applications, the availability of data is often a serious problem. For instance, elementary customer information resides in customer dat abases, but market survey data are only available for a subset of the customers or even for a different sample of customers. Data fusion provides a way out by combining information from different sources into a single data set for further data mining. While a significant amount of work has been done on data fusion in the past, most of the research has been performed outside of the data mining community. In this paper, we provide an overview of data fusion, introduce basic terminology and the statistical mat ching approach, distinguish between internal and external evaluation, and we conclude with a larger case study},
author = {Putten, Peter Van Der and Kok, Joost N. and Gupta, Amar},
doi = {10.2139/ssrn.297501},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Putten, Kok, Gupta - 2002 - Data fusion through statistical matching.pdf:pdf},
institution = {MIT Soan School of Management},
issn = {1556-5068},
journal = {MIT Sloan School of Management},
number = {Working Paper 4342-02},
pages = {13},
title = {{Data fusion through statistical matching}},
year = {2002}
}
@inproceedings{Hall1997,
abstract = {Multisensor data fusion is an emerging technology applied to Department of Defense (DoD) areas such as automated target recognition, battlefield surveillance, and guidance and control of autonomous vehicles, and to non-DoD applications such as monitoring of complex machinery, medical diagnosis, and smart buildings. Techniques for multisensor data fusion are drawn from a wide range of areas including artificial intelligence, pattern recognition, statistical estimation and other areas. This paper provides a tutorial on data fusion, introducing data fusion applications, process models, and identification of applicable techniques. Comments are made on the state-of-the-art in data fusion},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Hall, David L and Llinas, James},
booktitle = {Proceedings of the IEEE},
doi = {10.1109/5.554205},
eprint = {9605103},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Hall, Llinas - 1997 - An introduction to multisensor data fusion.pdf:pdf},
isbn = {0780344553},
issn = {00189219},
keywords = {Automatic control,Biomedical monitoring,Computerized monitoring,Condition monitoring,Department of Defense,DoD,Intelligent vehicles,Mobile robots,Navigation,Remotely operated vehicles,Surveillance,Target recognition,aerospace computing,artificial intelligence,automated target recognition,autonomous vehicles,battlefield surveillance,complex machinery,computerised instrumentation,control,emerging technology,guidance,identification,knowledge based methods,knowledge based systems,medical diagnosis,military computing,military systems,multisensor data fusion,nonlinearities,pattern recognition,process models,sensor fusion,smart buildings,statistical estimation},
number = {1},
pages = {6--23},
pmid = {21321613},
primaryClass = {cs},
title = {{An introduction to multisensor data fusion}},
volume = {85},
year = {1997}
}
@article{Gruendl2016,
abstract = {We present a natural extension of two-dimensional parallel-coordinates plots for revealing relationships in time-dependent multi-attribute data by building on the idea that time can be considered as the third dimension. A time slice through the visualization represents a certain point in time and can be viewed as a regular parallel-coordinates display. A vertical slice through one of the axes of the parallel-coordinates display would show a time-series plot. For a focus-and-context integration of both views, we embed time-series plots between two adjacent axes of the parallel-coordinates plot. Both time-series plots are drawn using a pseudo three-dimensional perspective with a single vanishing point. An independent parallel-coordinates panel that connects the two perspectively displayed time-series plots can move forward and backward in time to reveal changes in the relationship between the time-dependent attributes. The visualization of time-series plots in the context of the parallel- coordinates plot facilitates the exploration of time-related aspects of the data without the need to switch to a separate display. We provide a consistent set of tools for selecting and contrasting subsets of the data, which are important for various application domains.},
author = {Gruendl, Henning and Riehmann, Patrick and Pausch, Yves and Froehlich, Bernd},
doi = {10.1111/cgf.12908},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Gruendl et al. - 2016 - Time-series plots integrated in parallel-coordinates displays.pdf:pdf},
issn = {14678659},
journal = {Computer Graphics Forum},
keywords = {Categories and Subject Descriptors (according to A,I.3.3 [Computer Graphics]: Picture/Image Generatio},
number = {3},
pages = {321--330},
title = {{Time-series plots integrated in parallel-coordinates displays}},
volume = {35},
year = {2016}
}
@inproceedings{Kosara2004,
abstract = {Histograms are a very useful tool for data analysis, because they$\backslash$nshow the distribution of values over a data dimension. Many data$\backslash$nsets in engineering (like computational fluid dynamics, CFD), however,$\backslash$nare time-dependent. While standard histograms can certainly show$\backslash$nsuch data sets, they do not account for the special role time plays$\backslash$nin physical processes and our perception of the world. We present$\backslash$nTimeHistograms, which are an extension to standard histograms that$\backslash$ntake time into account. In several 2D and 3D views, the data is presented$\backslash$nin different ways that allow the user to understand different aspects$\backslash$nof the temporal development of a dimension. A number of interaction$\backslash$ntechniques are also provided to make best use of the display, and$\backslash$nto allow the user to brush in the histograms.},
author = {Kosara, Robert and Bendix, Fabian and Hauser, Helwig},
booktitle = {Proceedings of Joint Eurographics -- IEEE TCVG Symposium on Visualization},
doi = {10.1.1.2.4840},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Kosara, Bendix, Hauser - 2004 - TimeHistograms for large, time-dependent data.pdf:pdf},
isbn = {3-905673-07-X},
keywords = {visualization technique},
pages = {45--54},
title = {{TimeHistograms for large, time-dependent data}},
year = {2004}
}
@inproceedings{Barlow2004,
abstract = {In this paper, an uncommon use of parallel coordinates is illustrated$\backslash$nusing the Animator software. Animator is used to plot the parallel$\backslash$ncoordinates of objects in multi-dimensional space. Subsequently,$\backslash$nthe Animator software is used to animate the movement of individual$\backslash$nobjects, in this multi-dimensional space over time. Initial empirical$\backslash$nstudies of this technique for the visualization of data from Neurophysiological$\backslash$nresearch, multi-dimensional spike train datasets, have shown that$\backslash$nthe technique is useful. Thus, Animator was developed for public$\backslash$naccess and is now freely available (including source code) from the$\backslash$nVisualization Lab at the University of Plymouth, www.plymouth.ac.uk/infovis.},
author = {Barlow, N and Stuart, L.J.},
booktitle = {Proceedings of Eighth International Conference on Information Visualisation},
doi = {10.1109/IV.2004.1320222},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Barlow, Stuart - 2004 - Animator A tool for the animation of parallel coordinates.pdf:pdf},
isbn = {0-7695-2177-0},
issn = {1093-9547},
keywords = {visualization technique},
pages = {725--730},
title = {{Animator: A tool for the animation of parallel coordinates}},
year = {2004}
}
@inproceedings{Theron2006,
abstract = {Decade scale oceanic phenomena like El Nino are correlated with weather anomalies all over the globe. Only by understanding the events that produced the climatic conditions in the past will it be possible to forecast abrupt climate changes and prevent disastrous consequences for human beings and their environment. Paleoceanography research is a collaborative effort that requires the analysis of paleo time-series, which are obtained from a number of independent techniques and instruments and produced by a variety of different researchers and/or laboratories. The complexity of these phenomena that consist of massive, dynamic and often conflicting data can only be faced by means of analytical reasoning supported by a highly interactive visual interface. This paper presents an interactive visual analysis environment for paleoceanography that permits to gain insight into the paleodata and allow the control and steering of the analytical methods involved in the reconstruction of the climatic conditions of the past},
author = {Theron, Roberto},
booktitle = {Proceedings of 2006 IEEE Symposium On Visual Analytics Science And Technology},
doi = {10.1109/VAST.2006.261452},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Theron - 2006 - Visual analytics of paleoceanographic conditions.pdf:pdf},
isbn = {1424405912},
keywords = {Exploratory analysis,Infovis,Multiple linked views,Parallel coordinates},
pages = {19--26},
title = {{Visual analytics of paleoceanographic conditions}},
year = {2006}
}
@inproceedings{Potter2009,
abstract = {Scientists increasingly use ensemble data sets to explore relationships present in dynamic systems. Ensemble data sets combine spatio-temporal simulation results generated using multiple numerical models, sampled input conditions and perturbed parameters. While ensemble data sets are a powerful tool for mitigating uncertainty, they pose significant visualization and analysis challenges due to their complexity. In this article, we present Ensemble-Vis, a framework consisting of a collection of overview and statistical displays linked through a high level of interactivity. Ensemble-Vis allows scientists to gain key scientific insight into the distribution of simulation results as well as the uncertainty associated with the scientific data. In contrast to methods that present large amounts of diverse information in a single display, we argue that combining multiple linked displays yields a clearer presentation of the data and facilitates a greater level of visual data analysis. We demonstrate our framework using driving problems from climate modeling and meteorology and discuss generalizations to other fields.},
author = {Potter, Kristin and Wilson, Andrew and Bremer, Peer Timo and Williams, Dean and Doutriaux, Charles and Pascucci, Valerio and Johnson, Chris R.},
booktitle = {Proceedings of ICDM Workshops 2009 -- IEEE International Conference on Data Mining},
doi = {10.1109/ICDMW.2009.55},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Potter et al. - 2009 - Ensemble-vis A framework for the statistical visualization of ensemble data.pdf:pdf},
isbn = {9780769539027},
keywords = {Coordinated and linked views,Ensemble data,Statistical graphics,Uncertainty},
pages = {233--240},
title = {{Ensemble-vis: A framework for the statistical visualization of ensemble data}},
year = {2009}
}
@article{Li2007,
abstract = {Visualization of uncertainty or error in astrophysical data is seldom available in simulations of astronomical phenomena, and yet almost all rendered attributes possess some degree of uncertainty due to observational error. Uncertainties associated with spatial location typically vary significantly with scale and thus introduce further complexity in the interpretation of a given visualization. This paper introduces effective techniques for visualizing uncertainty in large-scale virtual astrophysical environments. Building upon our previous transparently scalable visualization architecture, we develop tools that enhance the perception and comprehension of uncertainty across wide scale ranges. Our methods include a unified color-coding scheme for representing log-scale distances and percentage errors, an ellipsoid model to represent positional uncertainty, an ellipsoid envelope model to expose trajectory uncertainty, and a magic-glass design supporting the selection of ranges of log-scale distance and uncertainty parameters, as well as an overview mode and a scalable WIM tool for exposing the magnitudes of spatial context and uncertainty.},
author = {Li, Hongwei and Fu, Chi-Wing and Li, Yinggang and Hanson, Andrew J.},
doi = {10.1109/TVCG.2007.70530},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2007 - Visualizing large-scale uncertainty in astrophysical data.pdf:pdf},
isbn = {10772626 (ISSN)},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Astronomy,Interstellar data,Large spatial scale,Uncertainty visualization},
number = {6},
pages = {1640--1647},
pmid = {17968120},
title = {{Visualizing large-scale uncertainty in astrophysical data}},
volume = {13},
year = {2007}
}
@article{Sanyal2010,
abstract = {Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single mid-troposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 "Superstorm". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95{\%} confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.},
author = {Sanyal, Jibonananda and Zhang, Song and Dyer, Jamie and Mercer, Andrew and Amburn, Philip and Moorhead, Robert J.},
doi = {10.1109/TVCG.2010.181},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Sanyal et al. - 2010 - Noodles A tool for visualization of numerical weather model ensemble uncertainty.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Uncertainty visualization,geographic/geospatial visualization,glyph-based techniques,qualitative evaluation,timevarying data,weather ensemble},
number = {6},
pages = {1421--1430},
pmid = {20975183},
title = {{Noodles: A tool for visualization of numerical weather model ensemble uncertainty}},
volume = {16},
year = {2010}
}
@inproceedings{Walsh2003,
author = {Walsh, K and Sirer, EG},
booktitle = {Proceedings of the 2003 Winter Simulation Conference},
doi = {10.1109/WSC.2003.1261490},
file = {:Users/nsawada/Google Drive/Papers/Visualization methods for time-dependent data - an overview.pdf:pdf},
pages = {737--745},
title = {{Visualization methods for time-dependent data - an overview}},
volume = {1},
year = {2003}
}
@article{Bonneau2014,
abstract = {{\textcopyright} Springer-Verlag London 2014. The goal of visualization is to effectively and accurately communicate data. Visualization research has often overlooked the errors and uncertainty which accompany the scientific process and describe key characteristics used to fully understand the data. The lack of these representations can be attributed, in part, to the inherent difficulty in defining, characterizing, and controlling this uncertainty, and in part, to the difficulty in including additional visual metaphors in a well designed, potent display. However, the exclusion of this information cripples the use of visualization as a decision making tool due to the fact that the display is no longer a true representation of the data. This systematic omission of uncertainty commands fundamental research within the visualization community to address, integrate, and expect uncertainty information. In this chapter, we outline sources and models of uncertainty, give an overview of the state-of-the-art, provide general guidelines, outline small exemplary applications, and finally, discuss open problems in uncertainty visualization.},
author = {Bonneau, Georges Pierre and Hege, Hans Christian and Johnson, Chris R. and Oliveira, Manuel M. and Potter, Kristin and Rheingans, Penny and Schultz, Thomas},
doi = {10.1007/978-1-4471-6497-5_1},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Bonneau et al. - 2014 - Overview and state-of-the-art of uncertainty visualization.pdf:pdf},
isbn = {1447164962},
issn = {2197666X},
journal = {Mathematics and Visualization},
pages = {3--27},
title = {{Overview and state-of-the-art of uncertainty visualization}},
volume = {37},
year = {2014}
}
@article{Bach2016,
author = {Bach, Benjamin and Shi, Conglei and Heulot, Nicolas and Madhyastha, Tara and Dragicevic, Pierre},
doi = {10.1109/TVCG.2015.2467851},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Bach et al. - 2016 - Time Curves Folding time to visualize patterns of temporal evolution in data.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {559--568},
title = {{Time Curves: Folding time to visualize patterns of temporal evolution in data}},
volume = {22},
year = {2016}
}
@article{Dutta2016,
abstract = {Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.},
annote = {ä»ã¾ã§ã®ç¹å¾´éæ¤åºã®ç ç©¶ã¯ãç¹å¾´ã®å®ç¾©ããããããå®ãããã¦ãã
ãã¼ã¿ã®æéçããã³ç©ºéçãªä¸è²«æ§ãå©ç¨ãã¦ãæ°è¦ã®åå¸é§ååç¹å¾´è¿½è·¡ã¢ã«ã´ãªãºã ãæ§ç¯ãã
Goal: æ­£ç¢ºãªãã£ã¼ãã£å®ç¾©ãå©ç¨ã§ããªãã¨ãã«ãå¤§è¦æ¨¡ãã¼ã¿ã®ãã£ã¼ãã£ãè¿½è·¡ãããã¨ãã§ããå¹ççãªã¢ã«ã´ãªãºã ãèæ¡ãããã¨

section3
ãã®ä½æ¥­ã«ãããæãã®é«ãç®æ¨ã¯ãæ­£ç¢ºãªãã£ã¼ãã£å®ç¾©ãå©ç¨ã§ããªãã¨ãã«ãå¤§è¦æ¨¡ãã¼ã¿ã®ãã£ã¼ãã£ãè¿½è·¡ãããã¨ãã§ããå¹ççãªã¢ã«ã´ãªãºã ãèæ¡ãããã¨ã§ãããç¹å¾´ãã¢ãã«åããããã«ã¬ã¦ã¹åå¸ï¼GMMï¼ã®æ··åãä½¿ç¨ãããã®ãããªç¹å¾´ã®æ½åºããã³è¿½è·¡ã®ããã®åå¸é§åæè¡ãä½¿ç¨ãããæãã¯ããã¼ã¿ããã­ãã¯ãã¨ã«ã¢ãã«åããåå¸ãGMMã®å½¢å¼ã§åãã­ãã¯ã«æ ¼ç´ãããå³1ã¯ãææ¡ãããã·ã¹ãã ã®æ¦ç¥å³ãç¤ºããæåã«ãé¢å¿å¯¾è±¡ã®ç¹å¾´ã¨ãã¦ãã¼ã¿åã®é åãä¸ããé¸æãããé åããã®ãã¼ã¿ãä½¿ç¨ãã¦ç¹å¾´GMMãæ§ç¯ãããã¾ããGMMã®ãã©ã¡ã¼ã¿ãæ®µéçã«å­¦ç¿ããåæ¯æ¨å®ã¢ã«ã´ãªãºã ãé©å¿ããã¦ãã­ãã¯åã®åãç©ä½ã®å­å¨ãå®éåãããã¨ã«ãã£ã¦ããã¹ã¦ã®ãã¼ã¿ãã­ãã¯ã®åå¸ãæ§ç¯ãããæ¬¡ã«ããã¼ã¿ã®ç©ºéçä¸è²«æ§ãå©ç¨ãã¦ããã­ãã¯ã®åå¸ããã£ã¼ãã£GMMã¨ç´æ¥æ¯è¼ãããã¨ã«ãã£ã¦ããã­ãã¯ããã£ã¼ãã£ã®ä¸é¨ã§ããå¯è½æ§ãè¨ç®ãã¾ããç¹å¾´ã®ä¸é¨ã¨ãã¦ã®ãã­ãã¯ã®æçµçãªå¯è½æ§ãæ¸¬å®ããããã«ã2ã¤ã®ã¿ã¤ãã®æ¨å®æå ±ãçµåãã¦ãç¹å¾´ã®é«ãåé¡é åãæ§æããé«ä¾¡å¤é åãã¦ã¼ã¶ã®é¢å¿ã®ããç¹å¾´ãå¼·èª¿ãããæå¾ã«ãåé¡ãã£ã¼ã«ããä½¿ç¨ããèªåè¿½è·¡æè¡ãå®æ¼ããå¯¾è©±åã®ããªã¥ã¼ã è¦è¦åæè¡ã«ãã£ã¦è¿½è·¡ãããç¹å¾´ã®é²åãæ¢ç´¢ããã},
author = {Dutta, Soumya and Shen, Han Wei},
doi = {10.1109/TVCG.2015.2467436},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Dutta, Shen - 2016 - Distribution driven extraction and tracking of features for time-varying data analysis.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Computational modeling,Data models,Data visualization,Estimation,Feature extraction,Target tracking},
number = {1},
pages = {837--846},
title = {{Distribution driven extraction and tracking of features for time-varying data analysis}},
volume = {22},
year = {2016}
}
@inproceedings{Shneiderman1996,
abstract = {A useful starting point for designing advanced graphical user$\backslash$ninterfaces is the visual information seeking Mantra: overview first,$\backslash$nzoom and filter, then details on demand. But this is only a starting$\backslash$npoint in trying to understand the rich and varied set of information$\backslash$nvisualizations that have been proposed in recent years. The paper offers$\backslash$na task by data type taxonomy with seven data types (one, two, three$\backslash$ndimensional data, temporal and multi dimensional data, and tree and$\backslash$nnetwork data) and seven tasks (overview, zoom, filter,$\backslash$ndetails-on-demand, relate, history, and extracts)},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Shneiderman, Ben.},
booktitle = {1996 IEEE Symposium on Visual Languages},
doi = {10.1109/VL.1996.545307},
eprint = {arXiv:1011.1669v3},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Shneiderman - 1996 - The eyes have it A task by data type taxonomy for information visualizations.pdf:pdf},
isbn = {0-8186-7508-X},
issn = {1049-2615},
keywords = {graphical user interfaces,information visualization,visualization},
pages = {336--343},
pmid = {4986861},
title = {{The eyes have it: A task by data type taxonomy for information visualizations}},
year = {1996}
}
@inproceedings{Viegas2004,
abstract = {The Internet has fostered an unconventional and powerful$\backslash$nstyle of collaboration: "wiki" web sites, where every visitor$\backslash$nhas the power to become an editor. In this paper we$\backslash$ninvestigate the dynamics of Wikipedia, a prominent, thriving$\backslash$nwiki. We make three contributions. First, we introduce a new$\backslash$nexploratory data analysis tool, the history flow visualization,$\backslash$nwhich is effective in revealing patterns within the wiki$\backslash$ncontext and which we believe will be useful in other$\backslash$ncollaborative situations as...},
author = {Vi{\'{e}}gas, Fernanda B. and Wattenberg, Martin and Dave, Kushal},
booktitle = {Proceedings of the 2004 conference on Human factors in computing systems},
doi = {10.1145/985692.985765},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Vi{\'{e}}gas, Wattenberg, Dave - 2004 - Studying cooperation and conflict between authors with history flow visualizations.pdf:pdf},
isbn = {1581137028},
issn = {1581137028},
keywords = {allowing users to change,categories,content of the page,edit this page,higher level of,link at the bottom,subject descriptors,the,this interface supports a},
number = {1},
pages = {575--582},
pmid = {363},
title = {{Studying cooperation and conflict between authors with history flow visualizations}},
volume = {6},
year = {2004}
}
@article{Hao2016,
abstract = {An ensemble is a collection of related datasets, called members, built from a series of runs of a simulation or an experiment. Ensembles are large, temporal, multidimensional, and multivariate, making them difficult to analyze. Another important challenge is visualizing ensembles that vary both in space and time. Initial visualization techniques displayed ensembles with a small number of members, or presented an overview of an entire ensemble, but without potentially important details. Recently, researchers have suggested combining these two directions, allowing users to choose subsets of members to visualization. This manual selection process places the burden on the user to identify which members to explore. We first introduce a static ensemble visualization system that automatically helps users locate interesting subsets of members to visualize. We next extend the system to support analysis and visualization of temporal ensembles. We employ 3D shape comparison, cluster tree visualization, and glyph based visualization to represent different levels of detail within an ensemble. This strategy is used to provide two approaches for temporal ensemble analysis: (1) segment based ensemble analysis, to capture important shape transition time-steps, clusters groups of similar members, and identify common shape changes over time across multiple members; and (2) time-step based ensemble analysis, which assumes ensemble members are aligned in time by combining similar shapes at common time-steps. Both approaches enable users to interactively visualize and analyze a temporal ensemble from different perspectives at different levels of detail. We demonstrate our techniques on an ensemble studying matter transition from hadronic gas to quark-gluon plasma during gold-on-gold particle collisions.},
author = {Hao, Lihua and Healey, Christopher G. and Bass, Steffen A.},
doi = {10.1109/TVCG.2015.2468093},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Hao, Healey, Bass - 2016 - Effective visualization of temporal ensembles.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data mining,Data visualization,Octrees,Shape,Shape measurement,Three-dimensional displays,Visualization},
number = {1},
pages = {787--796},
title = {{Effective visualization of temporal ensembles}},
volume = {22},
year = {2016}
}
@inproceedings{Wattenberg2002,
abstract = {This paper introduces a new visualization method, the arc diagram, which is capable of representing complex patterns of repetition in string data. Arc diagrams improve over previous methods such as dotplots because they scale efficiently for strings that contain many instances of the same subsequence. This paper describes design and implementation issues related to arc diagrams and shows how they may be applied to visualize such diverse data as music, text, and compiled code.},
author = {Wattenberg, Martin},
booktitle = {Proceedings of the IEEE Symposium on Information Visualization 2002},
doi = {10.1109/INFVIS.2002.1173155},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Wattenberg - 2002 - Arc diagrams Visualizing structure in strings.pdf:pdf},
isbn = {076951751X},
issn = {1522404X},
keywords = {Autocorrelation,Chaos,DNA,Data visualization,Displays,Frequency,Histograms,Image sequence analysis,Performance analysis,Pixel},
pages = {110--116},
title = {{Arc diagrams: Visualizing structure in strings}},
year = {2002}
}
@article{Chen2016,
author = {Chen, Mingcheng and Shadden, Shawn C. and Hart, John C.},
doi = {10.1109/TVCG.2015.2476795},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Chen, Shadden, Hart - 2016 - Fast coherent particle advection through time-varying unstructured flow datasets.pdf:pdf},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {GPU,Unsteady flow,parallel algorithms,unstructured mesh},
number = {8},
pages = {1959--1972},
title = {{Fast coherent particle advection through time-varying unstructured flow datasets}},
volume = {22},
year = {2016}
}
@article{Kondo2014,
abstract = {We introduce a new direct manipulation technique, DimpVis, for interacting with visual items in information visualizations to enable exploration of the time dimension. DimpVis is guided by visual hint paths which indicate how a selected data item changes through the time dimension in a visualization. Temporal navigation is controlled by manipulating any data item along its hint path. All other items are updated to reflect the new time. We demonstrate how the DimpVis technique can be designed to directly manipulate position, colour, and size in familiar visualizations such as bar charts and scatter plots, as a means for temporal navigation. We present results from a comparative evaluation, showing that the DimpVis technique was subjectively preferred and quantitatively competitive with the traditional time slider, and significantly faster than small multiples for a variety of tasks.},
annote = {æç³»åãã¼ã¿ãã¤ã³ã¿ã©ã¯ãã£ããªæä½ã§è§£æããæ¹æ³ã®è«æ},
author = {Kondo, Brittany and Collins, Christopher},
doi = {10.1109/TVCG.2014.2346250},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Kondo, Collins - 2014 - DimpVis Exploring time-varying information visualizations by direct manipulation.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Time navigation,direct manipulation,information visualization},
number = {12},
pages = {2003--2012},
title = {{DimpVis: Exploring time-varying information visualizations by direct manipulation}},
volume = {20},
year = {2014}
}
@article{Tatu2012,
abstract = {In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data. View full abstract},
author = {Tatu, Andrada and Maa{\ss}, Fabian and F{\"{a}}rber, Ines and Bertini, Enrico and Schreck, Tobias and Seidl, Thomas and Keim, Daniel},
doi = {10.1109/VAST.2012.6400488},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Tatu et al. - 2012 - Subspace search and visualization to make sense of alternative clusterings in high-dimensional data.pdf:pdf},
isbn = {9781467347532},
journal = {IEEE Conference on Visual Analytics Science and Technology 2012, VAST 2012 - Proceedings},
keywords = {H.2.8 [Database Applications]: Data mining,H.3.3 [Information Search and Retrieval]: Selectio,I.3.3 [Picture/Image Generation]: Display algorith},
number = {1},
pages = {63--72},
title = {{Subspace search and visualization to make sense of alternative clusterings in high-dimensional data}},
year = {2012}
}
@article{Ricci-Tersenghi2016,
abstract = {The problem of detecting communities in a graph is maybe one the most studied inference problems, given its simplicity and widespread diffusion among several disciplines. A very common benchmark for this problem is the stochastic block model or planted partition problem, where a phase transition takes place in the detection of the planted partition by changing the signal-to-noise ratio. Optimal algorithms for the detection exist which are based on spectral methods, but we show these are extremely sensible to slight modification in the generative model. Recently Javanmard, Montanari and Ricci-Tersenghi (arXiv:1511.08769) have used statistical physics arguments, and numerical simulations to show that finding communities in the stochastic block model via semidefinite programming is quasi optimal. Further, the resulting semidefinite relaxation can be solved efficiently, and is very robust with respect to changes in the generative model. In this paper we study in detail several practical aspects of this new algorithm based on semidefinite programming for the detection of the planted partition. The algorithm turns out to be very fast, allowing the solution of problems with {\$}O(10{\^{}}5){\$} variables in few second on a laptop computer.},
archivePrefix = {arXiv},
arxivId = {1603.09045},
author = {Ricci-Tersenghi, Federico and Javanmard, Adel and Montanari, Andrea},
doi = {10.1088/1742-6596/699/1/012015},
eprint = {1603.09045},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Ricci-Tersenghi, Javanmard, Montanari - 2016 - Performance of a community detection algorithm based on semidefinite programming.pdf:pdf},
issn = {1742-6588},
journal = {Journal of Physics: Conference Series},
pages = {012015},
title = {{Performance of a community detection algorithm based on semidefinite programming}},
volume = {699},
year = {2016}
}
@article{Senay1994,
abstract = {Vista is a knowledge-based system that helps scientists design visualization techniques. It generates a technique for a given data set and lets users modify the design interactively using a compositional design methodology. To ensure the effectiveness of its designs, Vista uses many rules, mostly heuristic in nature, that were acquired through literature surveys and discussions with visualization experts. In general, Vista's design was based on research in graphical perception. It extends the design methodology of Automatic Presentation Tool (APT) (J.D. Mckinlay, 1986), a presentation tool for 2D graphics, to three dimensions. While Vista's primary function is to automatically generate an effective visualization technique design for a given data set, it also allows users to interactively modify this design and renders the resulting image using a variety of rendering algorithms.},
author = {Senay, Hikmet and Ignatius, Eve},
doi = {10.1109/38.329093},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Senay, Ignatius - 1994 - A knowledge-based system for visualization design.pdf:pdf},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {6},
pages = {36--47},
title = {{A knowledge-based system for visualization design}},
volume = {14},
year = {1994}
}
@inproceedings{Foote1999,
abstract = {This paper presents a novel approach to visual- izing the time structure of music and audio. The acoustic similarity between any two instants of an audio recording is calculated and displayed as a two-dimensional representation. Similar or repeating elements are visually distinct, allow- ing identification of structural and rhythmic characteristics. Visualization examples are pre- sented for orchestral, jazz, and popular music. Applications include content-based analysis and segmentation, as well as tempo and struc- ture extraction.},
annote = {ããç¬éã®é³ã¨ã»ãã®ã¿ã¤ãã³ã°ã®é³ã®é¡ä¼¼åº¦ãè¡åå½¢å¼ã§å¯è¦å
é³æ¥½ã®æéæ¹åã®æ§é ãç¹å®},
archivePrefix = {arXiv},
arxivId = {arXiv:1304.2671v1},
author = {Foote, Jonathan},
booktitle = {Proceedings of the Seventh ACM International Conference on Multimedia (Part 1)},
doi = {10.1145/319463.319472},
eprint = {arXiv:1304.2671v1},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Foote - 1999 - Visualizing music and audio using self-similarity.pdf:pdf},
isbn = {1581131518},
issn = {00992240},
pages = {77--80},
pmid = {16348467},
title = {{Visualizing music and audio using self-similarity}},
year = {1999}
}
@article{Mitchell1997,
abstract = {The perspective tunnel, a general kind of information visualisation artefact, embodies a visual form which exploits natural human visual perception. Perspective tunnels map information on to the floor, ceiling and walls of a tunnel, so that both every item of data is visible and the visual field is used effectively. This maximises the effective use of screen real estate, with the potential of representing an infinite amount of data. In real terms, the visualisation of large amounts of information is achieved. A justification of the perspective tunnel's appropriateness is sought from the study of human visual perception. In addition, a selection of perspective tunnel visualisation techniques are presented.},
annote = {ç«æ¹ä½ã®å´é¢ã¨ãã«ãã¼ã¿ãã¯ã£ã¤ãã¦ãè¦éããããã¼ã¿ã®å¤åãå¯è¦åãã},
author = {Mitchell, Kenneth and Kennedy, Jessie},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Mitchell, Kennedy - 1997 - The perspective tunnel An inside view on smoothly integrating detail and context.pdf:pdf},
isbn = {3211830499},
journal = {Eurographics Workshop in Boulogne-sur-Mer},
title = {{The perspective tunnel: An inside view on smoothly integrating detail and context}},
year = {1997}
}
@article{Yuan2013,
abstract = {For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.},
author = {Yuan, Xiaoru and Ren, Donghao and Wang, Zuchao and Guo, Cong},
doi = {10.1109/tvcg.2013.150},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Yuan et al. - 2013 - Dimension projection matrix tree Interactive subspace visual exploration and analysis of high dimensional data.pdf:pdf},
isbn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {High dimensional data,hierarchical visualization,matrix,sub-dimensional space,subspace,tree,user interaction},
number = {12},
pages = {2625--2633},
title = {{Dimension projection matrix / tree : Interactive subspace visual exploration and analysis of high dimensional data}},
volume = {19},
year = {2013}
}
@article{Schroeder2016,
abstract = {We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more acces- sible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data âunderâ the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay âin the creative zoneâ as they work.},
annote = {æ°åãã¼ã¿ãªã©ããã¹ã±ããã¹ã¼ã¹ã§ããæãã«ãã¦ããã
é©å½ãªã«ã©ã¼ãããã«ãã¦ãããã},
author = {Schroeder, David and Keefe, Daniel F.},
doi = {10.1109/TVCG.2015.2467153},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Schroeder, Keefe - 2016 - Visualization-by-Sketching An artist's interface for creating multivariate time-varying data visualizations.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Brushes,Data visualization,Image color analysis,Painting,Paints,Visualization},
number = {1},
pages = {877--885},
pmid = {26529734},
title = {{Visualization-by-Sketching: An artist's interface for creating multivariate time-varying data visualizations}},
volume = {22},
year = {2016}
}
@article{Heinrich2013,
abstract = {This work presents a survey of the current state of the art of visualization techniques for parallel coordinates. It covers geometric models for constructing parallel coordinates and reviews methods for creating and understand- ing visual representations of parallel coordinates. The classification of these methods is based on a taxonomy that was established from the literature and is aimed at guiding researchers to find existing techniques and identifying white spots that require further research. The techniques covered in this survey are further related to an estab- lished taxonomy of knowledge-discovery tasks to support users of parallel coordinates in choosing a technique for their problem at hand. Finally, we discuss the challenges in constructing and understanding parallel-coordinates plots and provide some examples from different application domains.},
author = {Heinrich, J and Weiskopf, D},
doi = {10.2312/conf/EG2013/stars/095-116},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Heinrich, Weiskopf - 2013 - State of the art of parallel coordinates.pdf:pdf},
isbn = {1017-4656},
journal = {Eurographics 2013 - State of the Art Reports},
pages = {95--116},
title = {{State of the art of parallel coordinates}},
year = {2013}
}
@inproceedings{Tominski2012,
abstract = {Understanding how data evolves in space and time is an essential task in many application domains. Despite the numerous visual methods that have been proposed to facilitate this task (e.g., showing the data on a map or plotting a time graph), the exploration of data with references to space and time still remains challenging. In this work, we present a novel concept for visualizing spatio-temporal data that refer to 2D geographical space and 1D linear time. The idea is to construct a non-planar slice - called the Great Wall of Space-Time - through the 3D (2D+1D) space-time continuum. Different visual representations can be projected onto the wall in order to display the data. We illustrate data visualizations based on color-coding and parallel coordinates. Compared to existing approaches, the wall has the advantage that it shows a closed path through space with no gaps between the information-bearing pixels on the screen. Hence, our novel visualization has the potential to be a useful addition to the user's toolbox of techniques for exploring the spatial and temporal evolution of data.},
author = {Tominski, Christian and Schulz, Hans-J{\"{o}}rg},
booktitle = {Proceedings of the Workshop on Vision, Modeling, and Visualization},
doi = {10.2312/PE/VMV/VMV12/199-206},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Tominski, Schulz - 2012 - The Great Wall of space-time.pdf:pdf},
isbn = {9783905673951},
pages = {199--206},
title = {{The Great Wall of space-time}},
year = {2012}
}
@article{Buchin2014,
author = {Buchin, K. and Goethem, A. v. and Hoffmann, M. and Kreveld, M. v. and Speckmann, B.},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Buchin et al. - 2014 - Travel-time maps Linear cartograms with fixed vertex locations.pdf:pdf},
issn = {16113349},
journal = {Geographic Information Science},
number = {612},
pages = {18--33},
title = {{Travel-time maps: Linear cartograms with fixed vertex locations}},
volume = {LNCS 8728},
year = {2014}
}
@inproceedings{Daniel2003,
abstract = {Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for "summarizing" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing "relative" and "absolute" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.},
annote = {ãããªã®åå®¹ãè¦è¦çã«è¦ç´ãã
å¨ä½ãè¦éãã¦ãè¦ãã¹ãã¨ãããç¹å®ã§ãã},
author = {Daniel, Gareth and Chen, Min},
booktitle = {the IEEE Visualization Conference},
doi = {10.1109/VISUAL.2003.1250401},
file = {:Users/nsawada/Library/Application Support/Mendeley Desktop/Downloaded/Daniel, Chen - 2003 - Video visualization.pdf:pdf},
isbn = {0-7803-8120-3},
keywords = {Change detection,Image-swept volume,Video surveillance,Video visualization,Volume rendering},
pages = {409--416},
title = {{Video visualization}},
year = {2003}
}
@inproceedings{Longyin2016,
author = {Xu, Longyin and Nakayama, Masanori and Wu, Hsiang-Yun and Watanabe, Kazuho and Takahashi, Shigeo and Uemura, Makoto and Fujishiro, Issei},
booktitle = {Proceedings of NICOGRAPH International 2016},
doi = {10.1109/NicoInt.2016.3},
file = {:Users/nsawada/Google Drive/Papers/TimeTubes.pdf:pdf},
keywords = {3d information visualization,blazar,data,multivariate data},
pages = {15--20},
title = {{TimeTubes: Design of a visualization tool for time-dependent, multivariate blazar datasets}},
year = {2016}
}
@inproceedings{Brown1956,
  author = {Robert G. Brown},
  title = {Exponential smoothing for predicting demand},
  booktitle = {Arthur D. Little Inc.},
  year = {1956}
}

@article{Gaur2014,
author = {Gaur, Haritma and Gupta, Alok C and Wiita, Paul J and Uemura, Makoto and Itoh, Ryosuke and Sasada, Mahito},
doi = {10.1088/2041-8205/781/1/L4},
file = {:Users/nsawada/Google Drive/Papers/ANTI-CORRELATED OPTICAL FLUX AND POLARIZATION VARIABILITY IN BL LAC.pdf:pdf},
journal = {The Astrophysical Journal Letters},
keywords = {active,bl lac,bl lacertae objects,color figures,galaxies,individual,online-only material,photometry},
number = {L4},
pages = {1--5},
title = {{Anti-correlated optical flux and polarization variability in BL Lac}},
volume = {781},
year = {2014}
}

@inproceedings{Elmqvist2007,
abstract = {Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method. {\textcopyright} 2007 IEEE.},
author = {Elmqvist, Niklas and Stasko, John and Tsigas, Philippas},
booktitle = {Proceedings of 2007 IEEE Symposium on Visual Analytics Science and Technology},
doi = {10.1109/VAST.2007.4389013},
file = {:Users/nsawada/Google Drive/Papers/DataMeadow- A Visual Canvas for Analysis of Large-Scale Multivariate Data.pdf:pdf},
isbn = {9781424416592},
keywords = {Dynamic queries,Iterative analysis,Multivariate data,Parallel coordinates,Small multiples,Starplot,Visual analytics},
pages = {187--194},
title = {{DataMeadow: A visual canvas for analysis of large-scale multivariate data}},
year = {2007}
}

@inproceedings{Eichmann2015,
abstract = {Finding patterns is a common task in time series analysis which has gained a lot of attention across many fields. A multitude of similarity measures have been introduced to perform pattern searches. The accuracy of such measures is often evaluated objectively using a one nearest neighbor classification (1NN) on labeled time series or through clustering. Prior work often disregards the subjective similarity of time series which can be pivotal in systems where a user specified pattern is used as input and a similarity-based ranking is expected as output (query-by-example). In this paper, we describe how a human-annotated ranking based on real-world queries and datasets can be created using simple crowdsourcing tasks and use this ranking as ground-truth to evaluate the perceived accuracy of existing time series similarity measures. Furthermore, we show how different sampling strategies and time series representations of pen-drawn queries effect the precision of these similarity measures and provide a publicly available dataset which can be used to optimize existing and future similarity search algorithms.},
author = {Eichmann, Philipp and Zgraggen, Emanuel},
booktitle = {Proceedings of the 20th International Conference on Intelligent User Interfaces},
doi = {10.1145/2678025.2701379},
file = {:Users/nsawada/Google Drive/Papers/Evaluating subjective accuracy in time series pattern-matching using human-annotated rankings.pdf:pdf},
isbn = {9781450333061},
keywords = {Crowd sourcing,Information retrieval,Pen {\&} touch,Result ranking,Sampling,Sketching,Time series},
mendeley-groups = {Visual query},
pages = {28--37},
title = {{Evaluating subjective accuracy in time series pattern-matching using human-annotated rankings}},
year = {2015}
}

@INPROCEEDINGS{ruta2019sax,
author={Nicholas Ruta and Naoko Sawada and Katy McKeough and Michael Behrisch and Johanna Beyer},
booktitle={Proceedings of 2019 IEEE Visualization Conference (VIS)},
title={SAX Navigator: Time Series Exploration through Hierarchical Clustering},
year={2019},
volume={},
number={},
pages={236-240},
keywords={astronomy computing;data analysis;data visualisation;interactive systems;mathematics computing;pattern clustering;time series;data analysts;multiple time series;reasonable clustering;SAX navigator;time series data clusters;time series exploration;hierarchical clustering;long time series;clustering time series;symbolic aggregate approximation;interactive visualization tool;Time series analysis;Navigation;Heating systems;Visualization;Tools;Shape;Data visualization;Human-centered computing;Visualization;Visualization techniques;Treemaps;Visualization design and evaluation methods},
doi={10.1109/VISUAL.2019.8933618},
ISSN={null},}

@inproceedings{Shao2014,
abstract = {Recently, there has been an interest in methods for filtering large scatter plot spaces for interesting patterns. However, user interaction remains crucial in starting an explorative analysis in a large scatter plot space. We introduce an approach for explorative search and navigation in large sets of scatter plot diagrams. By means of a sketch-based query interface, users can start the exploration process by providing a visual example of the pattern they are interested in. A shadow-drawing approach provides suggestions for possibly relevant patterns while query drawing takes place, supporting the visual search process. We apply the approach on a large real-world data set, demonstrating the principal functionality and usefulness of our technique.},
author = {Shao, Lin and Behrisch, Michael and Schreck, Tobias and Landesberger, Tatiana V and Scherer, Maximilian and Bremm, Sebastian and Keim, Daniel},
booktitle = {Proceedings of EuroVis Workshop on Visual Analytics},
doi = {10.2312/eurova.20141140},
file = {:Users/nsawada/Google Drive/Papers/Guided sketching for visual search and exploration in large scatter plot spaces.pdf:pdf},
keywords = {H33 [Information Storage and Retrieval],Informa-tion Search and Retrieval—Search process},
mendeley-groups = {Visual query},
pages = {19--23},
title = {{Guided sketching for visual search and exploration in large scatter plot spaces}},
year = {2014}
}

@InProceedings{Zhang2005,
author="Zhang, Hui
and Ho, Tubao
and Huang, Wei",
editor="Wang, Jun
and Liao, Xiao-Feng
and Yi, Zhang",
title="Blind Feature Extraction for Time-Series Classification Using Haar Wavelet Transform",
booktitle="Advances in Neural Networks -- ISNN 2005",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="605--610",
abstract="Time-series classification has attracted increasing interest in recent years, particularly for long time-series as those arising in bioinformatics and financial domain. Many dimensionality reduction algorithms have been proposed to attack the so-called curse of dimensionality problem. However, choosing the number of features is not a trivial task and has not been well considered. In this paper, we propose a novel blind feature extraction algorithm with Haar wavelet transform which can determine the feature dimensionality automatically. The algorithm takes the tradeoff of achieving lower dimensionality and lower sum of squared errors between the features and original time-series. Experimental results performed on several widely used time-series data demonstrate the effectiveness of the proposed algorithm.",
isbn="978-3-540-32067-8"
}

@article{Marscher2010,
abstract = {We present results from monitoring the multi-waveband flux, linear polarization, and parsec-scale structure of the quasar PKS 1510 - 089, concentrating on eight major $\gamma$-ray flares that occurred during the interval 2009.0-2009.5. The $\gamma$-ray peaks were essentially simultaneous with maxima at optical wavelengths, although the flux ratio of the two wave bands varied by an order of magnitude. The optical polarization vector rotated by 720° during a five-day period encompassing six of these flares. This culminated in a very bright, ∼ 1 day, optical and $\gamma$-ray flare as a bright knot of emission passed through the highest-intensity, stationary feature (the "core") seen in 43 GHz Very Long Baseline Array images. The knot continued to propagate down the jet at an apparent speed of 22c and emit strongly at $\gamma$-ray energies as a months-long X-ray/radio outburst intensified. We interpret these events as the result of the knot following a spiral path through a mainly toroidal magnetic field pattern in the acceleration and collimation zone of the jet, after which it passes through a standing shock in the 43 GHz core and then continues downstream. In this picture, the rapid $\gamma$-ray flares result from scattering of infrared seed photons from a relatively slow sheath of the jet as well as from optical synchrotron radiation in the faster spine. The 2006-2009.7 radio and X-ray flux variations are correlated at very high significance; we conclude that the X-rays are mainly from inverse Compton scattering of infrared seed photons by 20-40 MeV electrons. {\textcopyright} 2010. The American Astronomical Society. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1001.2574},
author = {Marscher, Alan P. and Jorstad, Svetlana G. and Larionov, Valeri M. and Aller, Margo F. and Aller, Hugh D. and L{\"{a}}hteenm{\"{a}}ki, Anne and Agudo, Ivn and Smith, Paul S. and Gurwell, Mark and Hagen-Thorn, Vladimir A. and Konstantinova, Tatiana S. and Larionova, Elena G. and Larionova, Liudmila V. and Melnichuk, Daria A. and Blinov, Dmitry A. and Kopatskaya, Evgenia N. and Troitsky, Ivan S. and Tornikoski, Merja and Hovatta, Talvikki and Schmidt, Gary D. and D'Arcangelo, Francesca D. and Bhattarai, Dipesh and Taylor, Brian and Olmstead, Alice R. and Manne-Nicholas, Emily and Roca-Sogorb, Mar and G{\'{o}}mez, Jos{\'{e}} L. and McHardy, Ian M. and Kurtanidze, Omar and Nikolashvili, Maria G. and Kimeridze, Givi N. and Sigua, Lorand A.},
doi = {10.1088/2041-8205/710/2/L126},
eprint = {1001.2574},
file = {:Users/nsawada/Google Drive/Papers/Marscher{\_}2010{\_}ApJL{\_}710{\_}L126.pdf:pdf},
issn = {20418213},
journal = {Astrophysical Journal Letters},
keywords = {Gamma rays: general,Polarization,Quasars: individual (PKS 1510?089),Radio continuum: Galaxies,X-rays: galaxies},
number = {2},
pages = {126--131},
title = {{Probing the inner jet of the quasar PKS 1510-089 with multi-waveband monitoring during strong gamma-ray activity}},
volume = {710},
year = {2010}
}

@inproceedings{Chen2007,
abstract = {Monitoring predefined patterns in streaming time series is useful to applications such as trend-related analysis, sensor networks and video surveillance. Most current studies on such monitoring employ Euclidean distance to calculate the similarities between given query patterns and subsequences of streaming time series. Euclidean distance has been shown to be ineffective in measuring distances of time series in which shifting and scaling usually exist. Consequently, warping distances such as dynamic time warping (DTW), longest common subsequence (LCSS), have been proposed to handle warps in temporal dimension. However, they are inadequate in handling shifting and scaling in amplitude dimension. Moreover, they have been designed mainly for full sequence matching, whereas in online monitoring applications, we typically have no knowledge on the positions and lengths of possible matching subsequences. In this paper, we first discuss the weaknesses of existing warping distances on detecting patterns from streaming time series. We then propose a novel warping distance, which we name Spatial Assembling Distance (SpADe), that is able to handle shifting and scaling in both temporal and amplitude dimensions. We further propose an efficient approach for continuous pattern detection using SpADe, that is fundamental for subsequence matching on streaming data. Finally, our experimental results show that SpADe is effective and efficient for continuous pattern detection in streaming time series. {\textcopyright} 2007 IEEE.},
author = {Chen, Yueguo and Nascimento, Mario A. and Ooi, Beng Chin and Tung, Anthony K.H.},
booktitle = {Proceedings of 2007 IEEE 23rd International Conference on Data Engineering},
doi = {10.1109/ICDE.2007.367924},
file = {:Users/nsawada/Google Drive/Papers/SpADe- On Shape-based Pattern Detection in Streaming Time Series.pdf:pdf},
isbn = {1424408032},
issn = {10844627},
pages = {786--795},
title = {{SpADe: On shape-based pattern detection in streaming time series}},
year = {2007}
}

@misc{d3_framework,
  author = {Bostock, Mike},
  title = {D3.js},
  url = {https://d3js.org/},
  year = {2020},
}

@misc{paper_framework,
  author = {Lehni, Jurg and Puckey, Jonathan},
  title = {paper.js},
  url = {http://paperjs.org/},
  year = {2020},
}

@misc {three_framework,
    author = {three.js authors},
    title = {three.js},
    url = {https://threejs.org/},
    year = {2020},
}

@inproceedings{Tzeng2003,
author = {Tzeng, Fan-Yin and Lum, Eric B. and Ma, Kwan-Liu},
booktitle = {Proceedings of the 14th IEEE Visualization 2003},
doi = {10.1109/VISUAL.2003.1250413},
file = {:Users/nsawada/Google Drive/Papers/A Novel Interface for Higher-Dimensional Classification of Volume Data.pdf:pdf},
isbn = {0769520308},
keywords = {classification,graphics hardware,interactive visualization,multidimensional transfer function,neural network,user interface design,volume visualization},
pages = {505--512},
publisher = {IEEE Computer Society},
title = {{A novel interface for higher-dimensional classification of volume data}},
year = {2003}
}

@mastersthesis {Huang2019,
author = {Ruochen, Huang},
title = {Study of the magnetic field in the jet of active galactic nuclei using a new visualization technique of polarization data (in Japanese)},
year = {2019},
school = {Hiroshima University},
url = {http://www-heaf.astro.hiroshima-u.ac.jp/thesis/huang2018.pdf}
}

@article{Murase2018,
	doi = {10.3847/1538-4357/aada00},
	year = {2018},
	publisher = {American Astronomical Society},
	volume = {865},
	number = {2},
	pages = {124},
	author = {Kohta Murase and Foteini Oikonomou and Maria Petropoulou},
	title = {Blazar flares as an origin of high-energy cosmic neutrinos?},
	journal = {The Astrophysical Journal}
}

@article{Bednarek1999,
    author = {Bednarek, W. and Protheroe, R. J.},
    title = "{Gamma-ray and neutrino flares produced by protons accelerated on an accretion disc surface in active galactic nuclei}",
    journal = {Monthly Notices of the Royal Astronomical Society},
    volume = {302},
    number = {2},
    pages = {373-380},
    year = {1999},
    abstract = "{We discuss the consequences of almost rectilinear acceleration of protons to extremely high energies in a reconnection region on the surface of an accretion disc that surrounds a central black hole in an active galaxy. The protons produce γ-rays and neutrinos in interactions with the disc radiation as considered in several previous papers. However, in this model the secondary γ-rays can initiate cascades in the magnetic and radiation fields above the disc. We compute the spectra of γ-rays and neutrinos emerging from regions close to the disc surface. Depending on the parameters of the reconnection regions, this model predicts the appearance of γ-ray and neutrino flares if protons take most of the energy from the reconnection region. In contrast, if leptons take most of the energy, they produce pure γ-ray flares. The γ-ray spectrum expected in the case of hadronic cascading is compared with the spectrum observed during the flare in 1991 June from 3C 279. The neutrino flares that should accompany these γ-ray flares may be detected by future large-scale neutrino telescopes sensitive at ∼ 105 TeV.}",
    issn = {0035-8711},
    doi = {10.1046/j.1365-8711.1999.02132.x},
    eprint = {https://academic.oup.com/mnras/article-pdf/302/2/373/2908873/302-2-373.pdf},
}

@article{Atoyan2001,
  title = {High-energy neutrinos from photomeson processes in blazars},
  author = {Atoyan, Armen and Dermer, Charles D.},
  journal = {Physical Review Letters},
  volume = {87},
  number = {22},
  pages = {221102:1-221102:4},
  numpages = {4},
  year = {2001},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.87.221102},
}

@ARTICLE{Bock2020,
author={Alexander {Bock} and Emil {Axelsson} and Jonathas {Costa} and Gene {Payne} and Micah {Acinapura} and Vivian {Trakinski} and Carter {Emmart} and Claudio {Silva} and Charles {Hansen} and Anders {Ynnerman}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={OpenSpace: A system for astrographics},
year={2020},
volume={26},
number={1},
pages={633-642},
keywords={Data visualization;Tools;Rendering (computer graphics);Data models;Astronomy;Space vehicles;Space missions;Astrographics;astronomy;astrophysics;system},
doi={10.1109/TVCG.2019.2934259},
ISSN={2160-9306},
}

@INPROCEEDINGS{McCurdy2019,
author={Nina {McCurdy} and Miriah {Meyer}},
booktitle={2019 IEEE Visualization Conference (VIS)},
title={GalStamps: Analyzing real and simulated galaxy observations},
year={2019},
volume={},
number={},
pages={276-280},
keywords={astronomy computing;data analysis;data visualisation;galaxies;simulated galaxy observations;way astronomers;galaxy formation;visual analysis;statistical analysis;astrophysicists;data understanding;GalStamps;Data visualization;Visualization;Two dimensional displays;Task analysis;Telescopes;Prototypes;Extraterrestrial measurements;Visualization;Design study;Astronomy},
doi={10.1109/VISUAL.2019.8933671},
ISSN={null},}

@ARTICLE{Bock2020,
author={Alexander {Bock} and Emil {Axelsson} and Jonathas {Costa} and Gene {Payne} and Micah {Acinapura} and Vivian {Trakinski} and Carter {Emmart} and Claudio {Silva} and Charles {Hansen} and Anders {Ynnerman}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={OpenSpace: A System for Astrographics},
year={2020},
volume={26},
number={1},
pages={633-642},
keywords={astronomy computing;data visualisation;interactive astrographics;interaction paradigms;space mission data;rapid prototyping;collaboration capabilities;multiple spatio-temporal scales;data variety;exploratory astrographics;science communication;space exploration;astronomy;interactive exploration;software system;cosmos;human knowledge;OpenSpace;Data visualization;Tools;Rendering (computer graphics);Data models;Astronomy;Space vehicles;Space missions;Astrographics;astronomy;astrophysics;system},
doi={10.1109/TVCG.2019.2934259},
ISSN={2160-9306},
month={Jan},}

@inproceedings{Preston2016,
abstract = {Cosmological simulations produce a multitude of data types whose large scale makes them difficult to thoroughly explore in an interactive setting. One aspect of particular interest to scientists is the evolution of groups of dark matter particles, or "halos," described by merger trees. However, in order to fully understand subtleties in the merger trees, other data types derived from the simulation must be incorporated as well. In this work, we develop a novel interactive linked-view visualization system that focuses on simultaneously exploring dark matter halos, their hierarchical evolution, corresponding particle data, and other quantitative information. We employ a parallel remote renderer and a local merger tree selection tool so that users can analyze large data sets interactively. This allows scientists to assess their simulation code, understand inconsistencies in extracted data, and intuitively understand simulation behavior on all scales. We demonstrate the effectiveness of our system through a set of case studies on large-scale cosmological data from the HACC (Hardware/Hybrid Accelerated Cosmology Code) simulation framework.},
author = {Preston, Annie and Ghods, Ramyar and Xie, Jinrong and Sauer, Franz and Leaf, Nick and Ma, Kwan Liu and Rangel, Esteban and Kovacs, Eve and Heitmann, Katrin and Habib, Salman},
booktitle = {Proceedings of IEEE Pacific Visualization Symposium},
year = {2016},
doi = {10.1109/PACIFICVIS.2016.7465250},
file = {:Users/nsawada/Google Drive/Papers/An integrated visualization system for interactive analysis of large, heterogeneous cosmology data.pdf:pdf},
isbn = {9781509014514},
issn = {21658773},
keywords = {I.6.4 [Simulation and Modeling]: Simulation Output,J.2 [Physical Sciences and Engineering]: Astronomy},
pages = {48--55},
title = {{An integrated visualization system for interactive analysis of large, heterogeneous cosmology data}}
}
